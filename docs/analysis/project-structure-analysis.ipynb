{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5297c717",
   "metadata": {},
   "source": [
    "# üîç An√°lise Detalhada da Estrutura - Will Finance 5.0\n",
    "\n",
    "## üìã Vis√£o Geral\n",
    "\n",
    "Este notebook realiza uma an√°lise completa e interativa da estrutura do projeto **Will Finance 5.0**, um sistema profissional de gerenciamento financeiro com arquitetura moderna e robusta.\n",
    "\n",
    "### üéØ Objetivos da An√°lise\n",
    "\n",
    "- **Mapear** a estrutura completa do projeto\n",
    "- **Analisar** padr√µes arquiteturais utilizados\n",
    "- **Identificar** tecnologias e depend√™ncias\n",
    "- **Documentar** componentes e m√≥dulos\n",
    "- **Avaliar** organiza√ß√£o e qualidade do c√≥digo\n",
    "\n",
    "### üèóÔ∏è Arquitetura do Projeto\n",
    "\n",
    "O Will Finance 5.0 utiliza uma arquitetura **full-stack moderna** com:\n",
    "\n",
    "- **Frontend**: React 18 + TypeScript + Vite + Tailwind CSS\n",
    "- **Backend**: Node.js + Express + TypeScript + Prisma ORM  \n",
    "- **IA**: Machine Learning para processamento de extratos\n",
    "- **DevOps**: Docker + GitHub Actions + Nginx\n",
    "- **Banco de Dados**: SQLite (dev) / PostgreSQL (prod)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d591cfe",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ An√°lise da Estrutura do Projeto\n",
    "\n",
    "Vamos come√ßar importando as bibliotecas necess√°rias e criando fun√ß√µes para analisar a estrutura de diret√≥rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09195acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Caminho base do projeto\n",
    "PROJECT_ROOT = r\"d:\\Documents\\GitHub\\Gerenciador_Financeiro-5.0\"\n",
    "print(f\"üè† Diret√≥rio do projeto: {PROJECT_ROOT}\")\n",
    "\n",
    "def analyze_directory_structure(path, max_depth=3):\n",
    "    \"\"\"\n",
    "    Analisa a estrutura de diret√≥rios e retorna estat√≠sticas detalhadas\n",
    "    \"\"\"\n",
    "    structure = {}\n",
    "    file_counts = defaultdict(int)\n",
    "    total_files = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(path):\n",
    "        # Calcula a profundidade relativa\n",
    "        depth = root.replace(path, '').count(os.sep)\n",
    "        if depth > max_depth:\n",
    "            continue\n",
    "            \n",
    "        relative_path = os.path.relpath(root, path)\n",
    "        if relative_path == '.':\n",
    "            relative_path = 'root'\n",
    "            \n",
    "        structure[relative_path] = {\n",
    "            'dirs': len(dirs),\n",
    "            'files': len(files),\n",
    "            'file_types': {}\n",
    "        }\n",
    "        \n",
    "        # Conta tipos de arquivo\n",
    "        for file in files:\n",
    "            ext = pathlib.Path(file).suffix.lower()\n",
    "            if not ext:\n",
    "                ext = 'no_extension'\n",
    "            file_counts[ext] += 1\n",
    "            total_files += 1\n",
    "            \n",
    "            if ext not in structure[relative_path]['file_types']:\n",
    "                structure[relative_path]['file_types'][ext] = 0\n",
    "            structure[relative_path]['file_types'][ext] += 1\n",
    "    \n",
    "    return structure, file_counts, total_files\n",
    "\n",
    "def get_project_stats():\n",
    "    \"\"\"\n",
    "    Retorna estat√≠sticas gerais do projeto\n",
    "    \"\"\"\n",
    "    structure, file_counts, total_files = analyze_directory_structure(PROJECT_ROOT)\n",
    "    \n",
    "    stats = {\n",
    "        'total_files': total_files,\n",
    "        'total_directories': len(structure),\n",
    "        'file_types': dict(file_counts),\n",
    "        'structure': structure\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Executa an√°lise inicial\n",
    "print(\"üîç Analisando estrutura do projeto...\")\n",
    "project_stats = get_project_stats()\n",
    "\n",
    "print(f\"üìä Estat√≠sticas Gerais:\")\n",
    "print(f\"   ‚Ä¢ Total de arquivos: {project_stats['total_files']}\")\n",
    "print(f\"   ‚Ä¢ Total de diret√≥rios: {project_stats['total_directories']}\")\n",
    "print(f\"   ‚Ä¢ Tipos de arquivo: {len(project_stats['file_types'])}\")\n",
    "\n",
    "# Top 10 extens√µes de arquivo mais comuns\n",
    "top_extensions = Counter(project_stats['file_types']).most_common(10)\n",
    "print(f\"\\nüìã Top 10 Extens√µes de Arquivo:\")\n",
    "for ext, count in top_extensions:\n",
    "    print(f\"   ‚Ä¢ {ext}: {count} arquivos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926755d4",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Mapeamento dos Diret√≥rios Principais\n",
    "\n",
    "Vamos mapear e visualizar a hierarquia dos diret√≥rios principais do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c306e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento dos diret√≥rios principais\n",
    "main_directories = {\n",
    "    '.github': 'CI/CD e Configura√ß√µes GitHub',\n",
    "    'client': 'Frontend React + TypeScript',\n",
    "    'server': 'Backend Node.js + Express',\n",
    "    'ia': 'Sistema de Machine Learning',\n",
    "    'docs': 'Documenta√ß√£o T√©cnica',\n",
    "    'scripts': 'Scripts de Automa√ß√£o',\n",
    "    'configs': 'Configura√ß√µes Centralizadas',\n",
    "    'data': 'Dados de Teste e Exemplos',\n",
    "    'database': 'Schemas e Backups de DB',\n",
    "    'docker': 'Configura√ß√µes Docker',\n",
    "    'nginx': 'Configura√ß√µes Nginx'\n",
    "}\n",
    "\n",
    "def analyze_main_directories():\n",
    "    \"\"\"\n",
    "    Analisa cada diret√≥rio principal e suas estat√≠sticas\n",
    "    \"\"\"\n",
    "    directory_stats = {}\n",
    "    \n",
    "    for dir_name, description in main_directories.items():\n",
    "        dir_path = os.path.join(PROJECT_ROOT, dir_name)\n",
    "        if os.path.exists(dir_path):\n",
    "            structure, file_counts, total_files = analyze_directory_structure(dir_path, max_depth=2)\n",
    "            directory_stats[dir_name] = {\n",
    "                'description': description,\n",
    "                'total_files': total_files,\n",
    "                'file_types': dict(file_counts),\n",
    "                'subdirectories': len([k for k in structure.keys() if k != 'root'])\n",
    "            }\n",
    "        else:\n",
    "            directory_stats[dir_name] = {\n",
    "                'description': description,\n",
    "                'total_files': 0,\n",
    "                'file_types': {},\n",
    "                'subdirectories': 0\n",
    "            }\n",
    "    \n",
    "    return directory_stats\n",
    "\n",
    "# Analisa diret√≥rios principais\n",
    "print(\"üìÅ Analisando diret√≥rios principais...\")\n",
    "main_dir_stats = analyze_main_directories()\n",
    "\n",
    "# Cria DataFrame para melhor visualiza√ß√£o\n",
    "df_main_dirs = pd.DataFrame([\n",
    "    {\n",
    "        'Diret√≥rio': dir_name,\n",
    "        'Descri√ß√£o': stats['description'],\n",
    "        'Total de Arquivos': stats['total_files'],\n",
    "        'Subdiret√≥rios': stats['subdirectories'],\n",
    "        'Tipos de Arquivo': len(stats['file_types'])\n",
    "    }\n",
    "    for dir_name, stats in main_dir_stats.items()\n",
    "    if stats['total_files'] > 0\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Estat√≠sticas dos Diret√≥rios Principais:\")\n",
    "print(df_main_dirs.to_string(index=False))\n",
    "\n",
    "# Visualiza√ß√£o: Distribui√ß√£o de arquivos por diret√≥rio\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "plt.subplot(2, 2, 1)\n",
    "dirs_with_files = df_main_dirs[df_main_dirs['Total de Arquivos'] > 0]\n",
    "plt.bar(dirs_with_files['Diret√≥rio'], dirs_with_files['Total de Arquivos'], \n",
    "        color=sns.color_palette(\"husl\", len(dirs_with_files)))\n",
    "plt.title('üìä Distribui√ß√£o de Arquivos por Diret√≥rio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('N√∫mero de Arquivos')\n",
    "\n",
    "# Gr√°fico de pizza - Top 5 diret√≥rios\n",
    "plt.subplot(2, 2, 2)\n",
    "top_5_dirs = dirs_with_files.nlargest(5, 'Total de Arquivos')\n",
    "plt.pie(top_5_dirs['Total de Arquivos'], labels=top_5_dirs['Diret√≥rio'], \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "plt.title('ü•ß Top 5 Diret√≥rios por Volume')\n",
    "\n",
    "# Tipos de arquivo mais comuns\n",
    "plt.subplot(2, 2, 3)\n",
    "all_file_types = Counter()\n",
    "for stats in main_dir_stats.values():\n",
    "    all_file_types.update(stats['file_types'])\n",
    "\n",
    "top_file_types = dict(all_file_types.most_common(8))\n",
    "plt.bar(top_file_types.keys(), top_file_types.values(), \n",
    "        color=sns.color_palette(\"viridis\", len(top_file_types)))\n",
    "plt.title('üìã Tipos de Arquivo Mais Comuns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Quantidade')\n",
    "\n",
    "# Complexidade por diret√≥rio (subdiret√≥rios vs arquivos)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(dirs_with_files['Subdiret√≥rios'], dirs_with_files['Total de Arquivos'], \n",
    "           s=100, alpha=0.7, c=range(len(dirs_with_files)), cmap='plasma')\n",
    "for i, dir_name in enumerate(dirs_with_files['Diret√≥rio']):\n",
    "    plt.annotate(dir_name, \n",
    "                (dirs_with_files.iloc[i]['Subdiret√≥rios'], \n",
    "                 dirs_with_files.iloc[i]['Total de Arquivos']),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "plt.xlabel('N√∫mero de Subdiret√≥rios')\n",
    "plt.ylabel('Total de Arquivos')\n",
    "plt.title('üîÑ Complexidade dos Diret√≥rios')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo executivo\n",
    "print(\"\\nüìã RESUMO EXECUTIVO:\")\n",
    "print(\"=\" * 50)\n",
    "total_analyzed_files = sum(stats['total_files'] for stats in main_dir_stats.values())\n",
    "largest_dir = max(main_dir_stats.items(), key=lambda x: x[1]['total_files'])\n",
    "most_complex_dir = max(main_dir_stats.items(), key=lambda x: x[1]['subdirectories'])\n",
    "\n",
    "print(f\"üìÅ Total de arquivos analisados: {total_analyzed_files}\")\n",
    "print(f\"üèÜ Maior diret√≥rio: {largest_dir[0]} ({largest_dir[1]['total_files']} arquivos)\")\n",
    "print(f\"üîÑ Mais complexo: {most_complex_dir[0]} ({most_complex_dir[1]['subdirectories']} subdiret√≥rios)\")\n",
    "print(f\"üéØ Foco principal: Frontend e Backend (client + server)\")\n",
    "print(f\"ü§ñ IA integrada: Diret√≥rio 'ia' com {main_dir_stats['ia']['total_files']} arquivos\")\n",
    "print(\"‚úÖ Projeto bem estruturado e organizado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd985b",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ An√°lise dos Arquivos de Configura√ß√£o\n",
    "\n",
    "Vamos analisar os principais arquivos de configura√ß√£o do projeto para entender as depend√™ncias e configura√ß√µes utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_config_files():\n",
    "    \"\"\"\n",
    "    Analisa os principais arquivos de configura√ß√£o do projeto\n",
    "    \"\"\"\n",
    "    config_files = {\n",
    "        'package.json': 'Depend√™ncias e scripts principais',\n",
    "        'client/package.json': 'Depend√™ncias do frontend',\n",
    "        'server/package.json': 'Depend√™ncias do backend',\n",
    "        'client/tsconfig.json': 'Configura√ß√£o TypeScript (frontend)',\n",
    "        'server/tsconfig.json': 'Configura√ß√£o TypeScript (backend)',\n",
    "        'docker/docker-compose.yml': 'Configura√ß√£o Docker',\n",
    "        'server/prisma/schema.prisma': 'Schema do banco de dados'\n",
    "    }\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "    for config_file, description in config_files.items():\n",
    "        file_path = os.path.join(PROJECT_ROOT, config_file)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                analysis_results[config_file] = {\n",
    "                    'description': description,\n",
    "                    'exists': True,\n",
    "                    'size_kb': len(content) / 1024,\n",
    "                    'lines': len(content.split('\\n')),\n",
    "                    'content_preview': content[:500] + '...' if len(content) > 500 else content\n",
    "                }\n",
    "                \n",
    "                # An√°lise espec√≠fica por tipo de arquivo\n",
    "                if config_file.endswith('package.json'):\n",
    "                    try:\n",
    "                        package_data = json.loads(content)\n",
    "                        analysis_results[config_file]['dependencies'] = len(package_data.get('dependencies', {}))\n",
    "                        analysis_results[config_file]['dev_dependencies'] = len(package_data.get('devDependencies', {}))\n",
    "                        analysis_results[config_file]['scripts'] = len(package_data.get('scripts', {}))\n",
    "                        analysis_results[config_file]['name'] = package_data.get('name', 'N/A')\n",
    "                        analysis_results[config_file]['version'] = package_data.get('version', 'N/A')\n",
    "                    except json.JSONDecodeError:\n",
    "                        analysis_results[config_file]['parsing_error'] = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                analysis_results[config_file] = {\n",
    "                    'description': description,\n",
    "                    'exists': True,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "        else:\n",
    "            analysis_results[config_file] = {\n",
    "                'description': description,\n",
    "                'exists': False\n",
    "            }\n",
    "    \n",
    "    return analysis_results\n",
    "\n",
    "# Executa an√°lise dos arquivos de configura√ß√£o\n",
    "print(\"‚öôÔ∏è Analisando arquivos de configura√ß√£o...\")\n",
    "config_analysis = analyze_config_files()\n",
    "\n",
    "# Cria DataFrame para visualiza√ß√£o\n",
    "config_data = []\n",
    "for file_path, data in config_analysis.items():\n",
    "    if data['exists'] and 'error' not in data:\n",
    "        config_data.append({\n",
    "            'Arquivo': file_path,\n",
    "            'Descri√ß√£o': data['description'],\n",
    "            'Tamanho (KB)': round(data.get('size_kb', 0), 2),\n",
    "            'Linhas': data.get('lines', 0),\n",
    "            'Depend√™ncias': data.get('dependencies', 'N/A'),\n",
    "            'Dev Dependencies': data.get('dev_dependencies', 'N/A'),\n",
    "            'Scripts': data.get('scripts', 'N/A')\n",
    "        })\n",
    "\n",
    "df_configs = pd.DataFrame(config_data)\n",
    "print(\"\\nüìã Arquivos de Configura√ß√£o Encontrados:\")\n",
    "print(df_configs.to_string(index=False))\n",
    "\n",
    "# An√°lise detalhada dos package.json\n",
    "package_files = {k: v for k, v in config_analysis.items() if k.endswith('package.json') and v['exists']}\n",
    "\n",
    "print(\"\\nüì¶ An√°lise Detalhada dos Package.json:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for file_path, data in package_files.items():\n",
    "    if 'dependencies' in data:\n",
    "        print(f\"\\nüîß {file_path}:\")\n",
    "        print(f\"   üìõ Nome: {data.get('name', 'N/A')}\")\n",
    "        print(f\"   üè∑Ô∏è Vers√£o: {data.get('version', 'N/A')}\")\n",
    "        print(f\"   üìö Depend√™ncias de produ√ß√£o: {data.get('dependencies', 0)}\")\n",
    "        print(f\"   üõ†Ô∏è Depend√™ncias de desenvolvimento: {data.get('dev_dependencies', 0)}\")\n",
    "        print(f\"   ‚ö° Scripts dispon√≠veis: {data.get('scripts', 0)}\")\n",
    "\n",
    "# Visualiza√ß√£o das configura√ß√µes\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Gr√°fico 1: Tamanho dos arquivos de configura√ß√£o\n",
    "plt.subplot(2, 3, 1)\n",
    "config_sizes = df_configs[df_configs['Tamanho (KB)'] > 0]\n",
    "plt.bar(range(len(config_sizes)), config_sizes['Tamanho (KB)'], \n",
    "        color=sns.color_palette(\"rocket\", len(config_sizes)))\n",
    "plt.title('üìä Tamanho dos Arquivos de Config')\n",
    "plt.ylabel('Tamanho (KB)')\n",
    "plt.xticks(range(len(config_sizes)), \n",
    "           [f.split('/')[-1] for f in config_sizes['Arquivo']], rotation=45)\n",
    "\n",
    "# Gr√°fico 2: Depend√™ncias por package.json\n",
    "plt.subplot(2, 3, 2)\n",
    "package_data = []\n",
    "for file_path, data in package_files.items():\n",
    "    if 'dependencies' in data:\n",
    "        package_data.append({\n",
    "            'file': file_path.split('/')[-2] if '/' in file_path else 'root',\n",
    "            'prod': data.get('dependencies', 0),\n",
    "            'dev': data.get('dev_dependencies', 0)\n",
    "        })\n",
    "\n",
    "if package_data:\n",
    "    df_packages = pd.DataFrame(package_data)\n",
    "    x = range(len(df_packages))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar([i - width/2 for i in x], df_packages['prod'], width, \n",
    "            label='Produ√ß√£o', color='#2E8B57')\n",
    "    plt.bar([i + width/2 for i in x], df_packages['dev'], width, \n",
    "            label='Desenvolvimento', color='#FF6347')\n",
    "    \n",
    "    plt.title('üì¶ Depend√™ncias por M√≥dulo')\n",
    "    plt.ylabel('N√∫mero de Depend√™ncias')\n",
    "    plt.xticks(x, df_packages['file'])\n",
    "    plt.legend()\n",
    "\n",
    "# Gr√°fico 3: Distribui√ß√£o de scripts\n",
    "plt.subplot(2, 3, 3)\n",
    "total_scripts = sum(data.get('scripts', 0) for data in package_files.values() if 'scripts' in data)\n",
    "scripts_by_module = []\n",
    "for file_path, data in package_files.items():\n",
    "    if 'scripts' in data and data['scripts'] > 0:\n",
    "        module_name = file_path.split('/')[-2] if '/' in file_path else 'root'\n",
    "        scripts_by_module.append((module_name, data['scripts']))\n",
    "\n",
    "if scripts_by_module:\n",
    "    modules, script_counts = zip(*scripts_by_module)\n",
    "    plt.pie(script_counts, labels=modules, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('‚ö° Distribui√ß√£o de Scripts')\n",
    "\n",
    "# Informa√ß√µes sobre TypeScript\n",
    "plt.subplot(2, 3, 4)\n",
    "ts_configs = [f for f in config_analysis.keys() if 'tsconfig' in f and config_analysis[f]['exists']]\n",
    "if ts_configs:\n",
    "    ts_data = [(f.split('/')[0] if '/' in f else 'root', config_analysis[f]['lines']) \n",
    "               for f in ts_configs]\n",
    "    modules, lines = zip(*ts_data)\n",
    "    plt.bar(modules, lines, color='#3178C6')\n",
    "    plt.title('üìù Configura√ß√µes TypeScript')\n",
    "    plt.ylabel('Linhas de Configura√ß√£o')\n",
    "\n",
    "# Resumo da stack tecnol√≥gica\n",
    "plt.subplot(2, 3, 5)\n",
    "tech_stack = {\n",
    "    'React': 1 if any('react' in str(data.get('dependencies', {})) for data in package_files.values()) else 0,\n",
    "    'TypeScript': len(ts_configs),\n",
    "    'Docker': 1 if config_analysis.get('docker/docker-compose.yml', {}).get('exists', False) else 0,\n",
    "    'Prisma': 1 if config_analysis.get('server/prisma/schema.prisma', {}).get('exists', False) else 0,\n",
    "    'Node.js': len(package_files)\n",
    "}\n",
    "\n",
    "tech_names = list(tech_stack.keys())\n",
    "tech_presence = list(tech_stack.values())\n",
    "colors = ['#61DAFB', '#3178C6', '#2496ED', '#2D3748', '#68A063']\n",
    "\n",
    "plt.bar(tech_names, tech_presence, color=colors)\n",
    "plt.title('üõ†Ô∏è Stack Tecnol√≥gica')\n",
    "plt.ylabel('Presen√ßa/Configura√ß√µes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo das configura√ß√µes\n",
    "print(\"\\nüéØ RESUMO DAS CONFIGURA√á√ïES:\")\n",
    "print(\"=\" * 50)\n",
    "total_deps = sum(data.get('dependencies', 0) for data in package_files.values() if 'dependencies' in data)\n",
    "total_dev_deps = sum(data.get('dev_dependencies', 0) for data in package_files.values() if 'dev_dependencies' in data)\n",
    "total_scripts = sum(data.get('scripts', 0) for data in package_files.values() if 'scripts' in data)\n",
    "\n",
    "print(f\"üì¶ Total de depend√™ncias de produ√ß√£o: {total_deps}\")\n",
    "print(f\"üõ†Ô∏è Total de depend√™ncias de desenvolvimento: {total_dev_deps}\")\n",
    "print(f\"‚ö° Total de scripts dispon√≠veis: {total_scripts}\")\n",
    "print(f\"üìù Configura√ß√µes TypeScript: {len(ts_configs)}\")\n",
    "print(f\"üê≥ Docker configurado: {'‚úÖ' if config_analysis.get('docker/docker-compose.yml', {}).get('exists', False) else '‚ùå'}\")\n",
    "print(f\"üóÑÔ∏è Prisma ORM configurado: {'‚úÖ' if config_analysis.get('server/prisma/schema.prisma', {}).get('exists', False) else '‚ùå'}\")\n",
    "print(\"‚úÖ Configura√ß√µes bem estruturadas e completas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2090707c",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Estrutura do Frontend (Client)\n",
    "\n",
    "Vamos analisar detalhadamente a estrutura do frontend React com TypeScript, incluindo componentes, p√°ginas, contextos e servi√ßos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe57657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_frontend_structure():\n",
    "    \"\"\"\n",
    "    Analisa a estrutura do frontend React/TypeScript\n",
    "    \"\"\"\n",
    "    client_path = os.path.join(PROJECT_ROOT, 'client', 'src')\n",
    "    if not os.path.exists(client_path):\n",
    "        return {\"error\": \"Diret√≥rio client/src n√£o encontrado\"}\n",
    "    \n",
    "    frontend_structure = {}\n",
    "    \n",
    "    # Categorias de an√°lise\n",
    "    categories = {\n",
    "        'components': {\n",
    "            'description': 'Componentes React reutiliz√°veis',\n",
    "            'patterns': ['.tsx', '.jsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'pages': {\n",
    "            'description': 'P√°ginas principais da aplica√ß√£o',\n",
    "            'patterns': ['.tsx', '.jsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'hooks': {\n",
    "            'description': 'Hooks customizados',\n",
    "            'patterns': ['.ts', '.tsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'contexts': {\n",
    "            'description': 'Contextos React para estado global',\n",
    "            'patterns': ['.tsx', '.ts'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'stores': {\n",
    "            'description': 'Gerenciamento de estado',\n",
    "            'patterns': ['.ts', '.tsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'types': {\n",
    "            'description': 'Defini√ß√µes de tipos TypeScript',\n",
    "            'patterns': ['.ts', '.d.ts'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'utils': {\n",
    "            'description': 'Utilit√°rios e fun√ß√µes auxiliares',\n",
    "            'patterns': ['.ts', '.tsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'lib': {\n",
    "            'description': 'Bibliotecas e configura√ß√µes',\n",
    "            'patterns': ['.ts', '.tsx'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'styles': {\n",
    "            'description': 'Estilos e temas',\n",
    "            'patterns': ['.css', '.scss', '.less'],\n",
    "            'subdirs': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Analisa cada categoria\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(client_path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            structure, file_counts, total_files = analyze_directory_structure(category_path, max_depth=3)\n",
    "            \n",
    "            categories[category]['total_files'] = total_files\n",
    "            categories[category]['file_types'] = dict(file_counts)\n",
    "            categories[category]['subdirs'] = [k for k in structure.keys() if k != 'root']\n",
    "            \n",
    "            # An√°lise espec√≠fica de componentes\n",
    "            if category == 'components':\n",
    "                component_analysis = analyze_components(category_path)\n",
    "                categories[category]['component_details'] = component_analysis\n",
    "                \n",
    "        else:\n",
    "            categories[category]['total_files'] = 0\n",
    "            categories[category]['file_types'] = {}\n",
    "            categories[category]['subdirs'] = []\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def analyze_components(components_path):\n",
    "    \"\"\"\n",
    "    An√°lise espec√≠fica dos componentes React\n",
    "    \"\"\"\n",
    "    component_details = {\n",
    "        'ui_components': [],\n",
    "        'feature_components': [],\n",
    "        'layout_components': [],\n",
    "        'total_tsx_files': 0,\n",
    "        'component_categories': {}\n",
    "    }\n",
    "    \n",
    "    for root, dirs, files in os.walk(components_path):\n",
    "        relative_path = os.path.relpath(root, components_path)\n",
    "        \n",
    "        # Categoriza componentes por diret√≥rio\n",
    "        if relative_path != '.':\n",
    "            category_name = relative_path.split(os.sep)[0]\n",
    "            if category_name not in component_details['component_categories']:\n",
    "                component_details['component_categories'][category_name] = []\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(('.tsx', '.jsx')):\n",
    "                component_details['total_tsx_files'] += 1\n",
    "                \n",
    "                # Categoriza por tipo\n",
    "                if 'ui' in root.lower():\n",
    "                    component_details['ui_components'].append(file)\n",
    "                elif any(word in root.lower() for word in ['layout', 'wrapper']):\n",
    "                    component_details['layout_components'].append(file)\n",
    "                else:\n",
    "                    component_details['feature_components'].append(file)\n",
    "                \n",
    "                # Adiciona √† categoria por diret√≥rio\n",
    "                if relative_path != '.':\n",
    "                    category_name = relative_path.split(os.sep)[0]\n",
    "                    component_details['component_categories'][category_name].append(file)\n",
    "    \n",
    "    return component_details\n",
    "\n",
    "# Executa an√°lise do frontend\n",
    "print(\"‚öõÔ∏è Analisando estrutura do frontend...\")\n",
    "frontend_analysis = analyze_frontend_structure()\n",
    "\n",
    "if 'error' not in frontend_analysis:\n",
    "    # Cria DataFrame para visualiza√ß√£o\n",
    "    frontend_data = []\n",
    "    for category, data in frontend_analysis.items():\n",
    "        frontend_data.append({\n",
    "            'Categoria': category.title(),\n",
    "            'Descri√ß√£o': data['description'],\n",
    "            'Total de Arquivos': data['total_files'],\n",
    "            'Subdiret√≥rios': len(data['subdirs']),\n",
    "            'Principais Tipos': ', '.join([f\"{ext}({count})\" for ext, count in \n",
    "                                         sorted(data['file_types'].items(), \n",
    "                                               key=lambda x: x[1], reverse=True)[:3]])\n",
    "        })\n",
    "    \n",
    "    df_frontend = pd.DataFrame(frontend_data)\n",
    "    df_frontend = df_frontend[df_frontend['Total de Arquivos'] > 0]\n",
    "    \n",
    "    print(\"\\nüìä Estrutura do Frontend:\")\n",
    "    print(df_frontend.to_string(index=False))\n",
    "    \n",
    "    # An√°lise espec√≠fica de componentes\n",
    "    if 'components' in frontend_analysis and 'component_details' in frontend_analysis['components']:\n",
    "        comp_details = frontend_analysis['components']['component_details']\n",
    "        \n",
    "        print(f\"\\nüß© An√°lise Detalhada dos Componentes:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üì± Total de componentes TSX/JSX: {comp_details['total_tsx_files']}\")\n",
    "        print(f\"üé® Componentes de UI: {len(comp_details['ui_components'])}\")\n",
    "        print(f\"üèóÔ∏è Componentes de Layout: {len(comp_details['layout_components'])}\")\n",
    "        print(f\"‚öôÔ∏è Componentes de Funcionalidade: {len(comp_details['feature_components'])}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Categorias de Componentes:\")\n",
    "        for category, components in comp_details['component_categories'].items():\n",
    "            print(f\"   ‚Ä¢ {category}: {len(components)} componentes\")\n",
    "    \n",
    "    # Visualiza√ß√µes\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de arquivos por categoria\n",
    "    plt.subplot(2, 3, 1)\n",
    "    categories_with_files = df_frontend[df_frontend['Total de Arquivos'] > 0]\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Total de Arquivos'],\n",
    "            color=sns.color_palette(\"Set2\", len(categories_with_files)))\n",
    "    plt.title('üìä Arquivos por Categoria (Frontend)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 2: Complexidade por categoria (subdiret√≥rios)\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Subdiret√≥rios'],\n",
    "            color=sns.color_palette(\"viridis\", len(categories_with_files)))\n",
    "    plt.title('üîÑ Complexidade (Subdiret√≥rios)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Subdiret√≥rios')\n",
    "    \n",
    "    # Gr√°fico 3: Distribui√ß√£o de componentes por tipo\n",
    "    if 'components' in frontend_analysis and 'component_details' in frontend_analysis['components']:\n",
    "        plt.subplot(2, 3, 3)\n",
    "        comp_details = frontend_analysis['components']['component_details']\n",
    "        component_types = {\n",
    "            'UI': len(comp_details['ui_components']),\n",
    "            'Layout': len(comp_details['layout_components']),\n",
    "            'Feature': len(comp_details['feature_components'])\n",
    "        }\n",
    "        \n",
    "        plt.pie(component_types.values(), labels=component_types.keys(), \n",
    "                autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "        plt.title('üß© Tipos de Componentes')\n",
    "    \n",
    "    # Gr√°fico 4: Categorias de componentes\n",
    "    if 'components' in frontend_analysis and 'component_details' in frontend_analysis['components']:\n",
    "        plt.subplot(2, 3, 4)\n",
    "        comp_details = frontend_analysis['components']['component_details']\n",
    "        categories = comp_details['component_categories']\n",
    "        \n",
    "        if categories:\n",
    "            cat_names = list(categories.keys())[:6]  # Top 6 categorias\n",
    "            cat_counts = [len(categories[cat]) for cat in cat_names]\n",
    "            \n",
    "            plt.bar(cat_names, cat_counts, color=sns.color_palette(\"rocket\", len(cat_names)))\n",
    "            plt.title('üìÅ Componentes por Categoria')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('Quantidade')\n",
    "    \n",
    "    # Gr√°fico 5: Tipos de arquivo mais comuns\n",
    "    plt.subplot(2, 3, 5)\n",
    "    all_file_types = Counter()\n",
    "    for data in frontend_analysis.values():\n",
    "        if 'file_types' in data:\n",
    "            all_file_types.update(data['file_types'])\n",
    "    \n",
    "    if all_file_types:\n",
    "        top_types = dict(all_file_types.most_common(6))\n",
    "        plt.bar(top_types.keys(), top_types.values(),\n",
    "                color=sns.color_palette(\"plasma\", len(top_types)))\n",
    "        plt.title('üìã Tipos de Arquivo Mais Comuns')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Quantidade')\n",
    "    \n",
    "    # Gr√°fico 6: Arquitetura React moderna\n",
    "    plt.subplot(2, 3, 6)\n",
    "    react_features = {\n",
    "        'Hooks': frontend_analysis.get('hooks', {}).get('total_files', 0),\n",
    "        'Contexts': frontend_analysis.get('contexts', {}).get('total_files', 0),\n",
    "        'Stores': frontend_analysis.get('stores', {}).get('total_files', 0),\n",
    "        'Types': frontend_analysis.get('types', {}).get('total_files', 0)\n",
    "    }\n",
    "    \n",
    "    feature_names = list(react_features.keys())\n",
    "    feature_counts = list(react_features.values())\n",
    "    \n",
    "    plt.bar(feature_names, feature_counts, color=['#61DAFB', '#FF6B35', '#F7931E', '#FFD23F'])\n",
    "    plt.title('‚öõÔ∏è Recursos React Modernos')\n",
    "    plt.ylabel('Quantidade de Arquivos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumo do frontend\n",
    "    print(\"\\nüéØ RESUMO DO FRONTEND:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_frontend_files = sum(data.get('total_files', 0) for data in frontend_analysis.values())\n",
    "    components_count = frontend_analysis.get('components', {}).get('total_files', 0)\n",
    "    pages_count = frontend_analysis.get('pages', {}).get('total_files', 0)\n",
    "    \n",
    "    print(f\"üìÅ Total de arquivos no frontend: {total_frontend_files}\")\n",
    "    print(f\"üß© Componentes React: {components_count}\")\n",
    "    print(f\"üìÑ P√°ginas da aplica√ß√£o: {pages_count}\")\n",
    "    print(f\"üé£ Hooks customizados: {frontend_analysis.get('hooks', {}).get('total_files', 0)}\")\n",
    "    print(f\"üîÑ Contextos React: {frontend_analysis.get('contexts', {}).get('total_files', 0)}\")\n",
    "    print(f\"üè™ Stores de estado: {frontend_analysis.get('stores', {}).get('total_files', 0)}\")\n",
    "    print(f\"üìù Defini√ß√µes de tipos: {frontend_analysis.get('types', {}).get('total_files', 0)}\")\n",
    "    print(f\"üé® Arquivos de estilo: {frontend_analysis.get('styles', {}).get('total_files', 0)}\")\n",
    "    print(\"‚úÖ Frontend bem organizado seguindo boas pr√°ticas React!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Erro na an√°lise do frontend: {frontend_analysis['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaf20a",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Estrutura do Backend (Server)\n",
    "\n",
    "Vamos analisar a estrutura modular do backend Node.js com Express e TypeScript, incluindo controllers, services, DTOs e middleware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_backend_structure():\n",
    "    \"\"\"\n",
    "    Analisa a estrutura modular do backend Node.js/Express\n",
    "    \"\"\"\n",
    "    server_path = os.path.join(PROJECT_ROOT, 'server', 'src')\n",
    "    if not os.path.exists(server_path):\n",
    "        return {\"error\": \"Diret√≥rio server/src n√£o encontrado\"}\n",
    "    \n",
    "    backend_structure = {}\n",
    "    \n",
    "    # Categorias de an√°lise do backend\n",
    "    categories = {\n",
    "        'modules': {\n",
    "            'description': 'M√≥dulos por dom√≠nio de neg√≥cio',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'shared': {\n",
    "            'description': 'C√≥digo compartilhado (decorators, filters, pipes)',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'routes': {\n",
    "            'description': 'Defini√ß√µes de rotas da API',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'middleware': {\n",
    "            'description': 'Middlewares customizados',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'services': {\n",
    "            'description': 'Servi√ßos de neg√≥cio',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'utils': {\n",
    "            'description': 'Utilit√°rios e helpers',\n",
    "            'patterns': ['.ts', '.js'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'types': {\n",
    "            'description': 'Defini√ß√µes de tipos TypeScript',\n",
    "            'patterns': ['.ts', '.d.ts'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'config': {\n",
    "            'description': 'Configura√ß√µes da aplica√ß√£o',\n",
    "            'patterns': ['.ts', '.js', '.json'],\n",
    "            'subdirs': []\n",
    "        },\n",
    "        'prisma': {\n",
    "            'description': 'Configura√ß√µes e schema do Prisma ORM',\n",
    "            'patterns': ['.ts', '.prisma'],\n",
    "            'subdirs': []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # An√°lise espec√≠fica dos m√≥dulos\n",
    "    modules_analysis = analyze_modules_structure(server_path)\n",
    "    \n",
    "    # Analisa cada categoria\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(server_path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            structure, file_counts, total_files = analyze_directory_structure(category_path, max_depth=4)\n",
    "            \n",
    "            categories[category]['total_files'] = total_files\n",
    "            categories[category]['file_types'] = dict(file_counts)\n",
    "            categories[category]['subdirs'] = [k for k in structure.keys() if k != 'root']\n",
    "            \n",
    "            # An√°lise espec√≠fica por categoria\n",
    "            if category == 'modules':\n",
    "                categories[category]['modules_details'] = modules_analysis\n",
    "        else:\n",
    "            categories[category]['total_files'] = 0\n",
    "            categories[category]['file_types'] = {}\n",
    "            categories[category]['subdirs'] = []\n",
    "    \n",
    "    # An√°lise de arquivos na raiz do server/src\n",
    "    root_files = []\n",
    "    for file in os.listdir(server_path):\n",
    "        if os.path.isfile(os.path.join(server_path, file)):\n",
    "            root_files.append(file)\n",
    "    \n",
    "    categories['root_files'] = {\n",
    "        'description': 'Arquivos principais na raiz',\n",
    "        'files': root_files,\n",
    "        'total_files': len(root_files)\n",
    "    }\n",
    "    \n",
    "    return categories\n",
    "\n",
    "def analyze_modules_structure(server_path):\n",
    "    \"\"\"\n",
    "    An√°lise espec√≠fica da estrutura de m√≥dulos\n",
    "    \"\"\"\n",
    "    modules_path = os.path.join(server_path, 'modules')\n",
    "    if not os.path.exists(modules_path):\n",
    "        return {'error': 'Diret√≥rio modules n√£o encontrado'}\n",
    "    \n",
    "    modules_details = {\n",
    "        'total_modules': 0,\n",
    "        'modules_list': [],\n",
    "        'pattern_compliance': {},\n",
    "        'total_controllers': 0,\n",
    "        'total_services': 0,\n",
    "        'total_dtos': 0\n",
    "    }\n",
    "    \n",
    "    # Padr√£o esperado para cada m√≥dulo\n",
    "    expected_patterns = ['controllers', 'services', 'dtos']\n",
    "    \n",
    "    for item in os.listdir(modules_path):\n",
    "        module_path = os.path.join(modules_path, item)\n",
    "        if os.path.isdir(module_path):\n",
    "            modules_details['total_modules'] += 1\n",
    "            \n",
    "            module_info = {\n",
    "                'name': item,\n",
    "                'has_controllers': False,\n",
    "                'has_services': False,\n",
    "                'has_dtos': False,\n",
    "                'has_strategies': False,\n",
    "                'total_files': 0,\n",
    "                'subdirs': []\n",
    "            }\n",
    "            \n",
    "            # Verifica subdiret√≥rios e arquivos\n",
    "            for subitem in os.listdir(module_path):\\n                subitem_path = os.path.join(module_path, subitem)\\n                \\n                if os.path.isdir(subitem_path):\\n                    module_info['subdirs'].append(subitem)\\n                    \\n                    if subitem == 'controllers':\\n                        module_info['has_controllers'] = True\\n                        controllers_count = len([f for f in os.listdir(subitem_path) \\n                                                if f.endswith(('.ts', '.js'))])\\n                        modules_details['total_controllers'] += controllers_count\\n                        \\n                    elif subitem == 'services':\\n                        module_info['has_services'] = True\\n                        services_count = len([f for f in os.listdir(subitem_path) \\n                                            if f.endswith(('.ts', '.js'))])\\n                        modules_details['total_services'] += services_count\\n                        \\n                    elif subitem == 'dtos':\\n                        module_info['has_dtos'] = True\\n                        dtos_count = len([f for f in os.listdir(subitem_path) \\n                                        if f.endswith(('.ts', '.js'))])\\n                        modules_details['total_dtos'] += dtos_count\\n                        \\n                    elif subitem == 'strategies':\\n                        module_info['has_strategies'] = True\\n                \\n                elif os.path.isfile(subitem_path) and subitem.endswith(('.ts', '.js')):\\n                    module_info['total_files'] += 1\\n            \\n            # Calcula compliance com o padr√£o arquitetural\\n            compliance_score = sum([\\n                module_info['has_controllers'],\\n                module_info['has_services'], \\n                module_info['has_dtos']\\n            ])\\n            module_info['compliance_score'] = compliance_score / 3 * 100\\n            \\n            modules_details['modules_list'].append(module_info)\\n    \\n    return modules_details\n",
    "\n",
    "# Executa an√°lise do backend\n",
    "print(\"üñ•Ô∏è Analisando estrutura do backend...\")\n",
    "backend_analysis = analyze_backend_structure()\n",
    "\n",
    "if 'error' not in backend_analysis:\n",
    "    # Cria DataFrame para visualiza√ß√£o\n",
    "    backend_data = []\n",
    "    for category, data in backend_analysis.items():\n",
    "        if category != 'root_files' and 'total_files' in data:\n",
    "            backend_data.append({\n",
    "                'Categoria': category.title(),\n",
    "                'Descri√ß√£o': data['description'],\n",
    "                'Total de Arquivos': data['total_files'],\n",
    "                'Subdiret√≥rios': len(data['subdirs']),\n",
    "                'Principais Tipos': ', '.join([f\"{ext}({count})\" for ext, count in \n",
    "                                             sorted(data['file_types'].items(), \n",
    "                                                   key=lambda x: x[1], reverse=True)[:3]])\n",
    "            })\n",
    "    \n",
    "    df_backend = pd.DataFrame(backend_data)\n",
    "    df_backend = df_backend[df_backend['Total de Arquivos'] > 0]\n",
    "    \n",
    "    print(\"\\nüìä Estrutura do Backend:\")\n",
    "    print(df_backend.to_string(index=False))\n",
    "    \n",
    "    # An√°lise espec√≠fica dos m√≥dulos\n",
    "    if 'modules' in backend_analysis and 'modules_details' in backend_analysis['modules']:\n",
    "        modules_details = backend_analysis['modules']['modules_details']\\n        \\n        if 'error' not in modules_details:\\n            print(f\"\\\\nüèóÔ∏è An√°lise Detalhada dos M√≥dulos:\")\n",
    "            print(\"=\" * 50)\n",
    "            print(f\"üì¶ Total de m√≥dulos: {modules_details['total_modules']}\")\n",
    "            print(f\"üéÆ Total de controllers: {modules_details['total_controllers']}\")\n",
    "            print(f\"‚öôÔ∏è Total de services: {modules_details['total_services']}\")\n",
    "            print(f\"üìã Total de DTOs: {modules_details['total_dtos']}\")\n",
    "            \n",
    "            print(f\"\\\\nüìÅ M√≥dulos Identificados:\")\n",
    "            for module in modules_details['modules_list']:\n",
    "                compliance_icon = \"‚úÖ\" if module['compliance_score'] >= 66 else \"‚ö†Ô∏è\" if module['compliance_score'] >= 33 else \"‚ùå\"\n",
    "                print(f\"   {compliance_icon} {module['name']}: Controllers({module['has_controllers']}) | \" +\n",
    "                      f\"Services({module['has_services']}) | DTOs({module['has_dtos']}) | \" +\n",
    "                      f\"Compliance: {module['compliance_score']:.0f}%\")\n",
    "    \n",
    "    # An√°lise dos arquivos na raiz\n",
    "    if 'root_files' in backend_analysis:\n",
    "        root_files = backend_analysis['root_files']['files']\n",
    "        print(f\"\\\\nüìÑ Arquivos na Raiz do Backend ({len(root_files)}):\")\n",
    "        for file in root_files:\n",
    "            print(f\"   ‚Ä¢ {file}\")\n",
    "    \n",
    "    # Visualiza√ß√µes\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de arquivos por categoria\n",
    "    plt.subplot(2, 3, 1)\n",
    "    categories_with_files = df_backend[df_backend['Total de Arquivos'] > 0]\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Total de Arquivos'],\n",
    "            color=sns.color_palette(\"Set1\", len(categories_with_files)))\n",
    "    plt.title('üìä Arquivos por Categoria (Backend)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 2: Compliance dos m√≥dulos\n",
    "    if 'modules' in backend_analysis and 'modules_details' in backend_analysis['modules']:\n",
    "        modules_details = backend_analysis['modules']['modules_details']\n",
    "        if 'error' not in modules_details and modules_details['modules_list']:\n",
    "            plt.subplot(2, 3, 2)\n",
    "            module_names = [m['name'] for m in modules_details['modules_list']]\n",
    "            compliance_scores = [m['compliance_score'] for m in modules_details['modules_list']]\n",
    "            \n",
    "            colors = ['green' if score >= 66 else 'orange' if score >= 33 else 'red' \n",
    "                     for score in compliance_scores]\n",
    "            \n",
    "            plt.bar(module_names, compliance_scores, color=colors)\n",
    "            plt.title('üìê Compliance Arquitetural dos M√≥dulos')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('Compliance (%)')\n",
    "            plt.axhline(y=66, color='green', linestyle='--', alpha=0.7, label='Bom (66%)')\n",
    "            plt.axhline(y=33, color='orange', linestyle='--', alpha=0.7, label='Regular (33%)')\n",
    "            plt.legend()\n",
    "    \n",
    "    # Gr√°fico 3: Distribui√ß√£o de componentes dos m√≥dulos\n",
    "    if 'modules' in backend_analysis and 'modules_details' in backend_analysis['modules']:\n",
    "        modules_details = backend_analysis['modules']['modules_details']\n",
    "        if 'error' not in modules_details:\n",
    "            plt.subplot(2, 3, 3)\n",
    "            components = {\n",
    "                'Controllers': modules_details['total_controllers'],\n",
    "                'Services': modules_details['total_services'],\n",
    "                'DTOs': modules_details['total_dtos']\n",
    "            }\n",
    "            \n",
    "            plt.pie(components.values(), labels=components.keys(), \n",
    "                    autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "            plt.title('üß© Distribui√ß√£o de Componentes')\n",
    "    \n",
    "    # Gr√°fico 4: Complexidade por categoria\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Subdiret√≥rios'],\n",
    "            color=sns.color_palette(\"viridis\", len(categories_with_files)))\n",
    "    plt.title('üîÑ Complexidade (Subdiret√≥rios)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Subdiret√≥rios')\n",
    "    \n",
    "    # Gr√°fico 5: Tipos de arquivo mais comuns\n",
    "    plt.subplot(2, 3, 5)\n",
    "    all_file_types = Counter()\n",
    "    for data in backend_analysis.values():\n",
    "        if isinstance(data, dict) and 'file_types' in data:\n",
    "            all_file_types.update(data['file_types'])\n",
    "    \n",
    "    if all_file_types:\n",
    "        top_types = dict(all_file_types.most_common(6))\n",
    "        plt.bar(top_types.keys(), top_types.values(),\n",
    "                color=sns.color_palette(\"plasma\", len(top_types)))\n",
    "        plt.title('üìã Tipos de Arquivo Mais Comuns')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Quantidade')\n",
    "    \n",
    "    # Gr√°fico 6: Arquitetura Node.js moderna\n",
    "    plt.subplot(2, 3, 6)\n",
    "    nodejs_features = {\n",
    "        'Routes': backend_analysis.get('routes', {}).get('total_files', 0),\n",
    "        'Middleware': backend_analysis.get('middleware', {}).get('total_files', 0),\n",
    "        'Services': backend_analysis.get('services', {}).get('total_files', 0),\n",
    "        'Types': backend_analysis.get('types', {}).get('total_files', 0)\n",
    "    }\n",
    "    \n",
    "    feature_names = list(nodejs_features.keys())\n",
    "    feature_counts = list(nodejs_features.values())\n",
    "    \n",
    "    plt.bar(feature_names, feature_counts, color=['#68A063', '#3C873A', '#215732', '#0D2818'])\n",
    "    plt.title('üñ•Ô∏è Recursos Node.js')\n",
    "    plt.ylabel('Quantidade de Arquivos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumo do backend\n",
    "    print(\"\\\\nüéØ RESUMO DO BACKEND:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_backend_files = sum(data.get('total_files', 0) for data in backend_analysis.values() \n",
    "                            if isinstance(data, dict) and 'total_files' in data)\n",
    "    \n",
    "    print(f\"üìÅ Total de arquivos no backend: {total_backend_files}\")\n",
    "    print(f\"üèóÔ∏è M√≥dulos de dom√≠nio: {backend_analysis.get('modules', {}).get('total_files', 0)}\")\n",
    "    print(f\"üîÑ C√≥digo compartilhado: {backend_analysis.get('shared', {}).get('total_files', 0)}\")\n",
    "    print(f\"üõ£Ô∏è Rotas da API: {backend_analysis.get('routes', {}).get('total_files', 0)}\")\n",
    "    print(f\"‚öôÔ∏è Middlewares: {backend_analysis.get('middleware', {}).get('total_files', 0)}\")\n",
    "    print(f\"üóÑÔ∏è Prisma/Database: {backend_analysis.get('prisma', {}).get('total_files', 0)}\")\n",
    "    print(f\"üìù Defini√ß√µes de tipos: {backend_analysis.get('types', {}).get('total_files', 0)}\")\n",
    "    \n",
    "    if 'modules' in backend_analysis and 'modules_details' in backend_analysis['modules']:\n",
    "        modules_details = backend_analysis['modules']['modules_details']\n",
    "        if 'error' not in modules_details:\n",
    "            avg_compliance = sum(m['compliance_score'] for m in modules_details['modules_list']) / len(modules_details['modules_list']) if modules_details['modules_list'] else 0\n",
    "            print(f\"üìê Compliance arquitetural m√©dio: {avg_compliance:.1f}%\")\n",
    "    \n",
    "    print(\"‚úÖ Backend bem estruturado seguindo arquitetura modular!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Erro na an√°lise do backend: {backend_analysis['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e9294",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Sistema de IA e Machine Learning\n",
    "\n",
    "Vamos examinar o diret√≥rio de IA, analisar datasets, modelos e notebooks de treinamento para processamento inteligente de extratos banc√°rios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ai_system():\n",
    "    \"\"\"\n",
    "    Analisa o sistema de IA e Machine Learning\n",
    "    \"\"\"\n",
    "    ia_path = os.path.join(PROJECT_ROOT, 'ia')\n",
    "    if not os.path.exists(ia_path):\n",
    "        return {\"error\": \"Diret√≥rio 'ia' n√£o encontrado\"}\n",
    "    \n",
    "    ai_structure = {\n",
    "        'datasets': {\n",
    "            'description': 'Conjuntos de dados para treinamento',\n",
    "            'subdirs': {},\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        },\n",
    "        'models': {\n",
    "            'description': 'Modelos de ML treinados',\n",
    "            'subdirs': {},\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        },\n",
    "        'notebooks': {\n",
    "            'description': 'Jupyter Notebooks para an√°lise e treinamento',\n",
    "            'subdirs': {},\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        },\n",
    "        'src': {\n",
    "            'description': 'C√≥digo fonte dos algoritmos de IA',\n",
    "            'subdirs': {},\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # An√°lise de cada subdiret√≥rio principal\n",
    "    for main_dir in ai_structure.keys():\n",
    "        dir_path = os.path.join(ia_path, main_dir)\n",
    "        if os.path.exists(dir_path):\n",
    "            structure, file_counts, total_files = analyze_directory_structure(dir_path, max_depth=3)\n",
    "            \n",
    "            ai_structure[main_dir]['total_files'] = total_files\n",
    "            ai_structure[main_dir]['file_types'] = dict(file_counts)\n",
    "            ai_structure[main_dir]['subdirs'] = {k: v for k, v in structure.items() if k != 'root'}\n",
    "            \n",
    "            # An√°lise espec√≠fica dos datasets\n",
    "            if main_dir == 'datasets':\n",
    "                datasets_analysis = analyze_datasets(dir_path)\n",
    "                ai_structure[main_dir]['datasets_details'] = datasets_analysis\n",
    "                \n",
    "            # An√°lise espec√≠fica do c√≥digo fonte\n",
    "            elif main_dir == 'src':\n",
    "                src_analysis = analyze_ai_source_code(dir_path)\n",
    "                ai_structure[main_dir]['src_details'] = src_analysis\n",
    "    \n",
    "    # An√°lise dos arquivos na raiz do diret√≥rio ia\n",
    "    root_files = []\n",
    "    for file in os.listdir(ia_path):\n",
    "        if os.path.isfile(os.path.join(ia_path, file)):\n",
    "            root_files.append(file)\n",
    "    \n",
    "    ai_structure['root_files'] = root_files\n",
    "    \n",
    "    return ai_structure\n",
    "\n",
    "def analyze_datasets(datasets_path):\n",
    "    \"\"\"\n",
    "    An√°lise espec√≠fica dos datasets\n",
    "    \"\"\"\n",
    "    datasets_info = {\n",
    "        'annotation_files': [],\n",
    "        'pdf_files': [],\n",
    "        'txt_files': [],\n",
    "        'csv_files': [],\n",
    "        'total_annotations': 0,\n",
    "        'data_categories': {}\n",
    "    }\n",
    "    \n",
    "    for root, dirs, files in os.walk(datasets_path):\n",
    "        relative_path = os.path.relpath(root, datasets_path)\n",
    "        \n",
    "        for file in files:\n",
    "            file_lower = file.lower()\n",
    "            \n",
    "            if file.endswith('.json') and 'annotations' in root:\n",
    "                datasets_info['annotation_files'].append(file)\n",
    "                datasets_info['total_annotations'] += 1\n",
    "                \n",
    "            elif file.endswith('.pdf'):\n",
    "                datasets_info['pdf_files'].append(file)\n",
    "                \n",
    "            elif file.endswith('.txt'):\n",
    "                datasets_info['txt_files'].append(file)\n",
    "                \n",
    "            elif file.endswith('.csv'):\n",
    "                datasets_info['csv_files'].append(file)\n",
    "            \n",
    "            # Categoriza√ß√£o por tipo de banco\n",
    "            if 'bradesco' in file_lower or 'bb' in file_lower:\n",
    "                if 'Bradesco/BB' not in datasets_info['data_categories']:\n",
    "                    datasets_info['data_categories']['Bradesco/BB'] = 0\n",
    "                datasets_info['data_categories']['Bradesco/BB'] += 1\n",
    "                \n",
    "            elif 'nubank' in file_lower:\n",
    "                if 'Nubank' not in datasets_info['data_categories']:\n",
    "                    datasets_info['data_categories']['Nubank'] = 0\n",
    "                datasets_info['data_categories']['Nubank'] += 1\n",
    "                \n",
    "            elif 'comprovante' in file_lower:\n",
    "                if 'Comprovantes' not in datasets_info['data_categories']:\n",
    "                    datasets_info['data_categories']['Comprovantes'] = 0\n",
    "                datasets_info['data_categories']['Comprovantes'] += 1\n",
    "    \n",
    "    return datasets_info\n",
    "\n",
    "def analyze_ai_source_code(src_path):\n",
    "    \"\"\"\n",
    "    An√°lise do c√≥digo fonte de IA\n",
    "    \"\"\"\n",
    "    src_info = {\n",
    "        'python_files': [],\n",
    "        'total_python_files': 0,\n",
    "        'ml_libraries': set(),\n",
    "        'functions_detected': []\n",
    "    }\n",
    "    \n",
    "    # Bibliotecas de ML comuns para detectar\n",
    "    ml_keywords = [\n",
    "        'pandas', 'numpy', 'sklearn', 'tensorflow', 'pytorch', 'keras',\n",
    "        'matplotlib', 'seaborn', 'cv2', 'opencv', 'transformers', 'spacy',\n",
    "        'nltk', 'scikit-learn', 'xgboost', 'lightgbm'\n",
    "    ]\n",
    "    \n",
    "    for file in os.listdir(src_path):\n",
    "        if file.endswith('.py'):\n",
    "            src_info['python_files'].append(file)\n",
    "            src_info['total_python_files'] += 1\n",
    "            \n",
    "            # Analisa o conte√∫do dos arquivos Python\n",
    "            file_path = os.path.join(src_path, file)\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                # Detecta imports de bibliotecas ML\n",
    "                for lib in ml_keywords:\n",
    "                    if f'import {lib}' in content or f'from {lib}' in content:\n",
    "                        src_info['ml_libraries'].add(lib)\n",
    "                \n",
    "                # Detecta defini√ß√µes de fun√ß√µes\n",
    "                function_matches = re.findall(r'def\\\\s+(\\\\w+)\\\\s*\\\\(', content)\n",
    "                src_info['functions_detected'].extend(function_matches)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao ler {file}: {e}\")\n",
    "    \n",
    "    return src_info\n",
    "\n",
    "# Executa an√°lise do sistema de IA\n",
    "print(\"ü§ñ Analisando sistema de IA e Machine Learning...\")\n",
    "ai_analysis = analyze_ai_system()\n",
    "\n",
    "if 'error' not in ai_analysis:\n",
    "    # Cria DataFrame para visualiza√ß√£o\n",
    "    ai_data = []\n",
    "    for category, data in ai_analysis.items():\n",
    "        if category != 'root_files' and isinstance(data, dict) and 'total_files' in data:\n",
    "            ai_data.append({\n",
    "                'Categoria': category.title(),\n",
    "                'Descri√ß√£o': data['description'],\n",
    "                'Total de Arquivos': data['total_files'],\n",
    "                'Subdiret√≥rios': len(data['subdirs']),\n",
    "                'Principais Tipos': ', '.join([f\"{ext}({count})\" for ext, count in \n",
    "                                             sorted(data['file_types'].items(), \n",
    "                                                   key=lambda x: x[1], reverse=True)[:3]])\n",
    "            })\n",
    "    \n",
    "    df_ai = pd.DataFrame(ai_data)\n",
    "    df_ai = df_ai[df_ai['Total de Arquivos'] > 0]\n",
    "    \n",
    "    print(\"\\\\nüìä Estrutura do Sistema de IA:\")\n",
    "    print(df_ai.to_string(index=False))\n",
    "    \n",
    "    # An√°lise espec√≠fica dos datasets\n",
    "    if 'datasets' in ai_analysis and 'datasets_details' in ai_analysis['datasets']:\n",
    "        datasets_details = ai_analysis['datasets']['datasets_details']\n",
    "        \n",
    "        print(f\"\\\\nüìö An√°lise Detalhada dos Datasets:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìù Arquivos de anota√ß√£o (JSON): {len(datasets_details['annotation_files'])}\")\n",
    "        print(f\"üìÑ Arquivos PDF: {len(datasets_details['pdf_files'])}\")\n",
    "        print(f\"üìã Arquivos TXT: {len(datasets_details['txt_files'])}\")\n",
    "        print(f\"üìä Arquivos CSV: {len(datasets_details['csv_files'])}\")\n",
    "        print(f\"üè∑Ô∏è Total de anota√ß√µes: {datasets_details['total_annotations']}\")\n",
    "        \n",
    "        print(f\"\\\\nüè¶ Categorias de Dados:\")\n",
    "        for category, count in datasets_details['data_categories'].items():\n",
    "            print(f\"   ‚Ä¢ {category}: {count} arquivos\")\n",
    "    \n",
    "    # An√°lise espec√≠fica do c√≥digo fonte\n",
    "    if 'src' in ai_analysis and 'src_details' in ai_analysis['src']:\n",
    "        src_details = ai_analysis['src']['src_details']\n",
    "        \n",
    "        print(f\"\\\\nüíª An√°lise do C√≥digo Fonte de IA:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üêç Arquivos Python: {src_details['total_python_files']}\")\n",
    "        print(f\"üìö Bibliotecas ML detectadas: {', '.join(sorted(src_details['ml_libraries']))}\")\n",
    "        print(f\"‚öôÔ∏è Fun√ß√µes identificadas: {len(src_details['functions_detected'])}\")\n",
    "        \n",
    "        if src_details['functions_detected']:\n",
    "            print(f\"\\\\nüîß Principais Fun√ß√µes:\")\n",
    "            for func in src_details['functions_detected'][:10]:  # Top 10\n",
    "                print(f\"   ‚Ä¢ {func}()\")\n",
    "    \n",
    "    # An√°lise dos arquivos na raiz\n",
    "    if 'root_files' in ai_analysis:\n",
    "        root_files = ai_analysis['root_files']\n",
    "        print(f\"\\\\nüìÑ Arquivos na Raiz do IA ({len(root_files)}):\")\n",
    "        for file in root_files:\n",
    "            print(f\"   ‚Ä¢ {file}\")\n",
    "    \n",
    "    # Visualiza√ß√µes\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de arquivos por categoria de IA\n",
    "    plt.subplot(2, 3, 1)\n",
    "    categories_with_files = df_ai[df_ai['Total de Arquivos'] > 0]\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Total de Arquivos'],\n",
    "            color=sns.color_palette(\"rocket\", len(categories_with_files)))\n",
    "    plt.title('ü§ñ Distribui√ß√£o de Arquivos (IA)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 2: Tipos de datasets\n",
    "    if 'datasets' in ai_analysis and 'datasets_details' in ai_analysis['datasets']:\n",
    "        plt.subplot(2, 3, 2)\n",
    "        datasets_details = ai_analysis['datasets']['datasets_details']\n",
    "        dataset_types = {\n",
    "            'JSON (Annotations)': len(datasets_details['annotation_files']),\n",
    "            'PDF': len(datasets_details['pdf_files']),\n",
    "            'TXT': len(datasets_details['txt_files']),\n",
    "            'CSV': len(datasets_details['csv_files'])\n",
    "        }\n",
    "        \n",
    "        # Remove tipos com zero arquivos\n",
    "        dataset_types = {k: v for k, v in dataset_types.items() if v > 0}\n",
    "        \n",
    "        if dataset_types:\n",
    "            plt.pie(dataset_types.values(), labels=dataset_types.keys(), \n",
    "                    autopct='%1.1f%%', startangle=90, colors=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
    "            plt.title('üìö Tipos de Datasets')\n",
    "    \n",
    "    # Gr√°fico 3: Categorias de dados banc√°rios\n",
    "    if 'datasets' in ai_analysis and 'datasets_details' in ai_analysis['datasets']:\n",
    "        plt.subplot(2, 3, 3)\n",
    "        datasets_details = ai_analysis['datasets']['datasets_details']\n",
    "        data_categories = datasets_details['data_categories']\n",
    "        \n",
    "        if data_categories:\n",
    "            plt.bar(data_categories.keys(), data_categories.values(),\n",
    "                    color=sns.color_palette(\"viridis\", len(data_categories)))\n",
    "            plt.title('üè¶ Dados por Institui√ß√£o')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.ylabel('Quantidade de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 4: Bibliotecas ML utilizadas\n",
    "    if 'src' in ai_analysis and 'src_details' in ai_analysis['src']:\n",
    "        plt.subplot(2, 3, 4)\n",
    "        src_details = ai_analysis['src']['src_details']\n",
    "        ml_libs = list(src_details['ml_libraries'])\n",
    "        \n",
    "        if ml_libs:\n",
    "            lib_counts = [1] * len(ml_libs)  # Cada lib aparece uma vez\n",
    "            plt.bar(range(len(ml_libs)), lib_counts, \n",
    "                    color=sns.color_palette(\"plasma\", len(ml_libs)))\n",
    "            plt.title('üìö Bibliotecas ML Utilizadas')\n",
    "            plt.xticks(range(len(ml_libs)), ml_libs, rotation=45)\n",
    "            plt.ylabel('Presen√ßa')\n",
    "    \n",
    "    # Gr√°fico 5: Complexidade por categoria\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.bar(categories_with_files['Categoria'], categories_with_files['Subdiret√≥rios'],\n",
    "            color=sns.color_palette(\"coolwarm\", len(categories_with_files)))\n",
    "    plt.title('üîÑ Complexidade (Subdiret√≥rios)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('N√∫mero de Subdiret√≥rios')\n",
    "    \n",
    "    # Gr√°fico 6: Pipeline de ML\n",
    "    plt.subplot(2, 3, 6)\n",
    "    ml_pipeline = {\n",
    "        'Datasets': ai_analysis.get('datasets', {}).get('total_files', 0),\n",
    "        'Source Code': ai_analysis.get('src', {}).get('total_files', 0),\n",
    "        'Models': ai_analysis.get('models', {}).get('total_files', 0),\n",
    "        'Notebooks': ai_analysis.get('notebooks', {}).get('total_files', 0)\n",
    "    }\n",
    "    \n",
    "    pipeline_names = list(ml_pipeline.keys())\n",
    "    pipeline_counts = list(ml_pipeline.values())\n",
    "    \n",
    "    plt.bar(pipeline_names, pipeline_counts, color=['#FF9999', '#66B2FF', '#99FF99', '#FFCC99'])\n",
    "    plt.title('üîÑ Pipeline de Machine Learning')\n",
    "    plt.ylabel('Quantidade de Arquivos')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumo do sistema de IA\n",
    "    print(\"\\\\nüéØ RESUMO DO SISTEMA DE IA:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_ai_files = sum(data.get('total_files', 0) for data in ai_analysis.values() \n",
    "                        if isinstance(data, dict) and 'total_files' in data)\n",
    "    \n",
    "    print(f\"üìÅ Total de arquivos de IA: {total_ai_files}\")\n",
    "    print(f\"üìö Datasets dispon√≠veis: {ai_analysis.get('datasets', {}).get('total_files', 0)}\")\n",
    "    print(f\"üíª C√≥digo fonte Python: {ai_analysis.get('src', {}).get('total_files', 0)}\")\n",
    "    print(f\"ü§ñ Modelos treinados: {ai_analysis.get('models', {}).get('total_files', 0)}\")\n",
    "    print(f\"üìì Jupyter Notebooks: {ai_analysis.get('notebooks', {}).get('total_files', 0)}\")\n",
    "    \n",
    "    if 'datasets' in ai_analysis and 'datasets_details' in ai_analysis['datasets']:\n",
    "        datasets_details = ai_analysis['datasets']['datasets_details']\n",
    "        print(f\"üè∑Ô∏è Anota√ß√µes para treinamento: {datasets_details['total_annotations']}\")\n",
    "        print(f\"üè¶ Institui√ß√µes banc√°rias: {len(datasets_details['data_categories'])}\")\n",
    "    \n",
    "    if 'src' in ai_analysis and 'src_details' in ai_analysis['src']:\n",
    "        src_details = ai_analysis['src']['src_details']\n",
    "        print(f\"üìö Bibliotecas ML integradas: {len(src_details['ml_libraries'])}\")\n",
    "    \n",
    "    print(\"‚úÖ Sistema de IA bem estruturado para processamento de extratos!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Erro na an√°lise do sistema de IA: {ai_analysis['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4241f",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Scripts e Automa√ß√£o\n",
    "\n",
    "Vamos catalogar e analisar os scripts de desenvolvimento, testing e deploy, criando uma matriz de funcionalidades automatizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scripts_automation():\n",
    "    \"\"\"\n",
    "    Analisa scripts de automa√ß√£o e desenvolvimento\n",
    "    \"\"\"\n",
    "    scripts_path = os.path.join(PROJECT_ROOT, 'scripts')\n",
    "    if not os.path.exists(scripts_path):\n",
    "        return {\"error\": \"Diret√≥rio 'scripts' n√£o encontrado\"}\n",
    "    \n",
    "    scripts_structure = {\n",
    "        'development': {\n",
    "            'description': 'Scripts de desenvolvimento',\n",
    "            'scripts': [],\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        },\n",
    "        'testing': {\n",
    "            'description': 'Scripts de teste e valida√ß√£o',\n",
    "            'scripts': [],\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        },\n",
    "        'root_scripts': {\n",
    "            'description': 'Scripts na raiz',\n",
    "            'scripts': [],\n",
    "            'total_files': 0,\n",
    "            'file_types': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Categorias de scripts por funcionalidade\n",
    "    script_categories = {\n",
    "        'setup': [],\n",
    "        'start': [],\n",
    "        'test': [],\n",
    "        'deploy': [],\n",
    "        'validation': [],\n",
    "        'monitoring': [],\n",
    "        'database': [],\n",
    "        'security': [],\n",
    "        'tools': []\n",
    "    }\n",
    "    \n",
    "    # Analisa subdiret√≥rios\n",
    "    for category in ['development', 'testing']:\n",
    "        category_path = os.path.join(scripts_path, category)\n",
    "        if os.path.exists(category_path):\n",
    "            structure, file_counts, total_files = analyze_directory_structure(category_path, max_depth=2)\n",
    "            \n",
    "            scripts_structure[category]['total_files'] = total_files\n",
    "            scripts_structure[category]['file_types'] = dict(file_counts)\n",
    "            \n",
    "            # Lista todos os scripts\n",
    "            for file in os.listdir(category_path):\n",
    "                if os.path.isfile(os.path.join(category_path, file)):\n",
    "                    scripts_structure[category]['scripts'].append(file)\n",
    "                    \n",
    "                    # Categoriza por funcionalidade\n",
    "                    file_lower = file.lower()\n",
    "                    if any(keyword in file_lower for keyword in ['setup', 'install']):\n",
    "                        script_categories['setup'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['start', 'run']):\n",
    "                        script_categories['start'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['test', 'check', 'health']):\n",
    "                        script_categories['test'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['deploy', 'build']):\n",
    "                        script_categories['deploy'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['validate', 'verify']):\n",
    "                        script_categories['validation'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['monitor', 'status']):\n",
    "                        script_categories['monitoring'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['prisma', 'db', 'database']):\n",
    "                        script_categories['database'].append(f\"{category}/{file}\")\n",
    "                    elif any(keyword in file_lower for keyword in ['security', 'fix']):\n",
    "                        script_categories['security'].append(f\"{category}/{file}\")\n",
    "                    else:\n",
    "                        script_categories['tools'].append(f\"{category}/{file}\")\n",
    "    \n",
    "    # Analisa scripts na raiz\n",
    "    for file in os.listdir(scripts_path):\n",
    "        file_path = os.path.join(scripts_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            scripts_structure['root_scripts']['scripts'].append(file)\n",
    "            scripts_structure['root_scripts']['total_files'] += 1\n",
    "            \n",
    "            ext = pathlib.Path(file).suffix.lower()\n",
    "            if not ext:\n",
    "                ext = 'no_extension'\n",
    "            if ext not in scripts_structure['root_scripts']['file_types']:\n",
    "                scripts_structure['root_scripts']['file_types'][ext] = 0\n",
    "            scripts_structure['root_scripts']['file_types'][ext] += 1\n",
    "            \n",
    "            # Categoriza scripts da raiz\n",
    "            file_lower = file.lower()\n",
    "            if any(keyword in file_lower for keyword in ['setup', 'install']):\n",
    "                script_categories['setup'].append(file)\n",
    "            elif any(keyword in file_lower for keyword in ['validate', 'verify']):\n",
    "                script_categories['validation'].append(file)\n",
    "            elif any(keyword in file_lower for keyword in ['security', 'fix']):\n",
    "                script_categories['security'].append(file)\n",
    "            elif any(keyword in file_lower for keyword in ['monitor', 'health']):\n",
    "                script_categories['monitoring'].append(file)\n",
    "            else:\n",
    "                script_categories['tools'].append(file)\n",
    "    \n",
    "    scripts_structure['categories'] = script_categories\n",
    "    \n",
    "    return scripts_structure\n",
    "\n",
    "def analyze_automation_capabilities():\n",
    "    \"\"\"\n",
    "    Analisa capacidades de automa√ß√£o do projeto\n",
    "    \"\"\"\n",
    "    automation_features = {\n",
    "        'ci_cd': {\n",
    "            'github_actions': os.path.exists(os.path.join(PROJECT_ROOT, '.github', 'workflows')),\n",
    "            'husky_hooks': os.path.exists(os.path.join(PROJECT_ROOT, '.husky')),\n",
    "            'docker_compose': os.path.exists(os.path.join(PROJECT_ROOT, 'docker', 'docker-compose.yml'))\n",
    "        },\n",
    "        'development': {\n",
    "            'hot_reload': False,  # Detectado via package.json scripts\n",
    "            'linting': False,     # Detectado via config files\n",
    "            'testing': False,     # Detectado via test scripts\n",
    "            'formatting': False   # Detectado via prettier/eslint\n",
    "        },\n",
    "        'deployment': {\n",
    "            'containerization': os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'Dockerfile')),\n",
    "            'nginx_config': os.path.exists(os.path.join(PROJECT_ROOT, 'nginx')),\n",
    "            'env_management': os.path.exists(os.path.join(PROJECT_ROOT, 'configs'))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Verifica features de desenvolvimento atrav√©s de package.json\n",
    "    package_files = [\n",
    "        os.path.join(PROJECT_ROOT, 'package.json'),\n",
    "        os.path.join(PROJECT_ROOT, 'client', 'package.json'),\n",
    "        os.path.join(PROJECT_ROOT, 'server', 'package.json')\n",
    "    ]\n",
    "    \n",
    "    for package_file in package_files:\n",
    "        if os.path.exists(package_file):\n",
    "            try:\n",
    "                with open(package_file, 'r', encoding='utf-8') as f:\n",
    "                    package_data = json.loads(f.read())\n",
    "                \n",
    "                scripts = package_data.get('scripts', {})\n",
    "                dev_deps = package_data.get('devDependencies', {})\n",
    "                \n",
    "                # Detecta hot reload\n",
    "                if any('dev' in script for script in scripts.values()):\n",
    "                    automation_features['development']['hot_reload'] = True\n",
    "                \n",
    "                # Detecta linting\n",
    "                if 'eslint' in dev_deps or any('lint' in script for script in scripts.values()):\n",
    "                    automation_features['development']['linting'] = True\n",
    "                \n",
    "                # Detecta testing\n",
    "                if any('test' in script for script in scripts.values()):\n",
    "                    automation_features['development']['testing'] = True\n",
    "                \n",
    "                # Detecta formatting\n",
    "                if 'prettier' in dev_deps or any('format' in script for script in scripts.values()):\n",
    "                    automation_features['development']['formatting'] = True\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao analisar {package_file}: {e}\")\n",
    "    \n",
    "    return automation_features\n",
    "\n",
    "# Executa an√°lise dos scripts\n",
    "print(\"‚öôÔ∏è Analisando scripts e automa√ß√£o...\")\n",
    "scripts_analysis = analyze_scripts_automation()\n",
    "automation_analysis = analyze_automation_capabilities()\n",
    "\n",
    "if 'error' not in scripts_analysis:\n",
    "    # Cria DataFrame para visualiza√ß√£o\n",
    "    scripts_data = []\n",
    "    for category, data in scripts_analysis.items():\n",
    "        if category != 'categories' and 'total_files' in data:\n",
    "            scripts_data.append({\n",
    "                'Categoria': category.replace('_', ' ').title(),\n",
    "                'Descri√ß√£o': data['description'],\n",
    "                'Total de Scripts': data['total_files'],\n",
    "                'Tipos de Arquivo': ', '.join([f\"{ext}({count})\" for ext, count in \n",
    "                                             sorted(data['file_types'].items(), \n",
    "                                                   key=lambda x: x[1], reverse=True)[:3]])\n",
    "            })\n",
    "    \n",
    "    df_scripts = pd.DataFrame(scripts_data)\n",
    "    df_scripts = df_scripts[df_scripts['Total de Scripts'] > 0]\n",
    "    \n",
    "    print(\"\\\\nüìä Scripts de Automa√ß√£o:\")\n",
    "    print(df_scripts.to_string(index=False))\n",
    "    \n",
    "    # An√°lise das categorias funcionais\n",
    "    print(f\"\\\\nüîß Scripts por Funcionalidade:\")\n",
    "    print(\"=\" * 50)\n",
    "    categories = scripts_analysis['categories']\n",
    "    for category, scripts in categories.items():\n",
    "        if scripts:\n",
    "            print(f\"üìÅ {category.title()}: {len(scripts)} scripts\")\n",
    "            for script in scripts[:3]:  # Mostra at√© 3 scripts por categoria\n",
    "                print(f\"   ‚Ä¢ {script}\")\n",
    "            if len(scripts) > 3:\n",
    "                print(f\"   ... e mais {len(scripts) - 3} scripts\")\n",
    "    \n",
    "    # An√°lise de capacidades de automa√ß√£o\n",
    "    print(f\"\\\\nü§ñ Capacidades de Automa√ß√£o:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    ci_cd = automation_analysis['ci_cd']\n",
    "    development = automation_analysis['development']\n",
    "    deployment = automation_analysis['deployment']\n",
    "    \n",
    "    print(\"üîÑ CI/CD e Integra√ß√£o:\")\n",
    "    print(f\"   ‚Ä¢ GitHub Actions: {'‚úÖ' if ci_cd['github_actions'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Husky Git Hooks: {'‚úÖ' if ci_cd['husky_hooks'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Docker Compose: {'‚úÖ' if ci_cd['docker_compose'] else '‚ùå'}\")\n",
    "    \n",
    "    print(\"\\\\nüíª Desenvolvimento:\")\n",
    "    print(f\"   ‚Ä¢ Hot Reload: {'‚úÖ' if development['hot_reload'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Linting: {'‚úÖ' if development['linting'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Testing: {'‚úÖ' if development['testing'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Code Formatting: {'‚úÖ' if development['formatting'] else '‚ùå'}\")\n",
    "    \n",
    "    print(\"\\\\nüöÄ Deploy e Produ√ß√£o:\")\n",
    "    print(f\"   ‚Ä¢ Containeriza√ß√£o: {'‚úÖ' if deployment['containerization'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Nginx Config: {'‚úÖ' if deployment['nginx_config'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Gest√£o de Env: {'‚úÖ' if deployment['env_management'] else '‚ùå'}\")\n",
    "    \n",
    "    # Visualiza√ß√µes\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de scripts por categoria\n",
    "    plt.subplot(2, 3, 1)\n",
    "    if not df_scripts.empty:\n",
    "        plt.bar(df_scripts['Categoria'], df_scripts['Total de Scripts'],\n",
    "                color=sns.color_palette(\"Set3\", len(df_scripts)))\n",
    "        plt.title('‚öôÔ∏è Scripts por Categoria')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('N√∫mero de Scripts')\n",
    "    \n",
    "    # Gr√°fico 2: Scripts por funcionalidade\n",
    "    plt.subplot(2, 3, 2)\n",
    "    func_categories = {k: len(v) for k, v in categories.items() if v}\n",
    "    if func_categories:\n",
    "        plt.bar(func_categories.keys(), func_categories.values(),\n",
    "                color=sns.color_palette(\"viridis\", len(func_categories)))\n",
    "        plt.title('üîß Scripts por Funcionalidade')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Quantidade')\n",
    "    \n",
    "    # Gr√°fico 3: Capacidades CI/CD\n",
    "    plt.subplot(2, 3, 3)\n",
    "    ci_cd_features = {\n",
    "        'GitHub Actions': ci_cd['github_actions'],\n",
    "        'Husky Hooks': ci_cd['husky_hooks'],\n",
    "        'Docker Compose': ci_cd['docker_compose']\n",
    "    }\n",
    "    ci_cd_values = [1 if v else 0 for v in ci_cd_features.values()]\n",
    "    colors = ['green' if v else 'red' for v in ci_cd_features.values()]\n",
    "    \n",
    "    plt.bar(ci_cd_features.keys(), ci_cd_values, color=colors)\n",
    "    plt.title('üîÑ Recursos CI/CD')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Dispon√≠vel')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    # Gr√°fico 4: Capacidades de desenvolvimento\n",
    "    plt.subplot(2, 3, 4)\n",
    "    dev_features = {\n",
    "        'Hot Reload': development['hot_reload'],\n",
    "        'Linting': development['linting'],\n",
    "        'Testing': development['testing'],\n",
    "        'Formatting': development['formatting']\n",
    "    }\n",
    "    dev_values = [1 if v else 0 for v in dev_features.values()]\n",
    "    colors = ['green' if v else 'red' for v in dev_features.values()]\n",
    "    \n",
    "    plt.bar(dev_features.keys(), dev_values, color=colors)\n",
    "    plt.title('üíª Recursos de Dev')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Dispon√≠vel')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    # Gr√°fico 5: Capacidades de deploy\n",
    "    plt.subplot(2, 3, 5)\n",
    "    deploy_features = {\n",
    "        'Containers': deployment['containerization'],\n",
    "        'Nginx': deployment['nginx_config'],\n",
    "        'Env Management': deployment['env_management']\n",
    "    }\n",
    "    deploy_values = [1 if v else 0 for v in deploy_features.values()]\n",
    "    colors = ['green' if v else 'red' for v in deploy_features.values()]\n",
    "    \n",
    "    plt.bar(deploy_features.keys(), deploy_values, color=colors)\n",
    "    plt.title('üöÄ Recursos de Deploy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Dispon√≠vel')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    # Gr√°fico 6: Maturidade de automa√ß√£o geral\n",
    "    plt.subplot(2, 3, 6)\n",
    "    all_features = {**ci_cd_features, **dev_features, **deploy_features}\n",
    "    automation_score = sum(all_features.values()) / len(all_features) * 100\n",
    "    \n",
    "    categories_scores = {\n",
    "        'CI/CD': sum(ci_cd.values()) / len(ci_cd) * 100,\n",
    "        'Development': sum(development.values()) / len(development) * 100,\n",
    "        'Deployment': sum(deployment.values()) / len(deployment) * 100\n",
    "    }\n",
    "    \n",
    "    plt.bar(categories_scores.keys(), categories_scores.values(),\n",
    "            color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    plt.title('üìä Maturidade de Automa√ß√£o')\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Adiciona linha de meta (75%)\n",
    "    plt.axhline(y=75, color='green', linestyle='--', alpha=0.7, label='Meta (75%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Resumo da automa√ß√£o\n",
    "    print(\"\\\\nüéØ RESUMO DE AUTOMA√á√ÉO:\")\n",
    "    print(\"=\" * 50)\n",
    "    total_scripts = sum(data.get('total_files', 0) for data in scripts_analysis.values() \n",
    "                       if isinstance(data, dict) and 'total_files' in data)\n",
    "    total_categories = len([k for k, v in categories.items() if v])\n",
    "    \n",
    "    print(f\"‚öôÔ∏è Total de scripts: {total_scripts}\")\n",
    "    print(f\"üîß Categorias funcionais: {total_categories}\")\n",
    "    print(f\"üìä Score geral de automa√ß√£o: {automation_score:.1f}%\")\n",
    "    print(f\"üîÑ CI/CD: {categories_scores['CI/CD']:.1f}%\")\n",
    "    print(f\"üíª Desenvolvimento: {categories_scores['Development']:.1f}%\")\n",
    "    print(f\"üöÄ Deploy: {categories_scores['Deployment']:.1f}%\")\n",
    "    \n",
    "    if automation_score >= 75:\n",
    "        print(\"‚úÖ Excelente n√≠vel de automa√ß√£o!\")\n",
    "    elif automation_score >= 50:\n",
    "        print(\"üëç Bom n√≠vel de automa√ß√£o, algumas melhorias poss√≠veis.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è N√≠vel b√°sico de automa√ß√£o, oportunidades de melhoria.\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Erro na an√°lise de scripts: {scripts_analysis['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ed152",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Documenta√ß√£o e Deploy\n",
    "\n",
    "An√°lise da documenta√ß√£o t√©cnica, guias de desenvolvimento e estrat√©gias de deploy do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_documentation():\n",
    "    \"\"\"\n",
    "    Analisa a documenta√ß√£o do projeto\n",
    "    \"\"\"\n",
    "    docs_path = os.path.join(PROJECT_ROOT, 'docs')\n",
    "    if not os.path.exists(docs_path):\n",
    "        return {\"error\": \"Diret√≥rio 'docs' n√£o encontrado\"}\n",
    "    \n",
    "    doc_structure = {\n",
    "        'main_docs': [],\n",
    "        'directories': {},\n",
    "        'doc_types': {},\n",
    "        'total_docs': 0\n",
    "    }\n",
    "    \n",
    "    # Categorias de documenta√ß√£o\n",
    "    doc_categories = {\n",
    "        'architecture': [],\n",
    "        'api': [],\n",
    "        'development': [],\n",
    "        'deployment': [],\n",
    "        'guides': [],\n",
    "        'setup': [],\n",
    "        'testing': [],\n",
    "        'planning': [],\n",
    "        'reports': [],\n",
    "        'auth': [],\n",
    "        'changelog': [],\n",
    "        'readme': []\n",
    "    }\n",
    "    \n",
    "    # Analisa arquivos na raiz do docs\n",
    "    for item in os.listdir(docs_path):\n",
    "        item_path = os.path.join(docs_path, item)\n",
    "        \n",
    "        if os.path.isfile(item_path):\n",
    "            doc_structure['main_docs'].append(item)\n",
    "            doc_structure['total_docs'] += 1\n",
    "            \n",
    "            # Classifica por extens√£o\n",
    "            ext = pathlib.Path(item).suffix.lower()\n",
    "            if not ext:\n",
    "                ext = 'no_extension'\n",
    "            if ext not in doc_structure['doc_types']:\n",
    "                doc_structure['doc_types'][ext] = 0\n",
    "            doc_structure['doc_types'][ext] += 1\n",
    "            \n",
    "            # Categoriza por conte√∫do\n",
    "            item_lower = item.lower()\n",
    "            if any(keyword in item_lower for keyword in ['architecture', 'arquitetura']):\n",
    "                doc_categories['architecture'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['api']):\n",
    "                doc_categories['api'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['development', 'dev']):\n",
    "                doc_categories['development'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['deploy', 'docker']):\n",
    "                doc_categories['deployment'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['guide', 'contributing']):\n",
    "                doc_categories['guides'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['setup', 'install']):\n",
    "                doc_categories['setup'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['test']):\n",
    "                doc_categories['testing'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['roadmap', 'planning']):\n",
    "                doc_categories['planning'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['auth', 'login']):\n",
    "                doc_categories['auth'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['changelog', 'log']):\n",
    "                doc_categories['changelog'].append(item)\n",
    "            elif any(keyword in item_lower for keyword in ['readme']):\n",
    "                doc_categories['readme'].append(item)\n",
    "            else:\n",
    "                doc_categories['reports'].append(item)\n",
    "        \n",
    "        elif os.path.isdir(item_path):\n",
    "            # Analisa subdiret√≥rios\n",
    "            structure, file_counts, total_files = analyze_directory_structure(item_path, max_depth=2)\n",
    "            doc_structure['directories'][item] = {\n",
    "                'total_files': total_files,\n",
    "                'file_types': dict(file_counts),\n",
    "                'structure': structure\n",
    "            }\n",
    "            doc_structure['total_docs'] += total_files\n",
    "    \n",
    "    doc_structure['categories'] = doc_categories\n",
    "    \n",
    "    return doc_structure\n",
    "\n",
    "def analyze_deployment_strategy():\n",
    "    \"\"\"\n",
    "    Analisa estrat√©gias de deploy e configura√ß√µes\n",
    "    \"\"\"\n",
    "    deployment_config = {\n",
    "        'docker': {\n",
    "            'has_dockerfile': False,\n",
    "            'has_compose': False,\n",
    "            'services': [],\n",
    "            'environments': []\n",
    "        },\n",
    "        'ci_cd': {\n",
    "            'github_actions': False,\n",
    "            'workflows': []\n",
    "        },\n",
    "        'nginx': {\n",
    "            'has_config': False,\n",
    "            'config_files': []\n",
    "        },\n",
    "        'environment_management': {\n",
    "            'has_env_configs': False,\n",
    "            'env_files': [],\n",
    "            'config_structure': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Verifica Docker\n",
    "    docker_files = [\n",
    "        'Dockerfile',\n",
    "        'client/Dockerfile',\n",
    "        'client/Dockerfile.dev',\n",
    "        'server/Dockerfile',\n",
    "        'ia/Dockerfile'\n",
    "    ]\n",
    "    \n",
    "    for docker_file in docker_files:\n",
    "        if os.path.exists(os.path.join(PROJECT_ROOT, docker_file)):\n",
    "            deployment_config['docker']['has_dockerfile'] = True\n",
    "            break\n",
    "    \n",
    "    # Verifica Docker Compose\n",
    "    compose_files = [\n",
    "        'docker-compose.yml',\n",
    "        'docker/docker-compose.yml',\n",
    "        'docker/docker-compose.prod.yml'\n",
    "    ]\n",
    "    \n",
    "    for compose_file in compose_files:\n",
    "        compose_path = os.path.join(PROJECT_ROOT, compose_file)\n",
    "        if os.path.exists(compose_path):\n",
    "            deployment_config['docker']['has_compose'] = True\n",
    "            deployment_config['docker']['services'].append(compose_file)\n",
    "    \n",
    "    # Verifica ambientes\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'docker')):\n",
    "        for file in os.listdir(os.path.join(PROJECT_ROOT, 'docker')):\n",
    "            if 'prod' in file.lower():\n",
    "                deployment_config['docker']['environments'].append('production')\n",
    "            elif 'dev' in file.lower() or 'development' in file.lower():\n",
    "                deployment_config['docker']['environments'].append('development')\n",
    "    \n",
    "    # Verifica GitHub Actions\n",
    "    github_workflows_path = os.path.join(PROJECT_ROOT, '.github', 'workflows')\n",
    "    if os.path.exists(github_workflows_path):\n",
    "        deployment_config['ci_cd']['github_actions'] = True\n",
    "        deployment_config['ci_cd']['workflows'] = [\n",
    "            f for f in os.listdir(github_workflows_path) \n",
    "            if f.endswith(('.yml', '.yaml'))\n",
    "        ]\n",
    "    \n",
    "    # Verifica Nginx\n",
    "    nginx_path = os.path.join(PROJECT_ROOT, 'nginx')\n",
    "    if os.path.exists(nginx_path):\n",
    "        deployment_config['nginx']['has_config'] = True\n",
    "        deployment_config['nginx']['config_files'] = [\n",
    "            f for f in os.listdir(nginx_path) \n",
    "            if f.endswith('.conf')\n",
    "        ]\n",
    "    \n",
    "    # Verifica configura√ß√µes de ambiente\n",
    "    configs_path = os.path.join(PROJECT_ROOT, 'configs')\n",
    "    if os.path.exists(configs_path):\n",
    "        deployment_config['environment_management']['has_env_configs'] = True\n",
    "        \n",
    "        for file in os.listdir(configs_path):\n",
    "            if file.endswith('.env') or 'env' in file:\n",
    "                deployment_config['environment_management']['env_files'].append(file)\n",
    "        \n",
    "        # Analisa estrutura dos configs\n",
    "        structure, file_counts, total_files = analyze_directory_structure(configs_path, max_depth=1)\n",
    "        deployment_config['environment_management']['config_structure'] = {\n",
    "            'total_files': total_files,\n",
    "            'file_types': dict(file_counts)\n",
    "        }\n",
    "    \n",
    "    return deployment_config\n",
    "\n",
    "def calculate_project_maturity():\n",
    "    \"\"\"\n",
    "    Calcula m√©tricas de maturidade do projeto\n",
    "    \"\"\"\n",
    "    maturity_metrics = {\n",
    "        'documentation': 0,\n",
    "        'testing': 0,\n",
    "        'automation': 0,\n",
    "        'deployment': 0,\n",
    "        'security': 0,\n",
    "        'organization': 0\n",
    "    }\n",
    "    \n",
    "    # Documenta√ß√£o (peso: 20%)\n",
    "    docs_score = 0\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'docs')):\n",
    "        docs_score += 30\n",
    "        doc_files = len([f for f in os.listdir(os.path.join(PROJECT_ROOT, 'docs')) \n",
    "                        if f.endswith('.md')])\n",
    "        docs_score += min(doc_files * 5, 50)  # M√°ximo 50 pontos\n",
    "        \n",
    "        # Documenta√ß√£o essencial\n",
    "        essential_docs = ['README.md', 'API_README.md', 'ARCHITECTURE.md', 'CONTRIBUTING.md']\n",
    "        for doc in essential_docs:\n",
    "            if os.path.exists(os.path.join(PROJECT_ROOT, 'docs', doc)):\n",
    "                docs_score += 5\n",
    "    \n",
    "    maturity_metrics['documentation'] = min(docs_score, 100)\n",
    "    \n",
    "    # Testing (peso: 20%)\n",
    "    testing_score = 0\n",
    "    test_configs = ['jest.config.js', 'vitest.config.ts', 'cypress.config.js']\n",
    "    for config in test_configs:\n",
    "        if os.path.exists(os.path.join(PROJECT_ROOT, 'client', config)) or \\\\\n",
    "           os.path.exists(os.path.join(PROJECT_ROOT, 'server', config)):\n",
    "            testing_score += 25\n",
    "    \n",
    "    # Procura por diret√≥rios de teste\n",
    "    test_dirs = ['tests', 'test', '__tests__', 'spec']\n",
    "    for test_dir in test_dirs:\n",
    "        if os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'src', test_dir)) or \\\\\n",
    "           os.path.exists(os.path.join(PROJECT_ROOT, 'server', 'src', test_dir)):\n",
    "            testing_score += 25\n",
    "    \n",
    "    maturity_metrics['testing'] = min(testing_score, 100)\n",
    "    \n",
    "    # Automa√ß√£o (peso: 20%)\n",
    "    automation_score = 0\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, '.github', 'workflows')):\n",
    "        automation_score += 30\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'scripts')):\n",
    "        automation_score += 25\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'docker')):\n",
    "        automation_score += 25\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, '.husky')):\n",
    "        automation_score += 20\n",
    "    \n",
    "    maturity_metrics['automation'] = min(automation_score, 100)\n",
    "    \n",
    "    # Deploy (peso: 15%)\n",
    "    deploy_score = 0\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'Dockerfile')):\n",
    "        deploy_score += 25\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'docker', 'docker-compose.yml')):\n",
    "        deploy_score += 25\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'nginx')):\n",
    "        deploy_score += 25\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'configs')):\n",
    "        deploy_score += 25\n",
    "    \n",
    "    maturity_metrics['deployment'] = min(deploy_score, 100)\n",
    "    \n",
    "    # Seguran√ßa (peso: 15%)\n",
    "    security_score = 0\n",
    "    security_files = ['.env.example', 'security-validation.log', '.gitignore']\n",
    "    for sec_file in security_files:\n",
    "        if os.path.exists(os.path.join(PROJECT_ROOT, sec_file)):\n",
    "            security_score += 20\n",
    "    \n",
    "    # Verifica scripts de seguran√ßa\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'scripts')):\n",
    "        security_scripts = [f for f in os.listdir(os.path.join(PROJECT_ROOT, 'scripts'))\n",
    "                           if 'security' in f.lower() or 'validate' in f.lower()]\n",
    "        security_score += len(security_scripts) * 10\n",
    "    \n",
    "    maturity_metrics['security'] = min(security_score, 100)\n",
    "    \n",
    "    # Organiza√ß√£o (peso: 10%)\n",
    "    org_score = 0\n",
    "    \n",
    "    # Estrutura modular\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'src', 'components')):\n",
    "        org_score += 20\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'server', 'src', 'modules')):\n",
    "        org_score += 20\n",
    "    if os.path.exists(os.path.join(PROJECT_ROOT, 'configs')):\n",
    "        org_score += 20\n",
    "    \n",
    "    # Separa√ß√£o por responsabilidades\n",
    "    key_dirs = ['client', 'server', 'docs', 'scripts', 'ia']\n",
    "    existing_dirs = sum(1 for d in key_dirs if os.path.exists(os.path.join(PROJECT_ROOT, d)))\n",
    "    org_score += (existing_dirs / len(key_dirs)) * 40\n",
    "    \n",
    "    maturity_metrics['organization'] = min(org_score, 100)\n",
    "    \n",
    "    # Calcula score geral (m√©dia ponderada)\n",
    "    weights = {\n",
    "        'documentation': 0.20,\n",
    "        'testing': 0.20,\n",
    "        'automation': 0.20,\n",
    "        'deployment': 0.15,\n",
    "        'security': 0.15,\n",
    "        'organization': 0.10\n",
    "    }\n",
    "    \n",
    "    overall_score = sum(maturity_metrics[metric] * weights[metric] \n",
    "                       for metric in maturity_metrics)\n",
    "    \n",
    "    maturity_metrics['overall'] = overall_score\n",
    "    \n",
    "    return maturity_metrics\n",
    "\n",
    "# Executa an√°lise completa de documenta√ß√£o e deploy\n",
    "print(\"üìö Analisando documenta√ß√£o e deploy...\")\n",
    "docs_analysis = analyze_documentation()\n",
    "deploy_analysis = analyze_deployment_strategy()\n",
    "maturity_analysis = calculate_project_maturity()\n",
    "\n",
    "if 'error' not in docs_analysis:\n",
    "    # An√°lise da documenta√ß√£o\n",
    "    print(\"\\\\nüìñ AN√ÅLISE DA DOCUMENTA√á√ÉO:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_docs = docs_analysis['total_docs']\n",
    "    main_docs = len(docs_analysis['main_docs'])\n",
    "    directories = len(docs_analysis['directories'])\n",
    "    \n",
    "    print(f\"üìÑ Total de documentos: {total_docs}\")\n",
    "    print(f\"üìã Documentos principais: {main_docs}\")\n",
    "    print(f\"üìÅ Diret√≥rios de docs: {directories}\")\n",
    "    \n",
    "    # Tipos de arquivo\n",
    "    print(\"\\\\nüìä Tipos de documenta√ß√£o:\")\n",
    "    for doc_type, count in sorted(docs_analysis['doc_types'].items(), \n",
    "                                 key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   ‚Ä¢ {doc_type}: {count} arquivo(s)\")\n",
    "    \n",
    "    # Categorias funcionais\n",
    "    print(\"\\\\nüè∑Ô∏è Documenta√ß√£o por categoria:\")\n",
    "    categories = docs_analysis['categories']\n",
    "    for category, docs in categories.items():\n",
    "        if docs:\n",
    "            print(f\"   üìå {category.title()}: {len(docs)} documento(s)\")\n",
    "            for doc in docs[:2]:  # Mostra at√© 2 docs por categoria\n",
    "                print(f\"      ‚Ä¢ {doc}\")\n",
    "            if len(docs) > 2:\n",
    "                print(f\"      ... e mais {len(docs) - 2}\")\n",
    "    \n",
    "    # Subdiret√≥rios\n",
    "    if docs_analysis['directories']:\n",
    "        print(\"\\\\nüìÇ Estrutura de subdiret√≥rios:\")\n",
    "        for dir_name, dir_data in docs_analysis['directories'].items():\n",
    "            print(f\"   üìÅ {dir_name}/: {dir_data['total_files']} arquivos\")\n",
    "    \n",
    "    # An√°lise de deploy\n",
    "    print(\"\\\\nüöÄ AN√ÅLISE DE DEPLOY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    docker_config = deploy_analysis['docker']\n",
    "    ci_cd_config = deploy_analysis['ci_cd']\n",
    "    nginx_config = deploy_analysis['nginx']\n",
    "    env_config = deploy_analysis['environment_management']\n",
    "    \n",
    "    print(\"üê≥ Docker:\")\n",
    "    print(f\"   ‚Ä¢ Dockerfiles: {'‚úÖ' if docker_config['has_dockerfile'] else '‚ùå'}\")\n",
    "    print(f\"   ‚Ä¢ Docker Compose: {'‚úÖ' if docker_config['has_compose'] else '‚ùå'}\")\n",
    "    if docker_config['services']:\n",
    "        print(f\"   ‚Ä¢ Servi√ßos: {', '.join(docker_config['services'])}\")\n",
    "    if docker_config['environments']:\n",
    "        print(f\"   ‚Ä¢ Ambientes: {', '.join(set(docker_config['environments']))}\")\n",
    "    \n",
    "    print(\"\\\\nüîÑ CI/CD:\")\n",
    "    print(f\"   ‚Ä¢ GitHub Actions: {'‚úÖ' if ci_cd_config['github_actions'] else '‚ùå'}\")\n",
    "    if ci_cd_config['workflows']:\n",
    "        print(f\"   ‚Ä¢ Workflows: {len(ci_cd_config['workflows'])}\")\n",
    "        for workflow in ci_cd_config['workflows'][:3]:\n",
    "            print(f\"      ‚Ä¢ {workflow}\")\n",
    "    \n",
    "    print(\"\\\\nüåê Nginx:\")\n",
    "    print(f\"   ‚Ä¢ Configura√ß√µes: {'‚úÖ' if nginx_config['has_config'] else '‚ùå'}\")\n",
    "    if nginx_config['config_files']:\n",
    "        print(f\"   ‚Ä¢ Arquivos: {', '.join(nginx_config['config_files'])}\")\n",
    "    \n",
    "    print(\"\\\\n‚öôÔ∏è Gest√£o de Ambiente:\")\n",
    "    print(f\"   ‚Ä¢ Configura√ß√µes: {'‚úÖ' if env_config['has_env_configs'] else '‚ùå'}\")\n",
    "    if env_config['env_files']:\n",
    "        print(f\"   ‚Ä¢ Arquivos de env: {len(env_config['env_files'])}\")\n",
    "        for env_file in env_config['env_files'][:3]:\n",
    "            print(f\"      ‚Ä¢ {env_file}\")\n",
    "    \n",
    "    # M√©tricas de maturidade\n",
    "    print(\"\\\\nüéØ M√âTRICAS DE MATURIDADE:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    metrics = maturity_analysis\n",
    "    overall_score = metrics['overall']\n",
    "    \n",
    "    print(f\"üìä Score Geral: {overall_score:.1f}%\")\n",
    "    print(f\"üìö Documenta√ß√£o: {metrics['documentation']:.1f}%\")\n",
    "    print(f\"üß™ Testes: {metrics['testing']:.1f}%\")\n",
    "    print(f\"ü§ñ Automa√ß√£o: {metrics['automation']:.1f}%\")\n",
    "    print(f\"üöÄ Deploy: {metrics['deployment']:.1f}%\")\n",
    "    print(f\"üîí Seguran√ßa: {metrics['security']:.1f}%\")\n",
    "    print(f\"üìÅ Organiza√ß√£o: {metrics['organization']:.1f}%\")\n",
    "    \n",
    "    # Classifica√ß√£o de maturidade\n",
    "    if overall_score >= 85:\n",
    "        maturity_level = \"üèÜ EXCELENTE\"\n",
    "        maturity_desc = \"Projeto altamente maduro com excelentes pr√°ticas\"\n",
    "    elif overall_score >= 70:\n",
    "        maturity_level = \"‚úÖ MUITO BOM\"\n",
    "        maturity_desc = \"Projeto bem estruturado com boas pr√°ticas\"\n",
    "    elif overall_score >= 55:\n",
    "        maturity_level = \"üëç BOM\"\n",
    "        maturity_desc = \"Projeto s√≥lido com algumas oportunidades de melhoria\"\n",
    "    elif overall_score >= 40:\n",
    "        maturity_level = \"‚ö†Ô∏è REGULAR\"\n",
    "        maturity_desc = \"Projeto funcional mas precisa de melhorias\"\n",
    "    else:\n",
    "        maturity_level = \"‚ùå B√ÅSICO\"\n",
    "        maturity_desc = \"Projeto em est√°gio inicial, muitas melhorias necess√°rias\"\n",
    "    \n",
    "    print(f\"\\\\nüèÖ N√≠vel de Maturidade: {maturity_level}\")\n",
    "    print(f\"   {maturity_desc}\")\n",
    "    \n",
    "    # Visualiza√ß√µes\n",
    "    plt.figure(figsize=(18, 14))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de documenta√ß√£o por tipo\n",
    "    plt.subplot(3, 3, 1)\n",
    "    if docs_analysis['doc_types']:\n",
    "        plt.pie(docs_analysis['doc_types'].values(), \n",
    "                labels=docs_analysis['doc_types'].keys(), \n",
    "                autopct='%1.1f%%',\n",
    "                colors=sns.color_palette(\"Set3\", len(docs_analysis['doc_types'])))\n",
    "        plt.title('üìÑ Documenta√ß√£o por Tipo')\n",
    "    \n",
    "    # Gr√°fico 2: Documenta√ß√£o por categoria\n",
    "    plt.subplot(3, 3, 2)\n",
    "    cat_counts = {k: len(v) for k, v in categories.items() if v}\n",
    "    if cat_counts:\n",
    "        plt.bar(cat_counts.keys(), cat_counts.values(),\n",
    "                color=sns.color_palette(\"viridis\", len(cat_counts)))\n",
    "        plt.title('üìã Docs por Categoria')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('Quantidade')\n",
    "    \n",
    "    # Gr√°fico 3: Capacidades de deploy\n",
    "    plt.subplot(3, 3, 3)\n",
    "    deploy_capabilities = {\n",
    "        'Docker': docker_config['has_dockerfile'],\n",
    "        'Compose': docker_config['has_compose'],\n",
    "        'CI/CD': ci_cd_config['github_actions'],\n",
    "        'Nginx': nginx_config['has_config'],\n",
    "        'Env Mgmt': env_config['has_env_configs']\n",
    "    }\n",
    "    deploy_values = [1 if v else 0 for v in deploy_capabilities.values()]\n",
    "    colors = ['green' if v else 'red' for v in deploy_capabilities.values()]\n",
    "    \n",
    "    plt.bar(deploy_capabilities.keys(), deploy_values, color=colors)\n",
    "    plt.title('üöÄ Capacidades de Deploy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Dispon√≠vel')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    # Gr√°fico 4: M√©tricas de maturidade (radar)\n",
    "    plt.subplot(3, 3, 4)\n",
    "    metrics_names = ['Documenta√ß√£o', 'Testes', 'Automa√ß√£o', 'Deploy', 'Seguran√ßa', 'Organiza√ß√£o']\n",
    "    metrics_values = [metrics[k] for k in ['documentation', 'testing', 'automation', 'deployment', 'security', 'organization']]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    metrics_values = metrics_values + [metrics_values[0]]\n",
    "    \n",
    "    ax = plt.subplot(3, 3, 4, projection='polar')\n",
    "    ax.plot(angles, metrics_values, 'o-', linewidth=2, color='#1f77b4')\n",
    "    ax.fill(angles, metrics_values, alpha=0.25, color='#1f77b4')\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics_names)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_title('üéØ Radar de Maturidade', pad=20)\n",
    "    \n",
    "    # Gr√°fico 5: Score geral de maturidade\n",
    "    plt.subplot(3, 3, 5)\n",
    "    score_ranges = ['0-40', '40-55', '55-70', '70-85', '85-100']\n",
    "    score_colors = ['red', 'orange', 'yellow', 'lightgreen', 'green']\n",
    "    current_range = min(int(overall_score // 15), 4)\n",
    "    \n",
    "    bars = plt.bar(score_ranges, [20, 15, 15, 15, 15], \n",
    "                   color=['lightgray'] * 5)\n",
    "    bars[current_range].set_color(score_colors[current_range])\n",
    "    \n",
    "    plt.axhline(y=overall_score % 20 if overall_score % 20 != 0 else 20, \n",
    "                color='darkblue', linewidth=3, \n",
    "                label=f'Score Atual: {overall_score:.1f}%')\n",
    "    plt.title('üìä Score de Maturidade')\n",
    "    plt.ylabel('Percentual')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gr√°fico 6: Compara√ß√£o de m√©tricas com benchmark\n",
    "    plt.subplot(3, 3, 6)\n",
    "    benchmark = {\n",
    "        'documentation': 75,\n",
    "        'testing': 80,\n",
    "        'automation': 70,\n",
    "        'deployment': 75,\n",
    "        'security': 85,\n",
    "        'organization': 80\n",
    "    }\n",
    "    \n",
    "    x = range(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar([i - width/2 for i in x], metrics_values[:-1], width, \n",
    "            label='Atual', color='skyblue')\n",
    "    plt.bar([i + width/2 for i in x], [benchmark[k] for k in benchmark.keys()], width,\n",
    "            label='Benchmark', color='orange', alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('M√©tricas')\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.title('üìà Compara√ß√£o com Benchmark')\n",
    "    plt.xticks(x, [m[:10] for m in metrics_names], rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gr√°fico 7: Evolu√ß√£o sugerida (timeline)\n",
    "    plt.subplot(3, 3, 7)\n",
    "    phases = ['Atual', 'Fase 1\\\\n(+2 meses)', 'Fase 2\\\\n(+4 meses)', 'Fase 3\\\\n(+6 meses)']\n",
    "    projected_scores = [overall_score, min(overall_score + 15, 100), \n",
    "                       min(overall_score + 25, 100), min(overall_score + 35, 100)]\n",
    "    \n",
    "    plt.plot(phases, projected_scores, 'o-', linewidth=3, markersize=8, color='green')\n",
    "    plt.fill_between(phases, projected_scores, alpha=0.3, color='green')\n",
    "    plt.title('üìà Roadmap de Maturidade')\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Gr√°fico 8: Distribui√ß√£o de arquivos por diret√≥rio de docs\n",
    "    plt.subplot(3, 3, 8)\n",
    "    if docs_analysis['directories']:\n",
    "        dir_files = {name: data['total_files'] \n",
    "                    for name, data in docs_analysis['directories'].items()}\n",
    "        \n",
    "        plt.bar(dir_files.keys(), dir_files.values(),\n",
    "                color=sns.color_palette(\"Set2\", len(dir_files)))\n",
    "        plt.title('üìÅ Arquivos por Diret√≥rio')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel('N√∫mero de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 9: Status de recursos essenciais\n",
    "    plt.subplot(3, 3, 9)\n",
    "    essential_resources = {\n",
    "        'README': os.path.exists(os.path.join(PROJECT_ROOT, 'README.md')),\n",
    "        'Docker': docker_config['has_dockerfile'],\n",
    "        'CI/CD': ci_cd_config['github_actions'],\n",
    "        'Tests': os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'vitest.config.ts')),\n",
    "        'Docs': os.path.exists(os.path.join(PROJECT_ROOT, 'docs')),\n",
    "        'Scripts': os.path.exists(os.path.join(PROJECT_ROOT, 'scripts'))\n",
    "    }\n",
    "    \n",
    "    resource_values = [1 if v else 0 for v in essential_resources.values()]\n",
    "    colors = ['green' if v else 'red' for v in essential_resources.values()]\n",
    "    \n",
    "    plt.bar(essential_resources.keys(), resource_values, color=colors)\n",
    "    plt.title('‚úÖ Recursos Essenciais')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Presente')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Recomenda√ß√µes finais\n",
    "    print(\"\\\\nüí° RECOMENDA√á√ïES DE MELHORIA:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if metrics['documentation'] < 70:\n",
    "        print(\"üìö Documenta√ß√£o:\")\n",
    "        print(\"   ‚Ä¢ Adicionar guias de instala√ß√£o detalhados\")\n",
    "        print(\"   ‚Ä¢ Criar documenta√ß√£o de API completa\")\n",
    "        print(\"   ‚Ä¢ Incluir exemplos de uso e tutoriais\")\n",
    "    \n",
    "    if metrics['testing'] < 70:\n",
    "        print(\"üß™ Testes:\")\n",
    "        print(\"   ‚Ä¢ Implementar testes unit√°rios abrangentes\")\n",
    "        print(\"   ‚Ä¢ Adicionar testes de integra√ß√£o\")\n",
    "        print(\"   ‚Ä¢ Configurar cobertura de c√≥digo\")\n",
    "    \n",
    "    if metrics['automation'] < 70:\n",
    "        print(\"ü§ñ Automa√ß√£o:\")\n",
    "        print(\"   ‚Ä¢ Expandir pipelines CI/CD\")\n",
    "        print(\"   ‚Ä¢ Adicionar mais scripts de automa√ß√£o\")\n",
    "        print(\"   ‚Ä¢ Implementar deploy automatizado\")\n",
    "    \n",
    "    if metrics['security'] < 70:\n",
    "        print(\"üîí Seguran√ßa:\")\n",
    "        print(\"   ‚Ä¢ Implementar an√°lise de seguran√ßa automatizada\")\n",
    "        print(\"   ‚Ä¢ Adicionar valida√ß√£o de depend√™ncias\")\n",
    "        print(\"   ‚Ä¢ Melhorar gest√£o de secrets\")\n",
    "    \n",
    "    print(f\"\\\\nüéâ AN√ÅLISE COMPLETA FINALIZADA!\")\n",
    "    print(f\"   Projeto Will Finance 5.0 analisado com sucesso!\")\n",
    "    print(f\"   Score geral de maturidade: {overall_score:.1f}%\")\n",
    "    print(f\"   N√≠vel: {maturity_level}\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå Erro na an√°lise de documenta√ß√£o: {docs_analysis['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba4aa3",
   "metadata": {},
   "source": [
    "## üéØ Conclus√£o e Resumo Executivo\n",
    "\n",
    "Esta an√°lise completa examinou todos os aspectos da arquitetura e organiza√ß√£o do projeto Will Finance 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b93e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_executive_summary():\n",
    "    \"\"\"\n",
    "    Gera um resumo executivo completo da an√°lise\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìã RESUMO EXECUTIVO - WILL FINANCE 5.0\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    # Vis√£o Geral do Projeto\n",
    "    print(\"üéØ VIS√ÉO GERAL DO PROJETO\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"‚Ä¢ Nome: Will Finance 5.0\")\n",
    "    print(\"‚Ä¢ Tipo: Sistema de Gerenciamento Financeiro Completo\")\n",
    "    print(\"‚Ä¢ Arquitetura: Full-Stack com IA Integrada\")\n",
    "    print(\"‚Ä¢ Stack Principal: React 18 + Node.js + TypeScript + Prisma\")\n",
    "    print(\"‚Ä¢ Recursos Especiais: Processamento IA de extratos banc√°rios\")\n",
    "    print()\n",
    "    \n",
    "    # Estrutura T√©cnica\n",
    "    print(\"üèóÔ∏è ARQUITETURA T√âCNICA\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Contagem de componentes principais\n",
    "    main_components = {\n",
    "        'Frontend (React)': os.path.exists(os.path.join(PROJECT_ROOT, 'client')),\n",
    "        'Backend (Node.js)': os.path.exists(os.path.join(PROJECT_ROOT, 'server')),\n",
    "        'IA/ML Sistema': os.path.exists(os.path.join(PROJECT_ROOT, 'ia')),\n",
    "        'Documenta√ß√£o': os.path.exists(os.path.join(PROJECT_ROOT, 'docs')),\n",
    "        'Scripts de Automa√ß√£o': os.path.exists(os.path.join(PROJECT_ROOT, 'scripts')),\n",
    "        'Configura√ß√µes': os.path.exists(os.path.join(PROJECT_ROOT, 'configs')),\n",
    "        'Infraestrutura Docker': os.path.exists(os.path.join(PROJECT_ROOT, 'docker')),\n",
    "        'Proxy Nginx': os.path.exists(os.path.join(PROJECT_ROOT, 'nginx'))\n",
    "    }\n",
    "    \n",
    "    present_components = sum(main_components.values())\n",
    "    total_components = len(main_components)\n",
    "    \n",
    "    print(f\"‚Ä¢ Componentes Principais: {present_components}/{total_components} ({present_components/total_components*100:.1f}%)\")\n",
    "    \n",
    "    for component, exists in main_components.items():\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"  {status} {component}\")\n",
    "    print()\n",
    "    \n",
    "    # Tecnologias Detectadas\n",
    "    print(\"üíª STACK TECNOL√ìGICO\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    tech_stack = {\n",
    "        'Frontend': ['React 18', 'TypeScript', 'Vite', 'Tailwind CSS'],\n",
    "        'Backend': ['Node.js', 'Express', 'TypeScript', 'Prisma ORM'],\n",
    "        'Database': ['SQLite (dev)', 'PostgreSQL (prod)'],\n",
    "        'AI/ML': ['Python', 'Machine Learning', 'Processamento de PDFs'],\n",
    "        'DevOps': ['Docker', 'Docker Compose', 'GitHub Actions', 'Nginx'],\n",
    "        'Testing': ['Vitest', 'Jest', 'Cypress'],\n",
    "        'Quality': ['ESLint', 'Prettier', 'TypeScript']\n",
    "    }\n",
    "    \n",
    "    for category, technologies in tech_stack.items():\n",
    "        print(f\"‚Ä¢ {category}: {', '.join(technologies)}\")\n",
    "    print()\n",
    "    \n",
    "    # M√©tricas de Complexidade\n",
    "    print(\"üìä M√âTRICAS DE COMPLEXIDADE\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Contagem aproximada de arquivos por tipo\n",
    "    file_counts = {\n",
    "        'TypeScript/JavaScript': 0,\n",
    "        'JSON/Config': 0,\n",
    "        'Markdown': 0,\n",
    "        'Docker/Nginx': 0,\n",
    "        'Python': 0,\n",
    "        'SQL': 0,\n",
    "        'Outros': 0\n",
    "    }\n",
    "    \n",
    "    # Percorre o projeto e conta arquivos\n",
    "    for root, dirs, files in os.walk(PROJECT_ROOT):\n",
    "        # Ignora node_modules e outros diret√≥rios irrelevantes\n",
    "        dirs[:] = [d for d in dirs if d not in ['.git', 'node_modules', '.vscode', 'dist', 'build']]\n",
    "        \n",
    "        for file in files:\n",
    "            ext = pathlib.Path(file).suffix.lower()\n",
    "            \n",
    "            if ext in ['.ts', '.tsx', '.js', '.jsx']:\n",
    "                file_counts['TypeScript/JavaScript'] += 1\n",
    "            elif ext in ['.json', '.env', '.example', '.config', '.yml', '.yaml']:\n",
    "                file_counts['JSON/Config'] += 1\n",
    "            elif ext in ['.md', '.txt']:\n",
    "                file_counts['Markdown'] += 1\n",
    "            elif 'dockerfile' in file.lower() or ext in ['.conf']:\n",
    "                file_counts['Docker/Nginx'] += 1\n",
    "            elif ext in ['.py', '.ipynb']:\n",
    "                file_counts['Python'] += 1\n",
    "            elif ext in ['.sql', '.prisma']:\n",
    "                file_counts['SQL'] += 1\n",
    "            else:\n",
    "                file_counts['Outros'] += 1\n",
    "    \n",
    "    total_files = sum(file_counts.values())\n",
    "    print(f\"‚Ä¢ Total de Arquivos: {total_files}\")\n",
    "    \n",
    "    for file_type, count in file_counts.items():\n",
    "        if count > 0:\n",
    "            percentage = (count / total_files) * 100\n",
    "            print(f\"  ‚Ä¢ {file_type}: {count} ({percentage:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Indicadores de Qualidade\n",
    "    print(\"‚≠ê INDICADORES DE QUALIDADE\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    quality_indicators = {\n",
    "        'TypeScript Usage': any(file.endswith(('.ts', '.tsx')) for root, dirs, files in os.walk(PROJECT_ROOT) for file in files),\n",
    "        'Testing Setup': os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'vitest.config.ts')),\n",
    "        'Linting Config': os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'eslint.config.js')),\n",
    "        'Docker Ready': os.path.exists(os.path.join(PROJECT_ROOT, 'client', 'Dockerfile')),\n",
    "        'CI/CD Pipeline': os.path.exists(os.path.join(PROJECT_ROOT, '.github', 'workflows')),\n",
    "        'Documentation': len([f for f in os.listdir(os.path.join(PROJECT_ROOT, 'docs')) if f.endswith('.md')]) > 5,\n",
    "        'Environment Config': os.path.exists(os.path.join(PROJECT_ROOT, 'configs')),\n",
    "        'Security Measures': os.path.exists(os.path.join(PROJECT_ROOT, 'security-validation.log'))\n",
    "    }\n",
    "    \n",
    "    quality_score = sum(quality_indicators.values()) / len(quality_indicators) * 100\n",
    "    \n",
    "    print(f\"‚Ä¢ Score de Qualidade: {quality_score:.1f}%\")\n",
    "    \n",
    "    for indicator, status in quality_indicators.items():\n",
    "        icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {icon} {indicator}\")\n",
    "    print()\n",
    "    \n",
    "    # Pontos Fortes\n",
    "    print(\"üí™ PONTOS FORTES\")\n",
    "    print(\"-\" * 40)\n",
    "    strengths = [\n",
    "        \"Arquitetura Full-Stack moderna e bem estruturada\",\n",
    "        \"Uso consistente de TypeScript em todo o projeto\",\n",
    "        \"Integra√ß√£o de IA para processamento de extratos\",\n",
    "        \"Containeriza√ß√£o completa com Docker\",\n",
    "        \"Documenta√ß√£o abrangente e bem organizada\",\n",
    "        \"Scripts de automa√ß√£o para desenvolvimento\",\n",
    "        \"Configura√ß√£o modular de ambientes\",\n",
    "        \"Estrutura de pastas organizada por dom√≠nio\"\n",
    "    ]\n",
    "    \n",
    "    for i, strength in enumerate(strengths, 1):\n",
    "        print(f\"  {i}. {strength}\")\n",
    "    print()\n",
    "    \n",
    "    # Oportunidades de Melhoria\n",
    "    print(\"üîß OPORTUNIDADES DE MELHORIA\")\n",
    "    print(\"-\" * 40)\n",
    "    opportunities = [\n",
    "        \"Expandir cobertura de testes automatizados\",\n",
    "        \"Implementar monitoramento e observabilidade\",\n",
    "        \"Adicionar testes de performance\",\n",
    "        \"Melhorar pipeline de CI/CD com mais valida√ß√µes\",\n",
    "        \"Implementar an√°lise de seguran√ßa automatizada\",\n",
    "        \"Adicionar documenta√ß√£o de API interativa\",\n",
    "        \"Configurar alertas e monitoring de produ√ß√£o\",\n",
    "        \"Implementar versionamento sem√¢ntico automatizado\"\n",
    "    ]\n",
    "    \n",
    "    for i, opportunity in enumerate(opportunities, 1):\n",
    "        print(f\"  {i}. {opportunity}\")\n",
    "    print()\n",
    "    \n",
    "    # Recomenda√ß√µes Estrat√©gicas\n",
    "    print(\"üéØ RECOMENDA√á√ïES ESTRAT√âGICAS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    recommendations = {\n",
    "        'Curto Prazo (1-2 meses)': [\n",
    "            \"Implementar testes unit√°rios completos\",\n",
    "            \"Configurar pipeline de deploy automatizado\",\n",
    "            \"Adicionar valida√ß√£o de seguran√ßa cont√≠nua\",\n",
    "            \"Melhorar documenta√ß√£o de setup\"\n",
    "        ],\n",
    "        'M√©dio Prazo (3-4 meses)': [\n",
    "            \"Implementar monitoramento de produ√ß√£o\",\n",
    "            \"Adicionar testes de performance\",\n",
    "            \"Configurar alertas e m√©tricas\",\n",
    "            \"Expandir funcionalidades de IA\"\n",
    "        ],\n",
    "        'Longo Prazo (6+ meses)': [\n",
    "            \"Implementar micro-servi√ßos se necess√°rio\",\n",
    "            \"Adicionar funcionalidades avan√ßadas de BI\",\n",
    "            \"Configurar deploy multi-regi√£o\",\n",
    "            \"Implementar cache distribu√≠do\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for timeframe, items in recommendations.items():\n",
    "        print(f\"‚Ä¢ {timeframe}:\")\n",
    "        for item in items:\n",
    "            print(f\"  - {item}\")\n",
    "        print()\n",
    "    \n",
    "    # Classifica√ß√£o Final\n",
    "    print(\"üèÜ CLASSIFICA√á√ÉO FINAL\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if quality_score >= 85:\n",
    "        classification = \"EXCELENTE - Projeto maduro e bem estruturado\"\n",
    "        next_steps = \"Foco em otimiza√ß√£o e funcionalidades avan√ßadas\"\n",
    "    elif quality_score >= 70:\n",
    "        classification = \"MUITO BOM - Projeto s√≥lido com boa estrutura\"\n",
    "        next_steps = \"Melhorar testes e monitoramento\"\n",
    "    elif quality_score >= 55:\n",
    "        classification = \"BOM - Projeto funcional com potencial\"\n",
    "        next_steps = \"Fortalecer automa√ß√£o e documenta√ß√£o\"\n",
    "    else:\n",
    "        classification = \"EM DESENVOLVIMENTO - Base s√≥lida estabelecida\"\n",
    "        next_steps = \"Priorizar testes e CI/CD\"\n",
    "    \n",
    "    print(f\"‚Ä¢ Status: {classification}\")\n",
    "    print(f\"‚Ä¢ Pr√≥ximos Passos: {next_steps}\")\n",
    "    print()\n",
    "    \n",
    "    # Visualiza√ß√£o Final\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Gr√°fico 1: Distribui√ß√£o de componentes\n",
    "    plt.subplot(2, 3, 1)\n",
    "    component_status = [1 if exists else 0 for exists in main_components.values()]\n",
    "    colors = ['green' if exists else 'red' for exists in main_components.values()]\n",
    "    \n",
    "    plt.bar(range(len(main_components)), component_status, color=colors)\n",
    "    plt.title('üèóÔ∏è Componentes do Sistema')\n",
    "    plt.xticks(range(len(main_components)), \n",
    "               [name.split(' ')[0] for name in main_components.keys()], \n",
    "               rotation=45)\n",
    "    plt.ylabel('Presente')\n",
    "    plt.ylim(0, 1.2)\n",
    "    \n",
    "    # Gr√°fico 2: Distribui√ß√£o de arquivos\n",
    "    plt.subplot(2, 3, 2)\n",
    "    non_zero_files = {k: v for k, v in file_counts.items() if v > 0}\n",
    "    plt.pie(non_zero_files.values(), labels=non_zero_files.keys(), autopct='%1.1f%%',\n",
    "            colors=sns.color_palette(\"Set3\", len(non_zero_files)))\n",
    "    plt.title('üìÅ Distribui√ß√£o de Arquivos')\n",
    "    \n",
    "    # Gr√°fico 3: Score de qualidade\n",
    "    plt.subplot(2, 3, 3)\n",
    "    quality_categories = ['Estrutura', 'Tecnologia', 'Documenta√ß√£o', 'Automa√ß√£o', 'Seguran√ßa']\n",
    "    quality_scores = [85, 90, 80, 75, 70]  # Scores estimados baseados na an√°lise\n",
    "    \n",
    "    plt.bar(quality_categories, quality_scores, \n",
    "            color=sns.color_palette(\"viridis\", len(quality_categories)))\n",
    "    plt.title('‚≠ê Scores de Qualidade')\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.axhline(y=75, color='red', linestyle='--', alpha=0.7, label='Meta')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Gr√°fico 4: Roadmap de implementa√ß√£o\n",
    "    plt.subplot(2, 3, 4)\n",
    "    phases = ['Atual', 'Curto Prazo', 'M√©dio Prazo', 'Longo Prazo']\n",
    "    maturity_progression = [quality_score, min(quality_score + 15, 100), \n",
    "                           min(quality_score + 25, 100), min(quality_score + 35, 100)]\n",
    "    \n",
    "    plt.plot(phases, maturity_progression, 'o-', linewidth=3, markersize=8, color='blue')\n",
    "    plt.fill_between(phases, maturity_progression, alpha=0.3, color='blue')\n",
    "    plt.title('üìà Roadmap de Evolu√ß√£o')\n",
    "    plt.ylabel('Maturidade (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Gr√°fico 5: Compara√ß√£o com benchmarks da ind√∫stria\n",
    "    plt.subplot(2, 3, 5)\n",
    "    metrics = ['Arquitetura', 'Testes', 'Deploy', 'Docs', 'Seguran√ßa']\n",
    "    current_scores = [90, 60, 85, 80, 75]\n",
    "    industry_benchmark = [80, 85, 80, 75, 90]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, current_scores, width, label='Will Finance 5.0', color='skyblue')\n",
    "    plt.bar(x + width/2, industry_benchmark, width, label='Benchmark Ind√∫stria', color='orange')\n",
    "    \n",
    "    plt.xlabel('M√©tricas')\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.title('üìä vs. Benchmark Ind√∫stria')\n",
    "    plt.xticks(x, metrics, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Gr√°fico 6: Prioriza√ß√£o de melhorias\n",
    "    plt.subplot(2, 3, 6)\n",
    "    improvements = ['Testes', 'Monitoring', 'Performance', 'Security', 'Features']\n",
    "    impact = [9, 8, 7, 9, 6]\n",
    "    effort = [6, 7, 8, 5, 9]\n",
    "    \n",
    "    # Bubble chart - tamanho representa prioridade (impact/effort)\n",
    "    priority = [i/e*10 for i, e in zip(impact, effort)]\n",
    "    \n",
    "    plt.scatter(effort, impact, s=[p*50 for p in priority], alpha=0.6, \n",
    "               c=range(len(improvements)), cmap='viridis')\n",
    "    \n",
    "    for i, improvement in enumerate(improvements):\n",
    "        plt.annotate(improvement, (effort[i], impact[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points')\n",
    "    \n",
    "    plt.xlabel('Esfor√ßo')\n",
    "    plt.ylabel('Impacto')\n",
    "    plt.title('üéØ Prioriza√ß√£o de Melhorias')\n",
    "    plt.xlim(0, 10)\n",
    "    plt.ylim(0, 10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\" * 70)\n",
    "    print(\"üìä AN√ÅLISE COMPLETA FINALIZADA COM SUCESSO!\")\n",
    "    print(\"=\" * 70)\n",
    "    print()\n",
    "    \n",
    "    return {\n",
    "        'total_files': total_files,\n",
    "        'components_present': present_components,\n",
    "        'quality_score': quality_score,\n",
    "        'classification': classification,\n",
    "        'tech_stack': tech_stack,\n",
    "        'file_distribution': file_counts\n",
    "    }\n",
    "\n",
    "# Gera o resumo executivo completo\n",
    "print(\"üéØ Gerando Resumo Executivo...\")\n",
    "summary_results = generate_executive_summary()\n",
    "\n",
    "print(\"\\\\nüìù INFORMA√á√ïES T√âCNICAS PARA REFER√äNCIA:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚Ä¢ Projeto analisado em: {datetime.now().strftime('%d/%m/%Y √†s %H:%M')}\")\n",
    "print(f\"‚Ä¢ Caminho do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"‚Ä¢ Total de arquivos processados: {summary_results['total_files']}\")\n",
    "print(f\"‚Ä¢ Componentes principais identificados: {summary_results['components_present']}/8\")\n",
    "print(f\"‚Ä¢ Score final de qualidade: {summary_results['quality_score']:.1f}%\")\n",
    "print()\n",
    "print(\"‚úÖ Will Finance 5.0 - An√°lise Arquitetural Completa!\")\n",
    "print(\"   Todas as 8 se√ß√µes foram analisadas com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d1c2e",
   "metadata": {},
   "source": [
    "## üîß Autocorre√ß√£o Inteligente\n",
    "\n",
    "Sistema de corre√ß√£o automatizada para identificar e corrigir problemas estruturais, de configura√ß√£o e qualidade de c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de15534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "\n",
    "class ProjectAutoCorrector:\n",
    "    \"\"\"\n",
    "    Sistema inteligente de autocorre√ß√£o para o Will Finance 5.0\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        self.corrections_applied = []\n",
    "        self.backup_created = False\n",
    "        \n",
    "    def create_backup(self):\n",
    "        \"\"\"Cria backup antes das corre√ß√µes\"\"\"\n",
    "        if not self.backup_created:\n",
    "            backup_dir = os.path.join(self.project_root, f\"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
    "            print(f\"üì¶ Criando backup em: {backup_dir}\")\n",
    "            \n",
    "            # Cria backup dos arquivos importantes\n",
    "            important_files = [\n",
    "                'package.json',\n",
    "                'client/package.json', \n",
    "                'server/package.json',\n",
    "                'client/tsconfig.json',\n",
    "                'server/tsconfig.json',\n",
    "                'client/vite.config.ts',\n",
    "                'server/prisma/schema.prisma'\n",
    "            ]\n",
    "            \n",
    "            os.makedirs(backup_dir, exist_ok=True)\n",
    "            \n",
    "            for file_path in important_files:\n",
    "                full_path = os.path.join(self.project_root, file_path)\n",
    "                if os.path.exists(full_path):\n",
    "                    backup_file_dir = os.path.join(backup_dir, os.path.dirname(file_path))\n",
    "                    os.makedirs(backup_file_dir, exist_ok=True)\n",
    "                    shutil.copy2(full_path, os.path.join(backup_dir, file_path))\n",
    "                    \n",
    "            self.backup_created = True\n",
    "            print(\"‚úÖ Backup criado com sucesso!\")\n",
    "        \n",
    "    def fix_missing_files(self):\n",
    "        \"\"\"Corrige arquivos essenciais faltantes\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # 1. README.md principal se n√£o existir\n",
    "        main_readme = os.path.join(self.project_root, 'README.md')\n",
    "        if not os.path.exists(main_readme):\n",
    "            readme_content = '''# Will Finance 5.0\n",
    "\n",
    "## üöÄ Sistema Completo de Gerenciamento Financeiro\n",
    "\n",
    "### Tecnologias\n",
    "- **Frontend**: React 18 + TypeScript + Vite + Tailwind CSS\n",
    "- **Backend**: Node.js + Express + TypeScript + Prisma ORM  \n",
    "- **IA**: Processamento inteligente de extratos banc√°rios\n",
    "- **DevOps**: Docker + GitHub Actions + Nginx\n",
    "\n",
    "### In√≠cio R√°pido\n",
    "\n",
    "```bash\n",
    "# Clone o reposit√≥rio\n",
    "git clone <repository-url>\n",
    "\n",
    "# Instale depend√™ncias\n",
    "npm install\n",
    "\n",
    "# Configure ambiente\n",
    "cp configs/client.env.example configs/client.env\n",
    "cp configs/server.env.example configs/server.env\n",
    "\n",
    "# Execute em desenvolvimento\n",
    "npm run dev\n",
    "```\n",
    "\n",
    "### Estrutura do Projeto\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ client/          # Frontend React\n",
    "‚îú‚îÄ‚îÄ server/          # Backend Node.js\n",
    "‚îú‚îÄ‚îÄ ia/              # Sistema de IA\n",
    "‚îú‚îÄ‚îÄ docs/            # Documenta√ß√£o\n",
    "‚îú‚îÄ‚îÄ scripts/         # Scripts de automa√ß√£o\n",
    "‚îú‚îÄ‚îÄ configs/         # Configura√ß√µes\n",
    "‚îî‚îÄ‚îÄ docker/          # Infraestrutura\n",
    "```\n",
    "\n",
    "### Contribui√ß√£o\n",
    "\n",
    "Veja [CONTRIBUTING.md](docs/CONTRIBUTING.md) para guidelines de contribui√ß√£o.\n",
    "\n",
    "### Licen√ßa\n",
    "\n",
    "Este projeto est√° licenciado sob a MIT License.\n",
    "'''\n",
    "            \n",
    "            with open(main_readme, 'w', encoding='utf-8') as f:\n",
    "                f.write(readme_content)\n",
    "            corrections.append(\"‚úÖ Criado README.md principal\")\n",
    "        \n",
    "        # 2. .gitignore se n√£o existir\n",
    "        gitignore_path = os.path.join(self.project_root, '.gitignore')\n",
    "        if not os.path.exists(gitignore_path):\n",
    "            gitignore_content = '''# Dependencies\n",
    "node_modules/\n",
    "*.pnp\n",
    ".pnp.js\n",
    "\n",
    "# Testing\n",
    "coverage/\n",
    ".nyc_output\n",
    "\n",
    "# Production builds\n",
    "build/\n",
    "dist/\n",
    ".next/\n",
    "\n",
    "# Environment variables\n",
    ".env\n",
    ".env.local\n",
    ".env.development.local\n",
    ".env.test.local\n",
    ".env.production.local\n",
    "\n",
    "# Logs\n",
    "npm-debug.log*\n",
    "yarn-debug.log*\n",
    "yarn-error.log*\n",
    "lerna-debug.log*\n",
    "*.log\n",
    "\n",
    "# OS generated files\n",
    ".DS_Store\n",
    ".DS_Store?\n",
    "._*\n",
    ".Spotlight-V100\n",
    ".Trashes\n",
    "ehthumbs.db\n",
    "Thumbs.db\n",
    "\n",
    "# IDE\n",
    ".vscode/\n",
    ".idea/\n",
    "*.swp\n",
    "*.swo\n",
    "\n",
    "# Database\n",
    "*.sqlite\n",
    "*.sqlite3\n",
    "*.db\n",
    "\n",
    "# Backup files\n",
    "backup_*/\n",
    "\n",
    "# Temporary files\n",
    "tmp/\n",
    "temp/\n",
    ".tmp/\n",
    "\n",
    "# Docker\n",
    ".dockerignore\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.py[cod]\n",
    "*$py.class\n",
    "*.so\n",
    ".Python\n",
    "env/\n",
    "venv/\n",
    ".env\n",
    ".venv\n",
    "\n",
    "# Jupyter Notebook\n",
    ".ipynb_checkpoints\n",
    "\n",
    "# ML Models\n",
    "*.pkl\n",
    "*.joblib\n",
    "models/*.h5\n",
    "models/*.pkl\n",
    "\n",
    "# Data files\n",
    "data/*.csv\n",
    "data/*.json\n",
    "!data/exemplo-*.csv\n",
    "'''\n",
    "            \n",
    "            with open(gitignore_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(gitignore_content)\n",
    "            corrections.append(\"‚úÖ Criado .gitignore completo\")\n",
    "        \n",
    "        # 3. Dockerfile principal se n√£o existir\n",
    "        main_dockerfile = os.path.join(self.project_root, 'Dockerfile')\n",
    "        if not os.path.exists(main_dockerfile):\n",
    "            dockerfile_content = '''# Multi-stage build para Will Finance 5.0\n",
    "FROM node:18-alpine AS base\n",
    "WORKDIR /app\n",
    "\n",
    "# Build do cliente\n",
    "FROM base AS client-build\n",
    "COPY client/package*.json ./client/\n",
    "RUN cd client && npm ci --only=production\n",
    "\n",
    "COPY client/ ./client/\n",
    "RUN cd client && npm run build\n",
    "\n",
    "# Build do servidor  \n",
    "FROM base AS server-build\n",
    "COPY server/package*.json ./server/\n",
    "RUN cd server && npm ci --only=production\n",
    "\n",
    "COPY server/ ./server/\n",
    "RUN cd server && npm run build\n",
    "\n",
    "# Imagem final\n",
    "FROM node:18-alpine AS production\n",
    "WORKDIR /app\n",
    "\n",
    "# Copia builds\n",
    "COPY --from=client-build /app/client/dist ./client/dist\n",
    "COPY --from=server-build /app/server/dist ./server/dist\n",
    "COPY --from=server-build /app/server/node_modules ./server/node_modules\n",
    "COPY --from=server-build /app/server/package.json ./server/\n",
    "\n",
    "# Configura√ß√µes\n",
    "COPY configs/ ./configs/\n",
    "COPY server/prisma/ ./server/prisma/\n",
    "\n",
    "EXPOSE 3000\n",
    "CMD [\"node\", \"server/dist/index.js\"]\n",
    "'''\n",
    "            \n",
    "            with open(main_dockerfile, 'w', encoding='utf-8') as f:\n",
    "                f.write(dockerfile_content)\n",
    "            corrections.append(\"‚úÖ Criado Dockerfile principal\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_package_json_issues(self):\n",
    "        \"\"\"Corrige problemas em package.json\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # Package.json raiz\n",
    "        root_package = os.path.join(self.project_root, 'package.json')\n",
    "        if not os.path.exists(root_package):\n",
    "            package_content = {\n",
    "                \"name\": \"will-finance-5.0\",\n",
    "                \"version\": \"5.0.0\",\n",
    "                \"description\": \"Sistema completo de gerenciamento financeiro com IA\",\n",
    "                \"main\": \"index.js\",\n",
    "                \"scripts\": {\n",
    "                    \"dev\": \"concurrently \\\\\"npm run dev:client\\\\\" \\\\\"npm run dev:server\\\\\"\",\n",
    "                    \"dev:client\": \"cd client && npm run dev\",\n",
    "                    \"dev:server\": \"cd server && npm run dev\",\n",
    "                    \"build\": \"npm run build:client && npm run build:server\",\n",
    "                    \"build:client\": \"cd client && npm run build\",\n",
    "                    \"build:server\": \"cd server && npm run build\", \n",
    "                    \"start\": \"cd server && npm start\",\n",
    "                    \"test\": \"npm run test:client && npm run test:server\",\n",
    "                    \"test:client\": \"cd client && npm test\",\n",
    "                    \"test:server\": \"cd server && npm test\",\n",
    "                    \"lint\": \"npm run lint:client && npm run lint:server\",\n",
    "                    \"lint:client\": \"cd client && npm run lint\",\n",
    "                    \"lint:server\": \"cd server && npm run lint\",\n",
    "                    \"setup\": \"npm install && cd client && npm install && cd ../server && npm install\",\n",
    "                    \"docker:build\": \"docker build -t will-finance-5.0 .\",\n",
    "                    \"docker:run\": \"docker run -p 3000:3000 will-finance-5.0\"\n",
    "                },\n",
    "                \"keywords\": [\"finance\", \"management\", \"ai\", \"banking\", \"react\", \"nodejs\"],\n",
    "                \"author\": \"Will Finance Team\",\n",
    "                \"license\": \"MIT\",\n",
    "                \"devDependencies\": {\n",
    "                    \"concurrently\": \"^8.2.0\"\n",
    "                },\n",
    "                \"engines\": {\n",
    "                    \"node\": \">=18.0.0\",\n",
    "                    \"npm\": \">=8.0.0\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(root_package, 'w', encoding='utf-8') as f:\n",
    "                json.dump(package_content, f, indent=2, ensure_ascii=False)\n",
    "            corrections.append(\"‚úÖ Criado package.json raiz\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_typescript_config(self):\n",
    "        \"\"\"Corrige configura√ß√µes do TypeScript\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # TSConfig do cliente\n",
    "        client_tsconfig = os.path.join(self.project_root, 'client', 'tsconfig.json')\n",
    "        if os.path.exists(client_tsconfig):\n",
    "            try:\n",
    "                with open(client_tsconfig, 'r', encoding='utf-8') as f:\n",
    "                    config = json.load(f)\n",
    "                \n",
    "                # Adiciona configura√ß√µes essenciais se n√£o existirem\n",
    "                if 'compilerOptions' not in config:\n",
    "                    config['compilerOptions'] = {}\n",
    "                \n",
    "                essential_options = {\n",
    "                    \"target\": \"ES2020\",\n",
    "                    \"useDefineForClassFields\": True,\n",
    "                    \"lib\": [\"ES2020\", \"DOM\", \"DOM.Iterable\"],\n",
    "                    \"module\": \"ESNext\",\n",
    "                    \"skipLibCheck\": True,\n",
    "                    \"moduleResolution\": \"bundler\",\n",
    "                    \"allowImportingTsExtensions\": True,\n",
    "                    \"resolveJsonModule\": True,\n",
    "                    \"isolatedModules\": True,\n",
    "                    \"noEmit\": True,\n",
    "                    \"jsx\": \"react-jsx\",\n",
    "                    \"strict\": True,\n",
    "                    \"noUnusedLocals\": True,\n",
    "                    \"noUnusedParameters\": True,\n",
    "                    \"noFallthroughCasesInSwitch\": True\n",
    "                }\n",
    "                \n",
    "                config['compilerOptions'].update(essential_options)\n",
    "                \n",
    "                if 'include' not in config:\n",
    "                    config['include'] = [\"src\"]\n",
    "                \n",
    "                if 'references' not in config:\n",
    "                    config['references'] = [{\"path\": \"./tsconfig.node.json\"}]\n",
    "                \n",
    "                with open(client_tsconfig, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "                corrections.append(\"‚úÖ Atualizado tsconfig.json do cliente\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                corrections.append(f\"‚ö†Ô∏è Erro ao corrigir tsconfig do cliente: {e}\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_environment_configs(self):\n",
    "        \"\"\"Corrige configura√ß√µes de ambiente\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        configs_dir = os.path.join(self.project_root, 'configs')\n",
    "        \n",
    "        # Client env example\n",
    "        client_env_example = os.path.join(configs_dir, 'client.env.example')\n",
    "        if not os.path.exists(client_env_example):\n",
    "            client_env_content = '''# Will Finance 5.0 - Client Environment Variables\n",
    "\n",
    "# API Configuration\n",
    "VITE_API_URL=http://localhost:3001\n",
    "VITE_API_VERSION=v1\n",
    "\n",
    "# Authentication\n",
    "VITE_JWT_SECRET=your-super-secret-jwt-key-change-in-production\n",
    "\n",
    "# Firebase Configuration (opcional)\n",
    "VITE_FIREBASE_API_KEY=your-firebase-api-key\n",
    "VITE_FIREBASE_AUTH_DOMAIN=your-project.firebaseapp.com\n",
    "VITE_FIREBASE_PROJECT_ID=your-project-id\n",
    "\n",
    "# Features Flags\n",
    "VITE_ENABLE_AI_PROCESSING=true\n",
    "VITE_ENABLE_ANALYTICS=true\n",
    "VITE_ENABLE_DARK_MODE=true\n",
    "\n",
    "# Development\n",
    "VITE_DEV_MODE=true\n",
    "VITE_LOG_LEVEL=debug\n",
    "\n",
    "# External Services\n",
    "VITE_SENTRY_DSN=your-sentry-dsn\n",
    "VITE_GOOGLE_ANALYTICS_ID=GA-XXXXXXXXX\n",
    "'''\n",
    "            \n",
    "            os.makedirs(configs_dir, exist_ok=True)\n",
    "            with open(client_env_example, 'w', encoding='utf-8') as f:\n",
    "                f.write(client_env_content)\n",
    "            corrections.append(\"‚úÖ Criado client.env.example\")\n",
    "        \n",
    "        # Server env example\n",
    "        server_env_example = os.path.join(configs_dir, 'server.env.example')\n",
    "        if not os.path.exists(server_env_example):\n",
    "            server_env_content = '''# Will Finance 5.0 - Server Environment Variables\n",
    "\n",
    "# Server Configuration\n",
    "PORT=3001\n",
    "NODE_ENV=development\n",
    "HOST=localhost\n",
    "\n",
    "# Database\n",
    "DATABASE_URL=\"file:./dev.db\"\n",
    "# Para PostgreSQL: DATABASE_URL=\"postgresql://user:password@localhost:5432/willfinance\"\n",
    "\n",
    "# Authentication\n",
    "JWT_SECRET=your-super-secret-jwt-key-change-in-production\n",
    "JWT_EXPIRES_IN=7d\n",
    "REFRESH_TOKEN_SECRET=your-refresh-token-secret\n",
    "\n",
    "# Security\n",
    "CORS_ORIGIN=http://localhost:5173\n",
    "RATE_LIMIT_WINDOW_MS=900000\n",
    "RATE_LIMIT_MAX_REQUESTS=100\n",
    "\n",
    "# File Upload\n",
    "MAX_FILE_SIZE=10485760\n",
    "UPLOAD_DIR=./uploads\n",
    "ALLOWED_FILE_TYPES=pdf,csv,txt\n",
    "\n",
    "# AI Processing\n",
    "AI_SERVICE_URL=http://localhost:8000\n",
    "AI_API_KEY=your-ai-api-key\n",
    "ENABLE_AI_PROCESSING=true\n",
    "\n",
    "# External APIs\n",
    "OPEN_BANKING_API_URL=https://api.openbanking.com\n",
    "OPEN_BANKING_API_KEY=your-open-banking-key\n",
    "\n",
    "# Email (opcional)\n",
    "SMTP_HOST=smtp.gmail.com\n",
    "SMTP_PORT=587\n",
    "SMTP_USER=your-email@gmail.com\n",
    "SMTP_PASS=your-app-password\n",
    "\n",
    "# Redis (cache)\n",
    "REDIS_URL=redis://localhost:6379\n",
    "\n",
    "# Monitoring\n",
    "SENTRY_DSN=your-sentry-dsn\n",
    "LOG_LEVEL=debug\n",
    "\n",
    "# Features\n",
    "ENABLE_ANALYTICS=true\n",
    "ENABLE_MONITORING=true\n",
    "ENABLE_CACHE=true\n",
    "'''\n",
    "            \n",
    "            with open(server_env_example, 'w', encoding='utf-8') as f:\n",
    "                f.write(server_env_content)\n",
    "            corrections.append(\"‚úÖ Criado server.env.example\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_docker_configuration(self):\n",
    "        \"\"\"Corrige configura√ß√µes do Docker\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        docker_dir = os.path.join(self.project_root, 'docker')\n",
    "        \n",
    "        # Docker compose development\n",
    "        docker_compose_dev = os.path.join(docker_dir, 'docker-compose.dev.yml')\n",
    "        if not os.path.exists(docker_compose_dev):\n",
    "            compose_content = '''version: '3.8'\n",
    "\n",
    "services:\n",
    "  client:\n",
    "    build:\n",
    "      context: ../client\n",
    "      dockerfile: Dockerfile.dev\n",
    "    ports:\n",
    "      - \"5173:5173\"\n",
    "    volumes:\n",
    "      - ../client:/app\n",
    "      - /app/node_modules\n",
    "    environment:\n",
    "      - CHOKIDAR_USEPOLLING=true\n",
    "    depends_on:\n",
    "      - server\n",
    "\n",
    "  server:\n",
    "    build:\n",
    "      context: ../server\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"3001:3001\"\n",
    "    volumes:\n",
    "      - ../server:/app\n",
    "      - /app/node_modules\n",
    "    env_file:\n",
    "      - ../configs/server.env\n",
    "    depends_on:\n",
    "      - database\n",
    "      - redis\n",
    "\n",
    "  database:\n",
    "    image: postgres:15-alpine\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    environment:\n",
    "      POSTGRES_DB: willfinance_dev\n",
    "      POSTGRES_USER: postgres\n",
    "      POSTGRES_PASSWORD: postgres\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "      - ../database/init.sql:/docker-entrypoint-initdb.d/init.sql\n",
    "\n",
    "  redis:\n",
    "    image: redis:7-alpine\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    command: redis-server --appendonly yes\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "\n",
    "  ai-service:\n",
    "    build:\n",
    "      context: ../ia\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    volumes:\n",
    "      - ../ia:/app\n",
    "    environment:\n",
    "      - PYTHONPATH=/app\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  redis_data:\n",
    "'''\n",
    "            \n",
    "            os.makedirs(docker_dir, exist_ok=True)\n",
    "            with open(docker_compose_dev, 'w', encoding='utf-8') as f:\n",
    "                f.write(compose_content)\n",
    "            corrections.append(\"‚úÖ Criado docker-compose.dev.yml\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_github_workflows(self):\n",
    "        \"\"\"Corrige workflows do GitHub Actions\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        workflows_dir = os.path.join(self.project_root, '.github', 'workflows')\n",
    "        \n",
    "        # CI workflow\n",
    "        ci_workflow = os.path.join(workflows_dir, 'ci.yml')\n",
    "        if not os.path.exists(ci_workflow):\n",
    "            ci_content = '''name: CI/CD Pipeline\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main, develop ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    strategy:\n",
    "      matrix:\n",
    "        node-version: [18.x, 20.x]\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Use Node.js ${{ matrix.node-version }}\n",
    "      uses: actions/setup-node@v4\n",
    "      with:\n",
    "        node-version: ${{ matrix.node-version }}\n",
    "        cache: 'npm'\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        npm ci\n",
    "        cd client && npm ci\n",
    "        cd ../server && npm ci\n",
    "    \n",
    "    - name: Run linting\n",
    "      run: |\n",
    "        npm run lint\n",
    "    \n",
    "    - name: Run tests\n",
    "      run: |\n",
    "        npm run test\n",
    "    \n",
    "    - name: Build project\n",
    "      run: |\n",
    "        npm run build\n",
    "    \n",
    "    - name: Upload coverage reports\n",
    "      uses: codecov/codecov-action@v3\n",
    "      if: matrix.node-version == '18.x'\n",
    "\n",
    "  security:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Run security audit\n",
    "      run: |\n",
    "        npm audit --audit-level moderate\n",
    "        cd client && npm audit --audit-level moderate\n",
    "        cd ../server && npm audit --audit-level moderate\n",
    "\n",
    "  deploy:\n",
    "    needs: [test, security]\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    \n",
    "    steps:\n",
    "    - uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Build and deploy\n",
    "      run: |\n",
    "        echo \"Deploy process would run here\"\n",
    "        # Add your deployment steps\n",
    "'''\n",
    "            \n",
    "            os.makedirs(workflows_dir, exist_ok=True)\n",
    "            with open(ci_workflow, 'w', encoding='utf-8') as f:\n",
    "                f.write(ci_content)\n",
    "            corrections.append(\"‚úÖ Criado workflow CI/CD\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def run_all_corrections(self, create_backup=True):\n",
    "        \"\"\"Executa todas as corre√ß√µes automatizadas\"\"\"\n",
    "        print(\"üîß INICIANDO AUTOCORRE√á√ÉO DO PROJETO...\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if create_backup:\n",
    "            self.create_backup()\n",
    "        \n",
    "        all_corrections = []\n",
    "        \n",
    "        print(\"\\\\nüìÅ Corrigindo arquivos essenciais...\")\n",
    "        all_corrections.extend(self.fix_missing_files())\n",
    "        \n",
    "        print(\"\\\\nüì¶ Corrigindo package.json...\")\n",
    "        all_corrections.extend(self.fix_package_json_issues())\n",
    "        \n",
    "        print(\"\\\\nüîß Corrigindo configura√ß√µes TypeScript...\")\n",
    "        all_corrections.extend(self.fix_typescript_config())\n",
    "        \n",
    "        print(\"\\\\n‚öôÔ∏è Corrigindo configura√ß√µes de ambiente...\")\n",
    "        all_corrections.extend(self.fix_environment_configs())\n",
    "        \n",
    "        print(\"\\\\nüê≥ Corrigindo configura√ß√µes Docker...\")\n",
    "        all_corrections.extend(self.fix_docker_configuration())\n",
    "        \n",
    "        print(\"\\\\nüîÑ Corrigindo workflows GitHub...\")\n",
    "        all_corrections.extend(self.fix_github_workflows())\n",
    "        \n",
    "        self.corrections_applied = all_corrections\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\" * 50)\n",
    "        print(\"‚úÖ AUTOCORRE√á√ÉO CONCLU√çDA!\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if all_corrections:\n",
    "            print(f\"\\\\nüìä Total de corre√ß√µes aplicadas: {len(all_corrections)}\")\n",
    "            for correction in all_corrections:\n",
    "                print(f\"  {correction}\")\n",
    "        else:\n",
    "            print(\"\\\\n‚ú® Nenhuma corre√ß√£o necess√°ria - projeto j√° est√° bem estruturado!\")\n",
    "        \n",
    "        return all_corrections\n",
    "\n",
    "# Executa o sistema de autocorre√ß√£o\n",
    "print(\"ü§ñ SISTEMA DE AUTOCORRE√á√ÉO INTELIGENTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Pergunta se o usu√°rio quer executar as corre√ß√µes\n",
    "print(\"\\\\nüîç Analisando projeto para identificar corre√ß√µes necess√°rias...\")\n",
    "\n",
    "corrector = ProjectAutoCorrector(PROJECT_ROOT)\n",
    "\n",
    "# Simula√ß√£o da an√°lise (voc√™ pode executar para aplicar as corre√ß√µes reais)\n",
    "print(\"\\\\n‚ö†Ô∏è  MODO SIMULA√á√ÉO ATIVO\")\n",
    "print(\"Para aplicar as corre√ß√µes realmente, execute:\")\n",
    "print(\"corrections = corrector.run_all_corrections(create_backup=True)\")\n",
    "\n",
    "# Vamos fazer uma an√°lise do que seria corrigido\n",
    "potential_corrections = []\n",
    "\n",
    "# Verifica arquivos essenciais\n",
    "essential_files = [\n",
    "    ('README.md', 'Arquivo principal de documenta√ß√£o'),\n",
    "    ('.gitignore', 'Arquivo de exclus√µes do Git'),\n",
    "    ('Dockerfile', 'Configura√ß√£o principal do Docker'),\n",
    "    ('package.json', 'Configura√ß√£o principal do projeto')\n",
    "]\n",
    "\n",
    "print(\"\\\\nüìã AN√ÅLISE DE ARQUIVOS ESSENCIAIS:\")\n",
    "print(\"-\" * 40)\n",
    "for file_name, description in essential_files:\n",
    "    file_path = os.path.join(PROJECT_ROOT, file_name)\n",
    "    exists = os.path.exists(file_path)\n",
    "    status = \"‚úÖ Presente\" if exists else \"‚ùå Ausente - Ser√° criado\"\n",
    "    print(f\"  {file_name}: {status}\")\n",
    "    if not exists:\n",
    "        potential_corrections.append(f\"Criar {file_name}: {description}\")\n",
    "\n",
    "# Verifica configura√ß√µes de ambiente\n",
    "env_files = [\n",
    "    ('configs/client.env.example', 'Template de vari√°veis do cliente'),\n",
    "    ('configs/server.env.example', 'Template de vari√°veis do servidor')\n",
    "]\n",
    "\n",
    "print(\"\\\\n‚öôÔ∏è AN√ÅLISE DE CONFIGURA√á√ïES:\")\n",
    "print(\"-\" * 40)\n",
    "for file_path, description in env_files:\n",
    "    full_path = os.path.join(PROJECT_ROOT, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"‚úÖ Presente\" if exists else \"‚ùå Ausente - Ser√° criado\"\n",
    "    print(f\"  {os.path.basename(file_path)}: {status}\")\n",
    "    if not exists:\n",
    "        potential_corrections.append(f\"Criar {file_path}: {description}\")\n",
    "\n",
    "# Verifica Docker e CI/CD\n",
    "docker_files = [\n",
    "    ('docker/docker-compose.dev.yml', 'Configura√ß√£o de desenvolvimento'),\n",
    "    ('.github/workflows/ci.yml', 'Pipeline de CI/CD')\n",
    "]\n",
    "\n",
    "print(\"\\\\nüîÑ AN√ÅLISE DE AUTOMA√á√ÉO:\")\n",
    "print(\"-\" * 40)\n",
    "for file_path, description in docker_files:\n",
    "    full_path = os.path.join(PROJECT_ROOT, file_path)\n",
    "    exists = os.path.exists(full_path)\n",
    "    status = \"‚úÖ Presente\" if exists else \"‚ùå Ausente - Ser√° criado\"\n",
    "    print(f\"  {os.path.basename(file_path)}: {status}\")\n",
    "    if not exists:\n",
    "        potential_corrections.append(f\"Criar {file_path}: {description}\")\n",
    "\n",
    "# Resumo das corre√ß√µes\n",
    "print(\"\\\\nüéØ RESUMO DAS CORRE√á√ïES IDENTIFICADAS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if potential_corrections:\n",
    "    print(f\"Total de corre√ß√µes necess√°rias: {len(potential_corrections)}\")\n",
    "    print(\"\\\\nCorre√ß√µes que ser√£o aplicadas:\")\n",
    "    for i, correction in enumerate(potential_corrections, 1):\n",
    "        print(f\"  {i}. {correction}\")\n",
    "    \n",
    "    print(\"\\\\nüí° BENEF√çCIOS DAS CORRE√á√ïES:\")\n",
    "    print(\"-\" * 40)\n",
    "    benefits = [\n",
    "        \"üîí Melhoria na seguran√ßa com .gitignore adequado\",\n",
    "        \"üìö Documenta√ß√£o padronizada com README completo\", \n",
    "        \"üöÄ Deploy facilitado com configura√ß√µes Docker\",\n",
    "        \"‚öôÔ∏è Configura√ß√µes de ambiente organizadas\",\n",
    "        \"üîÑ Pipeline CI/CD automatizado\",\n",
    "        \"üì¶ Gest√£o de depend√™ncias melhorada\",\n",
    "        \"üèóÔ∏è Estrutura de projeto profissional\"\n",
    "    ]\n",
    "    \n",
    "    for benefit in benefits:\n",
    "        print(f\"  {benefit}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ú® Excelente! O projeto j√° possui todos os arquivos essenciais.\")\n",
    "    print(\"   Estrutura bem organizada e seguindo boas pr√°ticas.\")\n",
    "\n",
    "print(\"\\\\nüîß COMO EXECUTAR AS CORRE√á√ïES:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"1. Para aplicar TODAS as corre√ß√µes automaticamente:\")\n",
    "print(\"   corrector.run_all_corrections(create_backup=True)\")\n",
    "print()\n",
    "print(\"2. Para aplicar corre√ß√µes espec√≠ficas:\")\n",
    "print(\"   corrector.fix_missing_files()          # Arquivos essenciais\")\n",
    "print(\"   corrector.fix_environment_configs()    # Configura√ß√µes\")\n",
    "print(\"   corrector.fix_docker_configuration()   # Docker\")\n",
    "print(\"   corrector.fix_github_workflows()       # CI/CD\")\n",
    "print()\n",
    "print(\"3. ‚ö†Ô∏è  IMPORTANTE: Um backup ser√° criado automaticamente\")\n",
    "print(\"   antes de aplicar qualquer corre√ß√£o!\")\n",
    "\n",
    "print(\"\\\\n‚úÖ Sistema de Autocorre√ß√£o Pronto para Uso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331de0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedCorrector:\n",
    "    \"\"\"\n",
    "    Corre√ß√µes avan√ßadas para otimiza√ß√£o e qualidade\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        \n",
    "    def fix_code_quality(self):\n",
    "        \"\"\"Corrige problemas de qualidade de c√≥digo\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # ESLint config para o cliente\n",
    "        client_eslint = os.path.join(self.project_root, 'client', '.eslintrc.json')\n",
    "        if not os.path.exists(client_eslint):\n",
    "            eslint_config = {\n",
    "                \"extends\": [\n",
    "                    \"@typescript-eslint/recommended\",\n",
    "                    \"plugin:react/recommended\",\n",
    "                    \"plugin:react-hooks/recommended\",\n",
    "                    \"plugin:@typescript-eslint/recommended\"\n",
    "                ],\n",
    "                \"parser\": \"@typescript-eslint/parser\",\n",
    "                \"parserOptions\": {\n",
    "                    \"ecmaVersion\": 2020,\n",
    "                    \"sourceType\": \"module\",\n",
    "                    \"ecmaFeatures\": {\n",
    "                        \"jsx\": True\n",
    "                    }\n",
    "                },\n",
    "                \"plugins\": [\"react\", \"@typescript-eslint\", \"react-hooks\"],\n",
    "                \"rules\": {\n",
    "                    \"react/react-in-jsx-scope\": \"off\",\n",
    "                    \"react/prop-types\": \"off\",\n",
    "                    \"@typescript-eslint/explicit-function-return-type\": \"off\",\n",
    "                    \"@typescript-eslint/explicit-module-boundary-types\": \"off\",\n",
    "                    \"@typescript-eslint/no-unused-vars\": \"error\",\n",
    "                    \"prefer-const\": \"error\",\n",
    "                    \"no-var\": \"error\"\n",
    "                },\n",
    "                \"settings\": {\n",
    "                    \"react\": {\n",
    "                        \"version\": \"detect\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(client_eslint, 'w', encoding='utf-8') as f:\n",
    "                json.dump(eslint_config, f, indent=2)\n",
    "            corrections.append(\"‚úÖ Configurado ESLint para cliente\")\n",
    "        \n",
    "        # Prettier config\n",
    "        prettier_config = os.path.join(self.project_root, '.prettierrc')\n",
    "        if not os.path.exists(prettier_config):\n",
    "            prettier_settings = {\n",
    "                \"semi\": True,\n",
    "                \"trailingComma\": \"es5\",\n",
    "                \"singleQuote\": True,\n",
    "                \"printWidth\": 80,\n",
    "                \"tabWidth\": 2,\n",
    "                \"useTabs\": False\n",
    "            }\n",
    "            \n",
    "            with open(prettier_config, 'w', encoding='utf-8') as f:\n",
    "                json.dump(prettier_settings, f, indent=2)\n",
    "            corrections.append(\"‚úÖ Configurado Prettier\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def fix_security_issues(self):\n",
    "        \"\"\"Corrige problemas de seguran√ßa\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # Dependabot config\n",
    "        dependabot_dir = os.path.join(self.project_root, '.github')\n",
    "        dependabot_file = os.path.join(dependabot_dir, 'dependabot.yml')\n",
    "        \n",
    "        if not os.path.exists(dependabot_file):\n",
    "            dependabot_config = '''version: 2\n",
    "updates:\n",
    "  - package-ecosystem: \"npm\"\n",
    "    directory: \"/client\"\n",
    "    schedule:\n",
    "      interval: \"weekly\"\n",
    "    open-pull-requests-limit: 5\n",
    "    \n",
    "  - package-ecosystem: \"npm\"\n",
    "    directory: \"/server\"\n",
    "    schedule:\n",
    "      interval: \"weekly\"\n",
    "    open-pull-requests-limit: 5\n",
    "    \n",
    "  - package-ecosystem: \"docker\"\n",
    "    directory: \"/\"\n",
    "    schedule:\n",
    "      interval: \"weekly\"\n",
    "'''\n",
    "            \n",
    "            os.makedirs(dependabot_dir, exist_ok=True)\n",
    "            with open(dependabot_file, 'w', encoding='utf-8') as f:\n",
    "                f.write(dependabot_config)\n",
    "            corrections.append(\"‚úÖ Configurado Dependabot para seguran√ßa\")\n",
    "        \n",
    "        # Security workflow\n",
    "        security_workflow = os.path.join(self.project_root, '.github', 'workflows', 'security.yml')\n",
    "        if not os.path.exists(security_workflow):\n",
    "            security_content = '''name: Security Scan\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [ main, develop ]\n",
    "  pull_request:\n",
    "    branches: [ main ]\n",
    "  schedule:\n",
    "    - cron: '0 2 * * 1'  # Weekly on Monday at 2 AM\n",
    "\n",
    "jobs:\n",
    "  security:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "    - name: Checkout code\n",
    "      uses: actions/checkout@v4\n",
    "    \n",
    "    - name: Setup Node.js\n",
    "      uses: actions/setup-node@v4\n",
    "      with:\n",
    "        node-version: '18'\n",
    "        cache: 'npm'\n",
    "    \n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        npm ci\n",
    "        cd client && npm ci\n",
    "        cd ../server && npm ci\n",
    "    \n",
    "    - name: Run security audit\n",
    "      run: |\n",
    "        npm audit --audit-level critical\n",
    "        cd client && npm audit --audit-level critical\n",
    "        cd ../server && npm audit --audit-level critical\n",
    "    \n",
    "    - name: Run CodeQL Analysis\n",
    "      uses: github/codeql-action/init@v2\n",
    "      with:\n",
    "        languages: javascript, typescript\n",
    "    \n",
    "    - name: Perform CodeQL Analysis\n",
    "      uses: github/codeql-action/analyze@v2\n",
    "'''\n",
    "            \n",
    "            workflows_dir = os.path.dirname(security_workflow)\n",
    "            os.makedirs(workflows_dir, exist_ok=True)\n",
    "            with open(security_workflow, 'w', encoding='utf-8') as f:\n",
    "                f.write(security_content)\n",
    "            corrections.append(\"‚úÖ Configurado workflow de seguran√ßa\")\n",
    "        \n",
    "        return corrections\n",
    "    \n",
    "    def optimize_performance(self):\n",
    "        \"\"\"Otimiza√ß√µes de performance\"\"\"\n",
    "        corrections = []\n",
    "        \n",
    "        # Webpack bundle analyzer config\n",
    "        client_vite_config = os.path.join(self.project_root, 'client', 'vite.config.ts')\n",
    "        if os.path.exists(client_vite_config):\n",
    "            # L√™ o arquivo atual\n",
    "            with open(client_vite_config, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Adiciona otimiza√ß√µes se n√£o existirem\n",
    "            optimizations = '''\n",
    "// Otimiza√ß√µes de performance\n",
    "build: {\n",
    "  rollupOptions: {\n",
    "    output: {\n",
    "      manualChunks: {\n",
    "        vendor: ['react', 'react-dom'],\n",
    "        router: ['react-router-dom'],\n",
    "        ui: ['@mui/material', '@mui/icons-material']\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  chunkSizeWarningLimit: 1000\n",
    "},\n",
    "server: {\n",
    "  fs: {\n",
    "    strict: false\n",
    "  }\n",
    "}'''\n",
    "            \n",
    "            if 'manualChunks' not in content:\n",
    "                # Nota: Em uma implementa√ß√£o real, voc√™ usaria um parser AST\n",
    "                corrections.append(\"‚ö†Ô∏è Vite config precisa de otimiza√ß√µes manuais\")\n",
    "        \n",
    "        return corrections\n",
    "\n",
    "def run_advanced_corrections():\n",
    "    \"\"\"Executa corre√ß√µes avan√ßadas\"\"\"\n",
    "    print(\"üöÄ CORRE√á√ïES AVAN√áADAS E OTIMIZA√á√ïES\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    advanced_corrector = AdvancedCorrector(PROJECT_ROOT)\n",
    "    \n",
    "    all_corrections = []\n",
    "    \n",
    "    print(\"\\\\nüîç Corrigindo qualidade de c√≥digo...\")\n",
    "    all_corrections.extend(advanced_corrector.fix_code_quality())\n",
    "    \n",
    "    print(\"\\\\nüîí Aplicando corre√ß√µes de seguran√ßa...\")  \n",
    "    all_corrections.extend(advanced_corrector.fix_security_issues())\n",
    "    \n",
    "    print(\"\\\\n‚ö° Otimizando performance...\")\n",
    "    all_corrections.extend(advanced_corrector.optimize_performance())\n",
    "    \n",
    "    return all_corrections\n",
    "\n",
    "def generate_health_check():\n",
    "    \"\"\"Gera relat√≥rio de sa√∫de do projeto\"\"\"\n",
    "    print(\"\\\\nüè• RELAT√ìRIO DE SA√öDE DO PROJETO\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    health_score = 0\n",
    "    max_score = 100\n",
    "    issues = []\n",
    "    \n",
    "    # Verifica estrutura b√°sica (20 pontos)\n",
    "    essential_dirs = ['client', 'server', 'docs', 'configs']\n",
    "    present_dirs = sum(1 for d in essential_dirs if os.path.exists(os.path.join(PROJECT_ROOT, d)))\n",
    "    structure_score = (present_dirs / len(essential_dirs)) * 20\n",
    "    health_score += structure_score\n",
    "    \n",
    "    if structure_score < 20:\n",
    "        issues.append(\"üèóÔ∏è Estrutura de diret√≥rios incompleta\")\n",
    "    \n",
    "    # Verifica configura√ß√µes (20 pontos)\n",
    "    config_files = [\n",
    "        'package.json',\n",
    "        'client/package.json', \n",
    "        'server/package.json',\n",
    "        'configs/client.env.example',\n",
    "        'configs/server.env.example'\n",
    "    ]\n",
    "    present_configs = sum(1 for f in config_files if os.path.exists(os.path.join(PROJECT_ROOT, f)))\n",
    "    config_score = (present_configs / len(config_files)) * 20\n",
    "    health_score += config_score\n",
    "    \n",
    "    if config_score < 15:\n",
    "        issues.append(\"‚öôÔ∏è Configura√ß√µes essenciais ausentes\")\n",
    "    \n",
    "    # Verifica Docker (15 pontos)\n",
    "    docker_files = [\n",
    "        'client/Dockerfile',\n",
    "        'docker/docker-compose.yml',\n",
    "        'Dockerfile'\n",
    "    ]\n",
    "    present_docker = sum(1 for f in docker_files if os.path.exists(os.path.join(PROJECT_ROOT, f)))\n",
    "    docker_score = (present_docker / len(docker_files)) * 15\n",
    "    health_score += docker_score\n",
    "    \n",
    "    if docker_score < 10:\n",
    "        issues.append(\"üê≥ Configura√ß√µes Docker incompletas\")\n",
    "    \n",
    "    # Verifica CI/CD (15 pontos)\n",
    "    ci_files = [\n",
    "        '.github/workflows/ci.yml',\n",
    "        '.github/workflows/security.yml'\n",
    "    ]\n",
    "    present_ci = sum(1 for f in ci_files if os.path.exists(os.path.join(PROJECT_ROOT, f)))\n",
    "    ci_score = (present_ci / len(ci_files)) * 15\n",
    "    health_score += ci_score\n",
    "    \n",
    "    if ci_score < 10:\n",
    "        issues.append(\"üîÑ Pipeline CI/CD n√£o configurado\")\n",
    "    \n",
    "    # Verifica documenta√ß√£o (15 pontos)\n",
    "    doc_files = [\n",
    "        'README.md',\n",
    "        'docs/API_README.md',\n",
    "        'docs/ARCHITECTURE.md'\n",
    "    ]\n",
    "    present_docs = sum(1 for f in doc_files if os.path.exists(os.path.join(PROJECT_ROOT, f)))\n",
    "    doc_score = (present_docs / len(doc_files)) * 15\n",
    "    health_score += doc_score\n",
    "    \n",
    "    if doc_score < 10:\n",
    "        issues.append(\"üìö Documenta√ß√£o incompleta\")\n",
    "    \n",
    "    # Verifica seguran√ßa (15 pontos)\n",
    "    security_files = [\n",
    "        '.gitignore',\n",
    "        '.github/dependabot.yml',\n",
    "        'security-validation.log'\n",
    "    ]\n",
    "    present_security = sum(1 for f in security_files if os.path.exists(os.path.join(PROJECT_ROOT, f)))\n",
    "    security_score = (present_security / len(security_files)) * 15\n",
    "    health_score += security_score\n",
    "    \n",
    "    if security_score < 10:\n",
    "        issues.append(\"üîí Medidas de seguran√ßa insuficientes\")\n",
    "    \n",
    "    # Classifica a sa√∫de\n",
    "    if health_score >= 85:\n",
    "        health_status = \"üü¢ EXCELENTE\"\n",
    "        health_desc = \"Projeto em √≥timo estado\"\n",
    "    elif health_score >= 70:\n",
    "        health_status = \"üü° BOM\"\n",
    "        health_desc = \"Projeto bem estruturado com pequenas melhorias\"\n",
    "    elif health_score >= 50:\n",
    "        health_status = \"üü† REGULAR\"\n",
    "        health_desc = \"Projeto funcional mas precisa de aten√ß√£o\"\n",
    "    else:\n",
    "        health_status = \"üî¥ CR√çTICO\"\n",
    "        health_desc = \"Projeto precisa de corre√ß√µes urgentes\"\n",
    "    \n",
    "    print(f\"\\\\nüìä Score de Sa√∫de: {health_score:.1f}/{max_score}\")\n",
    "    print(f\"üéØ Status: {health_status}\")\n",
    "    print(f\"üìù Avalia√ß√£o: {health_desc}\")\n",
    "    \n",
    "    print(f\"\\\\nüìà DETALHAMENTO DOS SCORES:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"üèóÔ∏è Estrutura: {structure_score:.1f}/20\")\n",
    "    print(f\"‚öôÔ∏è Configura√ß√µes: {config_score:.1f}/20\") \n",
    "    print(f\"üê≥ Docker: {docker_score:.1f}/15\")\n",
    "    print(f\"üîÑ CI/CD: {ci_score:.1f}/15\")\n",
    "    print(f\"üìö Documenta√ß√£o: {doc_score:.1f}/15\")\n",
    "    print(f\"üîí Seguran√ßa: {security_score:.1f}/15\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"\\\\n‚ö†Ô∏è PROBLEMAS IDENTIFICADOS:\")\n",
    "        print(\"-\" * 30)\n",
    "        for issue in issues:\n",
    "            print(f\"  ‚Ä¢ {issue}\")\n",
    "    \n",
    "    # Gr√°fico de sa√∫de\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Gr√°fico 1: Score geral\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.pie([health_score, max_score - health_score], \n",
    "            labels=['Sa√∫de', 'Melhorias'], \n",
    "            colors=['lightgreen', 'lightcoral'],\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90)\n",
    "    plt.title(f'üè• Sa√∫de Geral: {health_score:.1f}%')\n",
    "    \n",
    "    # Gr√°fico 2: Breakdown por categoria\n",
    "    plt.subplot(2, 2, 2)\n",
    "    categories = ['Estrutura', 'Configs', 'Docker', 'CI/CD', 'Docs', 'Seguran√ßa']\n",
    "    scores = [structure_score, config_score, docker_score, ci_score, doc_score, security_score]\n",
    "    max_scores = [20, 20, 15, 15, 15, 15]\n",
    "    \n",
    "    colors = ['green' if s/m >= 0.8 else 'orange' if s/m >= 0.5 else 'red' \n",
    "              for s, m in zip(scores, max_scores)]\n",
    "    \n",
    "    plt.bar(categories, scores, color=colors)\n",
    "    plt.title('üìä Score por Categoria')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Pontos')\n",
    "    \n",
    "    # Gr√°fico 3: Evolu√ß√£o sugerida\n",
    "    plt.subplot(2, 2, 3)\n",
    "    timeline = ['Atual', '1 m√™s', '2 meses', '3 meses']\n",
    "    projected_health = [health_score, \n",
    "                       min(health_score + 20, 100),\n",
    "                       min(health_score + 35, 100), \n",
    "                       min(health_score + 50, 100)]\n",
    "    \n",
    "    plt.plot(timeline, projected_health, 'o-', linewidth=3, markersize=8, color='blue')\n",
    "    plt.fill_between(timeline, projected_health, alpha=0.3, color='blue')\n",
    "    plt.title('üìà Evolu√ß√£o Projetada')\n",
    "    plt.ylabel('Score de Sa√∫de')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Gr√°fico 4: Compara√ß√£o com benchmark\n",
    "    plt.subplot(2, 2, 4)\n",
    "    benchmark_scores = [18, 18, 12, 12, 12, 12]  # Scores ideais\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, scores, width, label='Atual', alpha=0.8)\n",
    "    plt.bar(x + width/2, benchmark_scores, width, label='Ideal', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Categorias')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('üìä vs. Benchmark')\n",
    "    plt.xticks(x, [c[:5] for c in categories], rotation=45)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'health_score': health_score,\n",
    "        'issues': issues,\n",
    "        'status': health_status,\n",
    "        'breakdown': {\n",
    "            'structure': structure_score,\n",
    "            'config': config_score,\n",
    "            'docker': docker_score,\n",
    "            'ci_cd': ci_score,\n",
    "            'docs': doc_score,\n",
    "            'security': security_score\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Executa verifica√ß√£o de sa√∫de\n",
    "health_report = generate_health_check()\n",
    "\n",
    "print(\"\\\\nüéØ PLANO DE A√á√ÉO RECOMENDADO:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prioriza corre√ß√µes baseado na sa√∫de\n",
    "if health_report['health_score'] < 70:\n",
    "    print(\"üö® A√á√ÉO URGENTE NECESS√ÅRIA!\")\n",
    "    print(\"\\\\n1. Execute autocorre√ß√£o completa:\")\n",
    "    print(\"   corrector = ProjectAutoCorrector(PROJECT_ROOT)\")\n",
    "    print(\"   corrector.run_all_corrections()\")\n",
    "    \n",
    "    print(\"\\\\n2. Aplique corre√ß√µes avan√ßadas:\")\n",
    "    print(\"   run_advanced_corrections()\")\n",
    "    \n",
    "    print(\"\\\\n3. Verifique novamente a sa√∫de:\")\n",
    "    print(\"   generate_health_check()\")\n",
    "\n",
    "else:\n",
    "    print(\"‚úÖ Projeto em bom estado!\")\n",
    "    print(\"\\\\nPr√≥ximos passos sugeridos:\")\n",
    "    print(\"1. Implementar testes automatizados\")\n",
    "    print(\"2. Configurar monitoramento\")\n",
    "    print(\"3. Otimizar performance\")\n",
    "\n",
    "print(\"\\\\nüèÜ SISTEMA DE AUTOCORRE√á√ÉO COMPLETO!\")\n",
    "print(\"   O projeto pode ser automaticamente corrigido e otimizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac39add",
   "metadata": {},
   "source": [
    "## üåê Sistema Web de Gest√£o do Projeto\n",
    "\n",
    "Interface web completa para gerenciar, analisar e corrigir o Will Finance 5.0 em tempo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25040901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import webbrowser\n",
    "import threading\n",
    "import time\n",
    "from http.server import HTTPServer, SimpleHTTPRequestHandler\n",
    "import socketserver\n",
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "class ProjectValidator:\n",
    "    \"\"\"\n",
    "    Validador completo que verifica TUDO no projeto\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        self.validation_results = {}\n",
    "        \n",
    "    def validate_everything(self):\n",
    "        \"\"\"Valida√ß√£o completa de todos os aspectos do projeto\"\"\"\n",
    "        print(\"üîç VALIDA√á√ÉO COMPLETA DO PROJETO\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        validations = {\n",
    "            'structure': self._validate_structure(),\n",
    "            'dependencies': self._validate_dependencies(), \n",
    "            'configurations': self._validate_configurations(),\n",
    "            'code_quality': self._validate_code_quality(),\n",
    "            'security': self._validate_security(),\n",
    "            'documentation': self._validate_documentation(),\n",
    "            'docker': self._validate_docker(),\n",
    "            'ci_cd': self._validate_ci_cd(),\n",
    "            'database': self._validate_database(),\n",
    "            'ai_system': self._validate_ai_system()\n",
    "        }\n",
    "        \n",
    "        self.validation_results = validations\n",
    "        \n",
    "        # Calcula score geral\n",
    "        total_score = 0\n",
    "        max_score = 0\n",
    "        \n",
    "        for category, result in validations.items():\n",
    "            total_score += result['score']\n",
    "            max_score += result['max_score']\n",
    "        \n",
    "        overall_score = (total_score / max_score) * 100 if max_score > 0 else 0\n",
    "        \n",
    "        print(f\"\\\\nüéØ RESULTADO GERAL: {overall_score:.1f}%\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return {\n",
    "            'overall_score': overall_score,\n",
    "            'categories': validations,\n",
    "            'can_autocorrect': overall_score < 95,  # Se n√£o est√° perfeito, pode corrigir\n",
    "            'priority_fixes': self._get_priority_fixes(validations)\n",
    "        }\n",
    "    \n",
    "    def _validate_structure(self):\n",
    "        \"\"\"Valida estrutura de diret√≥rios\"\"\"\n",
    "        required_dirs = [\n",
    "            ('client', 'Frontend React'),\n",
    "            ('server', 'Backend Node.js'),\n",
    "            ('ia', 'Sistema de IA'),\n",
    "            ('docs', 'Documenta√ß√£o'),\n",
    "            ('configs', 'Configura√ß√µes'),\n",
    "            ('scripts', 'Scripts de automa√ß√£o'),\n",
    "            ('docker', 'Configura√ß√µes Docker'),\n",
    "            ('nginx', 'Configura√ß√µes Nginx')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for dir_name, description in required_dirs:\n",
    "            dir_path = os.path.join(self.project_root, dir_name)\n",
    "            if os.path.exists(dir_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"Diret√≥rio {dir_name} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(required_dirs)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 80 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(required_dirs)\n",
    "        }\n",
    "    \n",
    "    def _validate_dependencies(self):\n",
    "        \"\"\"Valida depend√™ncias do projeto\"\"\"\n",
    "        package_files = [\n",
    "            'package.json',\n",
    "            'client/package.json',\n",
    "            'server/package.json'\n",
    "        ]\n",
    "        \n",
    "        total_issues = 0\n",
    "        vulnerabilities = 0\n",
    "        outdated = 0\n",
    "        \n",
    "        for package_file in package_files:\n",
    "            full_path = os.path.join(self.project_root, package_file)\n",
    "            if os.path.exists(full_path):\n",
    "                try:\n",
    "                    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                        package_data = json.load(f)\n",
    "                    \n",
    "                    # Verifica se tem scripts essenciais\n",
    "                    scripts = package_data.get('scripts', {})\n",
    "                    if 'start' not in scripts:\n",
    "                        total_issues += 1\n",
    "                    if 'build' not in scripts:\n",
    "                        total_issues += 1\n",
    "                    if 'test' not in scripts:\n",
    "                        total_issues += 1\n",
    "                        \n",
    "                except Exception:\n",
    "                    total_issues += 5  # Erro grave de parsing\n",
    "        \n",
    "        # Score baseado na aus√™ncia de problemas\n",
    "        max_issues = 15  # M√°ximo de issues poss√≠veis\n",
    "        score = max(0, (max_issues - total_issues) / max_issues * 100)\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 70 else 'NEEDS_FIX',\n",
    "            'issues': total_issues,\n",
    "            'vulnerabilities': vulnerabilities,\n",
    "            'outdated': outdated\n",
    "        }\n",
    "    \n",
    "    def _validate_configurations(self):\n",
    "        \"\"\"Valida arquivos de configura√ß√£o\"\"\"\n",
    "        config_files = [\n",
    "            ('client/tsconfig.json', 'TypeScript config do cliente'),\n",
    "            ('server/tsconfig.json', 'TypeScript config do servidor'),\n",
    "            ('client/vite.config.ts', 'Vite config'),\n",
    "            ('configs/client.env.example', 'Template env cliente'),\n",
    "            ('configs/server.env.example', 'Template env servidor'),\n",
    "            ('.gitignore', 'Git ignore'),\n",
    "            ('.prettierrc', 'Prettier config'),\n",
    "            ('client/.eslintrc.json', 'ESLint config')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for config_file, description in config_files:\n",
    "            file_path = os.path.join(self.project_root, config_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{config_file} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(config_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 75 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(config_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_code_quality(self):\n",
    "        \"\"\"Valida qualidade do c√≥digo\"\"\"\n",
    "        quality_indicators = [\n",
    "            ('client/src', 'C√≥digo fonte do cliente'),\n",
    "            ('server/src', 'C√≥digo fonte do servidor'),\n",
    "            ('client/package.json', 'ESLint no cliente'),\n",
    "            ('server/package.json', 'ESLint no servidor')\n",
    "        ]\n",
    "        \n",
    "        score = 75  # Score base\n",
    "        issues = []\n",
    "        \n",
    "        # Verifica se tem TypeScript\n",
    "        ts_files = 0\n",
    "        for root, dirs, files in os.walk(self.project_root):\n",
    "            if 'node_modules' in root:\n",
    "                continue\n",
    "            for file in files:\n",
    "                if file.endswith(('.ts', '.tsx')):\n",
    "                    ts_files += 1\n",
    "        \n",
    "        if ts_files > 10:\n",
    "            score += 15  # Bonus por usar TypeScript\n",
    "        elif ts_files > 0:\n",
    "            score += 5\n",
    "        else:\n",
    "            issues.append(\"Pouco uso de TypeScript\")\n",
    "            \n",
    "        # Verifica estrutura modular\n",
    "        if os.path.exists(os.path.join(self.project_root, 'client', 'src', 'components')):\n",
    "            score += 5\n",
    "        if os.path.exists(os.path.join(self.project_root, 'server', 'src', 'modules')):\n",
    "            score += 5\n",
    "            \n",
    "        return {\n",
    "            'score': min(score, 100),\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 80 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'typescript_files': ts_files\n",
    "        }\n",
    "    \n",
    "    def _validate_security(self):\n",
    "        \"\"\"Valida aspectos de seguran√ßa\"\"\"\n",
    "        security_files = [\n",
    "            ('.gitignore', 'Exclus√µes do Git'),\n",
    "            ('configs/client.env.example', 'Template seguro de env'),\n",
    "            ('configs/server.env.example', 'Template seguro de env'),\n",
    "            ('.github/dependabot.yml', 'Dependabot config'),\n",
    "            ('security-validation.log', 'Log de valida√ß√£o')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for security_file, description in security_files:\n",
    "            file_path = os.path.join(self.project_root, security_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{security_file} ausente ({description})\")\n",
    "        \n",
    "        # Verifica se .env est√° no .gitignore\n",
    "        gitignore_path = os.path.join(self.project_root, '.gitignore')\n",
    "        if os.path.exists(gitignore_path):\n",
    "            with open(gitignore_path, 'r', encoding='utf-8') as f:\n",
    "                gitignore_content = f.read()\n",
    "            if '.env' not in gitignore_content:\n",
    "                issues.append(\".env n√£o est√° no .gitignore\")\n",
    "                present -= 0.5\n",
    "        \n",
    "        score = (present / len(security_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': max(0, score),\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 80 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(security_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_documentation(self):\n",
    "        \"\"\"Valida documenta√ß√£o\"\"\"\n",
    "        doc_files = [\n",
    "            ('README.md', 'Documenta√ß√£o principal'),\n",
    "            ('docs/API_README.md', 'Documenta√ß√£o da API'),\n",
    "            ('docs/ARCHITECTURE.md', 'Documenta√ß√£o da arquitetura'),\n",
    "            ('docs/CONTRIBUTING.md', 'Guia de contribui√ß√£o'),\n",
    "            ('docs/DEPLOY.md', 'Guia de deploy')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for doc_file, description in doc_files:\n",
    "            file_path = os.path.join(self.project_root, doc_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{doc_file} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(doc_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 70 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(doc_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_docker(self):\n",
    "        \"\"\"Valida configura√ß√µes Docker\"\"\"\n",
    "        docker_files = [\n",
    "            ('Dockerfile', 'Dockerfile principal'),\n",
    "            ('client/Dockerfile', 'Dockerfile do cliente'),\n",
    "            ('client/Dockerfile.dev', 'Dockerfile dev do cliente'),\n",
    "            ('docker/docker-compose.yml', 'Docker Compose'),\n",
    "            ('docker/docker-compose.prod.yml', 'Docker Compose produ√ß√£o'),\n",
    "            ('.dockerignore', 'Docker ignore')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for docker_file, description in docker_files:\n",
    "            file_path = os.path.join(self.project_root, docker_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{docker_file} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(docker_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 60 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(docker_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_ci_cd(self):\n",
    "        \"\"\"Valida CI/CD\"\"\"\n",
    "        ci_files = [\n",
    "            ('.github/workflows/ci.yml', 'Workflow CI'),\n",
    "            ('.github/workflows/security.yml', 'Workflow de seguran√ßa'),\n",
    "            ('.github/dependabot.yml', 'Dependabot')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for ci_file, description in ci_files:\n",
    "            file_path = os.path.join(self.project_root, ci_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{ci_file} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(ci_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 70 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(ci_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_database(self):\n",
    "        \"\"\"Valida configura√ß√µes de banco\"\"\"\n",
    "        db_files = [\n",
    "            ('server/prisma/schema.prisma', 'Schema Prisma'),\n",
    "            ('database/init.sql', 'SQL de inicializa√ß√£o')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for db_file, description in db_files:\n",
    "            file_path = os.path.join(self.project_root, db_file)\n",
    "            if os.path.exists(file_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{db_file} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(db_files)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 50 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(db_files)\n",
    "        }\n",
    "    \n",
    "    def _validate_ai_system(self):\n",
    "        \"\"\"Valida sistema de IA\"\"\"\n",
    "        ai_components = [\n",
    "            ('ia/src', 'C√≥digo fonte da IA'),\n",
    "            ('ia/datasets', 'Datasets de treino'),\n",
    "            ('ia/models', 'Modelos treinados'),\n",
    "            ('ia/notebooks', 'Notebooks de desenvolvimento'),\n",
    "            ('ia/Dockerfile', 'Docker da IA')\n",
    "        ]\n",
    "        \n",
    "        present = 0\n",
    "        issues = []\n",
    "        \n",
    "        for ai_component, description in ai_components:\n",
    "            component_path = os.path.join(self.project_root, ai_component)\n",
    "            if os.path.exists(component_path):\n",
    "                present += 1\n",
    "            else:\n",
    "                issues.append(f\"{ai_component} ausente ({description})\")\n",
    "        \n",
    "        score = (present / len(ai_components)) * 100\n",
    "        \n",
    "        return {\n",
    "            'score': score,\n",
    "            'max_score': 100,\n",
    "            'status': 'OK' if score >= 60 else 'NEEDS_FIX',\n",
    "            'issues': issues,\n",
    "            'present': present,\n",
    "            'total': len(ai_components)\n",
    "        }\n",
    "    \n",
    "    def _get_priority_fixes(self, validations):\n",
    "        \"\"\"Determina corre√ß√µes priorit√°rias\"\"\"\n",
    "        priority_fixes = []\n",
    "        \n",
    "        for category, result in validations.items():\n",
    "            if result['status'] == 'NEEDS_FIX':\n",
    "                priority_fixes.append({\n",
    "                    'category': category,\n",
    "                    'score': result['score'],\n",
    "                    'max_score': result['max_score'],\n",
    "                    'issues': result.get('issues', [])\n",
    "                })\n",
    "        \n",
    "        # Ordena por prioridade (menor score = maior prioridade)\n",
    "        priority_fixes.sort(key=lambda x: x['score'])\n",
    "        \n",
    "        return priority_fixes\n",
    "\n",
    "class WebInterfaceGenerator:\n",
    "    \"\"\"\n",
    "    Gera interface web completa para gest√£o do projeto\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, project_root):\n",
    "        self.project_root = project_root\n",
    "        self.web_dir = os.path.join(project_root, 'project-manager-web')\n",
    "        \n",
    "    def create_web_interface(self):\n",
    "        \"\"\"Cria interface web completa\"\"\"\n",
    "        print(\"üåê CRIANDO INTERFACE WEB DE GEST√ÉO\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Cria diret√≥rio da interface\n",
    "        os.makedirs(self.web_dir, exist_ok=True)\n",
    "        \n",
    "        # Cria arquivos da interface\n",
    "        self._create_html_interface()\n",
    "        self._create_css_styles()\n",
    "        self._create_javascript_app()\n",
    "        self._create_api_server()\n",
    "        self._create_package_json()\n",
    "        \n",
    "        print(\"‚úÖ Interface web criada com sucesso!\")\n",
    "        print(f\"üìÅ Localiza√ß√£o: {self.web_dir}\")\n",
    "        \n",
    "        return self.web_dir\n",
    "    \n",
    "    def _create_html_interface(self):\n",
    "        \"\"\"Cria interface HTML principal\"\"\"\n",
    "        html_content = '''<!DOCTYPE html>\n",
    "<html lang=\"pt-BR\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Will Finance 5.0 - Project Manager</title>\n",
    "    <link rel=\"stylesheet\" href=\"styles.css\">\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" rel=\"stylesheet\">\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/chart.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "    <nav class=\"navbar navbar-dark bg-primary\">\n",
    "        <div class=\"container-fluid\">\n",
    "            <span class=\"navbar-brand mb-0 h1\">\n",
    "                <i class=\"fas fa-cogs\"></i> Will Finance 5.0 - Project Manager\n",
    "            </span>\n",
    "            <div class=\"d-flex\">\n",
    "                <span class=\"badge bg-success me-2\" id=\"health-badge\">Carregando...</span>\n",
    "                <button class=\"btn btn-outline-light btn-sm\" onclick=\"refreshData()\">\n",
    "                    <i class=\"fas fa-sync-alt\"></i> Atualizar\n",
    "                </button>\n",
    "            </div>\n",
    "        </div>\n",
    "    </nav>\n",
    "\n",
    "    <div class=\"container-fluid mt-4\">\n",
    "        <div class=\"row\">\n",
    "            <!-- Sidebar -->\n",
    "            <div class=\"col-md-3\">\n",
    "                <div class=\"card\">\n",
    "                    <div class=\"card-header\">\n",
    "                        <h5><i class=\"fas fa-tachometer-alt\"></i> Dashboard</h5>\n",
    "                    </div>\n",
    "                    <div class=\"list-group list-group-flush\">\n",
    "                        <a href=\"#overview\" class=\"list-group-item list-group-item-action active\" onclick=\"showSection('overview')\">\n",
    "                            <i class=\"fas fa-chart-pie\"></i> Vis√£o Geral\n",
    "                        </a>\n",
    "                        <a href=\"#validation\" class=\"list-group-item list-group-item-action\" onclick=\"showSection('validation')\">\n",
    "                            <i class=\"fas fa-check-circle\"></i> Valida√ß√£o\n",
    "                        </a>\n",
    "                        <a href=\"#corrections\" class=\"list-group-item list-group-item-action\" onclick=\"showSection('corrections')\">\n",
    "                            <i class=\"fas fa-wrench\"></i> Corre√ß√µes\n",
    "                        </a>\n",
    "                        <a href=\"#monitoring\" class=\"list-group-item list-group-item-action\" onclick=\"showSection('monitoring')\">\n",
    "                            <i class=\"fas fa-heartbeat\"></i> Monitoramento\n",
    "                        </a>\n",
    "                        <a href=\"#tools\" class=\"list-group-item list-group-item-action\" onclick=\"showSection('tools')\">\n",
    "                            <i class=\"fas fa-tools\"></i> Ferramentas\n",
    "                        </a>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <!-- Main Content -->\n",
    "            <div class=\"col-md-9\">\n",
    "                <!-- Overview Section -->\n",
    "                <div id=\"overview-section\" class=\"content-section\">\n",
    "                    <div class=\"row\">\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"card\">\n",
    "                                <div class=\"card-header\">\n",
    "                                    <h5><i class=\"fas fa-chart-line\"></i> Score Geral</h5>\n",
    "                                </div>\n",
    "                                <div class=\"card-body text-center\">\n",
    "                                    <div class=\"score-circle\" id=\"overall-score\">\n",
    "                                        <span id=\"score-value\">--</span>%\n",
    "                                    </div>\n",
    "                                    <p class=\"mt-3\" id=\"score-description\">Carregando...</p>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"card\">\n",
    "                                <div class=\"card-header\">\n",
    "                                    <h5><i class=\"fas fa-tasks\"></i> Status das Categorias</h5>\n",
    "                                </div>\n",
    "                                <div class=\"card-body\">\n",
    "                                    <canvas id=\"categories-chart\"></canvas>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    \n",
    "                    <div class=\"row mt-4\">\n",
    "                        <div class=\"col-12\">\n",
    "                            <div class=\"card\">\n",
    "                                <div class=\"card-header\">\n",
    "                                    <h5><i class=\"fas fa-exclamation-triangle\"></i> Problemas Priorit√°rios</h5>\n",
    "                                </div>\n",
    "                                <div class=\"card-body\">\n",
    "                                    <div id=\"priority-issues\">Carregando...</div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Validation Section -->\n",
    "                <div id=\"validation-section\" class=\"content-section d-none\">\n",
    "                    <div class=\"card\">\n",
    "                        <div class=\"card-header\">\n",
    "                            <h5><i class=\"fas fa-search\"></i> Valida√ß√£o Completa do Projeto</h5>\n",
    "                        </div>\n",
    "                        <div class=\"card-body\">\n",
    "                            <button class=\"btn btn-primary\" onclick=\"runValidation()\">\n",
    "                                <i class=\"fas fa-play\"></i> Executar Valida√ß√£o\n",
    "                            </button>\n",
    "                            <div id=\"validation-results\" class=\"mt-4\">\n",
    "                                <!-- Resultados aparecer√£o aqui -->\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Corrections Section -->\n",
    "                <div id=\"corrections-section\" class=\"content-section d-none\">\n",
    "                    <div class=\"card\">\n",
    "                        <div class=\"card-header\">\n",
    "                            <h5><i class=\"fas fa-magic\"></i> Autocorre√ß√£o Inteligente</h5>\n",
    "                        </div>\n",
    "                        <div class=\"card-body\">\n",
    "                            <div class=\"alert alert-info\">\n",
    "                                <i class=\"fas fa-info-circle\"></i>\n",
    "                                <strong>Aten√ß√£o:</strong> Um backup ser√° criado automaticamente antes de aplicar as corre√ß√µes.\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"row\">\n",
    "                                <div class=\"col-md-6\">\n",
    "                                    <h6>Corre√ß√µes B√°sicas</h6>\n",
    "                                    <button class=\"btn btn-success mb-2 w-100\" onclick=\"runCorrection('basic')\">\n",
    "                                        <i class=\"fas fa-file\"></i> Arquivos Essenciais\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-success mb-2 w-100\" onclick=\"runCorrection('config')\">\n",
    "                                        <i class=\"fas fa-cog\"></i> Configura√ß√µes\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-success mb-2 w-100\" onclick=\"runCorrection('docker')\">\n",
    "                                        <i class=\"fab fa-docker\"></i> Docker\n",
    "                                    </button>\n",
    "                                </div>\n",
    "                                <div class=\"col-md-6\">\n",
    "                                    <h6>Corre√ß√µes Avan√ßadas</h6>\n",
    "                                    <button class=\"btn btn-warning mb-2 w-100\" onclick=\"runCorrection('security')\">\n",
    "                                        <i class=\"fas fa-shield-alt\"></i> Seguran√ßa\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-warning mb-2 w-100\" onclick=\"runCorrection('cicd')\">\n",
    "                                        <i class=\"fas fa-sync\"></i> CI/CD\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-danger mb-2 w-100\" onclick=\"runCorrection('all')\">\n",
    "                                        <i class=\"fas fa-magic\"></i> TODAS as Corre√ß√µes\n",
    "                                    </button>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div id=\"correction-results\" class=\"mt-4\">\n",
    "                                <!-- Resultados das corre√ß√µes aparecer√£o aqui -->\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Monitoring Section -->\n",
    "                <div id=\"monitoring-section\" class=\"content-section d-none\">\n",
    "                    <div class=\"row\">\n",
    "                        <div class=\"col-md-4\">\n",
    "                            <div class=\"card text-center\">\n",
    "                                <div class=\"card-body\">\n",
    "                                    <i class=\"fas fa-file-code fa-3x text-primary\"></i>\n",
    "                                    <h5 class=\"mt-2\">Arquivos</h5>\n",
    "                                    <h3 id=\"files-count\">--</h3>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"col-md-4\">\n",
    "                            <div class=\"card text-center\">\n",
    "                                <div class=\"card-body\">\n",
    "                                    <i class=\"fas fa-code-branch fa-3x text-success\"></i>\n",
    "                                    <h5 class=\"mt-2\">Commits</h5>\n",
    "                                    <h3 id=\"commits-count\">--</h3>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"col-md-4\">\n",
    "                            <div class=\"card text-center\">\n",
    "                                <div class=\"card-body\">\n",
    "                                    <i class=\"fas fa-bug fa-3x text-danger\"></i>\n",
    "                                    <h5 class=\"mt-2\">Issues</h5>\n",
    "                                    <h3 id=\"issues-count\">--</h3>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "\n",
    "                <!-- Tools Section -->\n",
    "                <div id=\"tools-section\" class=\"content-section d-none\">\n",
    "                    <div class=\"row\">\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"card\">\n",
    "                                <div class=\"card-header\">\n",
    "                                    <h5><i class=\"fas fa-terminal\"></i> Terminal Integrado</h5>\n",
    "                                </div>\n",
    "                                <div class=\"card-body\">\n",
    "                                    <div class=\"terminal\" id=\"terminal\">\n",
    "                                        <div class=\"terminal-output\" id=\"terminal-output\">\n",
    "                                            Will Finance 5.0 Project Manager Terminal\n",
    "                                            Digite 'help' para ver comandos dispon√≠veis.\n",
    "                                        </div>\n",
    "                                        <div class=\"terminal-input\">\n",
    "                                            <span>$</span>\n",
    "                                            <input type=\"text\" id=\"terminal-input\" onkeypress=\"handleTerminalInput(event)\">\n",
    "                                        </div>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        <div class=\"col-md-6\">\n",
    "                            <div class=\"card\">\n",
    "                                <div class=\"card-header\">\n",
    "                                    <h5><i class=\"fas fa-download\"></i> Exports & Relat√≥rios</h5>\n",
    "                                </div>\n",
    "                                <div class=\"card-body\">\n",
    "                                    <button class=\"btn btn-outline-primary mb-2 w-100\" onclick=\"exportReport('json')\">\n",
    "                                        <i class=\"fas fa-file-code\"></i> Exportar JSON\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-outline-success mb-2 w-100\" onclick=\"exportReport('csv')\">\n",
    "                                        <i class=\"fas fa-file-csv\"></i> Exportar CSV\n",
    "                                    </button>\n",
    "                                    <button class=\"btn btn-outline-info mb-2 w-100\" onclick=\"exportReport('pdf')\">\n",
    "                                        <i class=\"fas fa-file-pdf\"></i> Relat√≥rio PDF\n",
    "                                    </button>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js\"></script>\n",
    "    <script src=\"app.js\"></script>\n",
    "</body>\n",
    "</html>'''\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'index.html'), 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "    \n",
    "    def _create_css_styles(self):\n",
    "        \"\"\"Cria estilos CSS\"\"\"\n",
    "        css_content = '''/* Will Finance 5.0 Project Manager Styles */\n",
    "\n",
    "body {\n",
    "    background-color: #f8f9fa;\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "}\n",
    "\n",
    ".content-section {\n",
    "    animation: fadeIn 0.3s ease-in;\n",
    "}\n",
    "\n",
    "@keyframes fadeIn {\n",
    "    from { opacity: 0; transform: translateY(20px); }\n",
    "    to { opacity: 1; transform: translateY(0); }\n",
    "}\n",
    "\n",
    ".score-circle {\n",
    "    width: 120px;\n",
    "    height: 120px;\n",
    "    border-radius: 50%;\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    justify-content: center;\n",
    "    margin: 0 auto;\n",
    "    font-size: 24px;\n",
    "    font-weight: bold;\n",
    "    color: white;\n",
    "    position: relative;\n",
    "}\n",
    "\n",
    ".score-circle.excellent { background: linear-gradient(45deg, #28a745, #20c997); }\n",
    ".score-circle.good { background: linear-gradient(45deg, #ffc107, #fd7e14); }\n",
    ".score-circle.needs-work { background: linear-gradient(45deg, #dc3545, #e83e8c); }\n",
    "\n",
    ".terminal {\n",
    "    background-color: #1e1e1e;\n",
    "    color: #00ff00;\n",
    "    font-family: 'Courier New', monospace;\n",
    "    border-radius: 5px;\n",
    "    padding: 15px;\n",
    "    height: 300px;\n",
    "    overflow-y: auto;\n",
    "}\n",
    "\n",
    ".terminal-output {\n",
    "    white-space: pre-wrap;\n",
    "    margin-bottom: 10px;\n",
    "    font-size: 14px;\n",
    "}\n",
    "\n",
    ".terminal-input {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "}\n",
    "\n",
    ".terminal-input span {\n",
    "    margin-right: 5px;\n",
    "    color: #00ff00;\n",
    "}\n",
    "\n",
    ".terminal-input input {\n",
    "    background: transparent;\n",
    "    border: none;\n",
    "    color: #00ff00;\n",
    "    outline: none;\n",
    "    flex: 1;\n",
    "    font-family: 'Courier New', monospace;\n",
    "}\n",
    "\n",
    ".card {\n",
    "    border: none;\n",
    "    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "    transition: transform 0.2s;\n",
    "}\n",
    "\n",
    ".card:hover {\n",
    "    transform: translateY(-2px);\n",
    "}\n",
    "\n",
    ".list-group-item.active {\n",
    "    background-color: #007bff;\n",
    "    border-color: #007bff;\n",
    "}\n",
    "\n",
    ".badge {\n",
    "    font-size: 0.9em;\n",
    "}\n",
    "\n",
    ".btn {\n",
    "    transition: all 0.2s;\n",
    "}\n",
    "\n",
    ".btn:hover {\n",
    "    transform: translateY(-1px);\n",
    "}\n",
    "\n",
    ".alert {\n",
    "    border: none;\n",
    "    border-left: 4px solid;\n",
    "}\n",
    "\n",
    ".progress {\n",
    "    height: 8px;\n",
    "    border-radius: 10px;\n",
    "}\n",
    "\n",
    ".status-indicator {\n",
    "    width: 12px;\n",
    "    height: 12px;\n",
    "    border-radius: 50%;\n",
    "    display: inline-block;\n",
    "    margin-right: 8px;\n",
    "}\n",
    "\n",
    ".status-ok { background-color: #28a745; }\n",
    ".status-warning { background-color: #ffc107; }\n",
    ".status-error { background-color: #dc3545; }\n",
    "\n",
    ".metric-card {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    color: white;\n",
    "    border-radius: 15px;\n",
    "}\n",
    "\n",
    ".loading-spinner {\n",
    "    border: 3px solid #f3f3f3;\n",
    "    border-radius: 50%;\n",
    "    border-top: 3px solid #007bff;\n",
    "    width: 30px;\n",
    "    height: 30px;\n",
    "    animation: spin 1s linear infinite;\n",
    "    margin: 20px auto;\n",
    "}\n",
    "\n",
    "@keyframes spin {\n",
    "    0% { transform: rotate(0deg); }\n",
    "    100% { transform: rotate(360deg); }\n",
    "}\n",
    "\n",
    "/* Responsive adjustments */\n",
    "@media (max-width: 768px) {\n",
    "    .container-fluid {\n",
    "        padding-left: 10px;\n",
    "        padding-right: 10px;\n",
    "    }\n",
    "    \n",
    "    .score-circle {\n",
    "        width: 100px;\n",
    "        height: 100px;\n",
    "        font-size: 20px;\n",
    "    }\n",
    "    \n",
    "    .terminal {\n",
    "        height: 200px;\n",
    "    }\n",
    "}'''\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'styles.css'), 'w', encoding='utf-8') as f:\n",
    "            f.write(css_content)\n",
    "    \n",
    "    def _create_javascript_app(self):\n",
    "        \"\"\"Cria aplica√ß√£o JavaScript\"\"\"\n",
    "        js_content = '''// Will Finance 5.0 Project Manager JavaScript\n",
    "\n",
    "let currentData = {};\n",
    "let charts = {};\n",
    "\n",
    "// Inicializa√ß√£o\n",
    "document.addEventListener('DOMContentLoaded', function() {\n",
    "    initializeApp();\n",
    "});\n",
    "\n",
    "function initializeApp() {\n",
    "    console.log('üöÄ Will Finance 5.0 Project Manager iniciado');\n",
    "    refreshData();\n",
    "    setupWebSocket();\n",
    "}\n",
    "\n",
    "function showSection(sectionId) {\n",
    "    // Esconde todas as se√ß√µes\n",
    "    document.querySelectorAll('.content-section').forEach(section => {\n",
    "        section.classList.add('d-none');\n",
    "    });\n",
    "    \n",
    "    // Remove active de todos os links\n",
    "    document.querySelectorAll('.list-group-item').forEach(item => {\n",
    "        item.classList.remove('active');\n",
    "    });\n",
    "    \n",
    "    // Mostra se√ß√£o selecionada\n",
    "    document.getElementById(sectionId + '-section').classList.remove('d-none');\n",
    "    document.querySelector(`[onclick=\"showSection('${sectionId}')\"]`).classList.add('active');\n",
    "    \n",
    "    // Carrega dados espec√≠ficos da se√ß√£o\n",
    "    loadSectionData(sectionId);\n",
    "}\n",
    "\n",
    "function refreshData() {\n",
    "    showLoading();\n",
    "    \n",
    "    // Simula carregamento de dados (em produ√ß√£o, faria chamadas para API)\n",
    "    setTimeout(() => {\n",
    "        loadMockData();\n",
    "        updateDashboard();\n",
    "        hideLoading();\n",
    "    }, 1000);\n",
    "}\n",
    "\n",
    "function loadMockData() {\n",
    "    currentData = {\n",
    "        overall_score: 78.5,\n",
    "        health_status: 'good',\n",
    "        categories: {\n",
    "            structure: { score: 85, status: 'OK' },\n",
    "            dependencies: { score: 72, status: 'NEEDS_FIX' },\n",
    "            configurations: { score: 80, status: 'OK' },\n",
    "            code_quality: { score: 75, status: 'OK' },\n",
    "            security: { score: 68, status: 'NEEDS_FIX' },\n",
    "            documentation: { score: 90, status: 'OK' },\n",
    "            docker: { score: 65, status: 'NEEDS_FIX' },\n",
    "            ci_cd: { score: 70, status: 'NEEDS_FIX' },\n",
    "            database: { score: 85, status: 'OK' },\n",
    "            ai_system: { score: 80, status: 'OK' }\n",
    "        },\n",
    "        priority_issues: [\n",
    "            { category: 'Security', issue: 'Dependabot n√£o configurado', priority: 'high' },\n",
    "            { category: 'Docker', issue: 'Docker Compose incompleto', priority: 'medium' },\n",
    "            { category: 'CI/CD', issue: 'Workflow de seguran√ßa ausente', priority: 'medium' }\n",
    "        ],\n",
    "        stats: {\n",
    "            files_count: 247,\n",
    "            commits_count: 156,\n",
    "            issues_count: 8\n",
    "        }\n",
    "    };\n",
    "}\n",
    "\n",
    "function updateDashboard() {\n",
    "    // Atualiza score geral\n",
    "    const scoreElement = document.getElementById('score-value');\n",
    "    const scoreCircle = document.getElementById('overall-score');\n",
    "    const scoreDesc = document.getElementById('score-description');\n",
    "    \n",
    "    scoreElement.textContent = Math.round(currentData.overall_score);\n",
    "    \n",
    "    // Define cor baseada no score\n",
    "    if (currentData.overall_score >= 85) {\n",
    "        scoreCircle.className = 'score-circle excellent';\n",
    "        scoreDesc.textContent = 'Excelente! Projeto bem estruturado.';\n",
    "    } else if (currentData.overall_score >= 70) {\n",
    "        scoreCircle.className = 'score-circle good';\n",
    "        scoreDesc.textContent = 'Bom projeto, algumas melhorias poss√≠veis.';\n",
    "    } else {\n",
    "        scoreCircle.className = 'score-circle needs-work';\n",
    "        scoreDesc.textContent = 'Projeto precisa de aten√ß√£o.';\n",
    "    }\n",
    "    \n",
    "    // Atualiza badge de sa√∫de\n",
    "    const healthBadge = document.getElementById('health-badge');\n",
    "    healthBadge.textContent = `${Math.round(currentData.overall_score)}% Saud√°vel`;\n",
    "    \n",
    "    // Atualiza problemas priorit√°rios\n",
    "    updatePriorityIssues();\n",
    "    \n",
    "    // Atualiza estat√≠sticas\n",
    "    updateStats();\n",
    "    \n",
    "    // Atualiza gr√°ficos\n",
    "    updateCharts();\n",
    "}\n",
    "\n",
    "function updatePriorityIssues() {\n",
    "    const container = document.getElementById('priority-issues');\n",
    "    let html = '';\n",
    "    \n",
    "    if (currentData.priority_issues.length === 0) {\n",
    "        html = '<div class=\"alert alert-success\"><i class=\"fas fa-check\"></i> Nenhum problema priorit√°rio encontrado!</div>';\n",
    "    } else {\n",
    "        currentData.priority_issues.forEach(issue => {\n",
    "            const badgeClass = issue.priority === 'high' ? 'danger' : \n",
    "                             issue.priority === 'medium' ? 'warning' : 'info';\n",
    "            html += `\n",
    "                <div class=\"alert alert-light border-start border-4 border-${badgeClass}\">\n",
    "                    <div class=\"d-flex justify-content-between align-items-center\">\n",
    "                        <div>\n",
    "                            <strong>${issue.category}:</strong> ${issue.issue}\n",
    "                        </div>\n",
    "                        <span class=\"badge bg-${badgeClass}\">${issue.priority.toUpperCase()}</span>\n",
    "                    </div>\n",
    "                </div>\n",
    "            `;\n",
    "        });\n",
    "    }\n",
    "    \n",
    "    container.innerHTML = html;\n",
    "}\n",
    "\n",
    "function updateStats() {\n",
    "    document.getElementById('files-count').textContent = currentData.stats.files_count;\n",
    "    document.getElementById('commits-count').textContent = currentData.stats.commits_count;\n",
    "    document.getElementById('issues-count').textContent = currentData.stats.issues_count;\n",
    "}\n",
    "\n",
    "function updateCharts() {\n",
    "    updateCategoriesChart();\n",
    "}\n",
    "\n",
    "function updateCategoriesChart() {\n",
    "    const ctx = document.getElementById('categories-chart').getContext('2d');\n",
    "    \n",
    "    const labels = Object.keys(currentData.categories).map(key => \n",
    "        key.replace('_', ' ').replace(/\\\\b\\\\w/g, l => l.toUpperCase())\n",
    "    );\n",
    "    const scores = Object.values(currentData.categories).map(cat => cat.score);\n",
    "    \n",
    "    if (charts.categoriesChart) {\n",
    "        charts.categoriesChart.destroy();\n",
    "    }\n",
    "    \n",
    "    charts.categoriesChart = new Chart(ctx, {\n",
    "        type: 'radar',\n",
    "        data: {\n",
    "            labels: labels,\n",
    "            datasets: [{\n",
    "                label: 'Score',\n",
    "                data: scores,\n",
    "                borderColor: 'rgb(54, 162, 235)',\n",
    "                backgroundColor: 'rgba(54, 162, 235, 0.2)',\n",
    "                borderWidth: 2\n",
    "            }]\n",
    "        },\n",
    "        options: {\n",
    "            scales: {\n",
    "                r: {\n",
    "                    beginAtZero: true,\n",
    "                    max: 100\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    });\n",
    "}\n",
    "\n",
    "function runValidation() {\n",
    "    const resultsContainer = document.getElementById('validation-results');\n",
    "    resultsContainer.innerHTML = '<div class=\"loading-spinner\"></div>';\n",
    "    \n",
    "    // Simula execu√ß√£o de valida√ß√£o\n",
    "    setTimeout(() => {\n",
    "        let html = '<div class=\"row\">';\n",
    "        \n",
    "        Object.entries(currentData.categories).forEach(([category, data]) => {\n",
    "            const statusClass = data.status === 'OK' ? 'success' : 'warning';\n",
    "            const iconClass = data.status === 'OK' ? 'check-circle' : 'exclamation-triangle';\n",
    "            \n",
    "            html += `\n",
    "                <div class=\"col-md-6 mb-3\">\n",
    "                    <div class=\"card border-${statusClass}\">\n",
    "                        <div class=\"card-body\">\n",
    "                            <div class=\"d-flex justify-content-between align-items-center\">\n",
    "                                <div>\n",
    "                                    <h6 class=\"card-title\">${category.replace('_', ' ').toUpperCase()}</h6>\n",
    "                                    <p class=\"card-text\">Score: ${data.score}%</p>\n",
    "                                </div>\n",
    "                                <i class=\"fas fa-${iconClass} fa-2x text-${statusClass}\"></i>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            `;\n",
    "        });\n",
    "        \n",
    "        html += '</div>';\n",
    "        resultsContainer.innerHTML = html;\n",
    "    }, 2000);\n",
    "}\n",
    "\n",
    "function runCorrection(type) {\n",
    "    const resultsContainer = document.getElementById('correction-results');\n",
    "    \n",
    "    let message = '';\n",
    "    switch(type) {\n",
    "        case 'basic':\n",
    "            message = 'Corrigindo arquivos essenciais...';\n",
    "            break;\n",
    "        case 'config':\n",
    "            message = 'Corrigindo configura√ß√µes...';\n",
    "            break;\n",
    "        case 'docker':\n",
    "            message = 'Corrigindo Docker...';\n",
    "            break;\n",
    "        case 'security':\n",
    "            message = 'Aplicando corre√ß√µes de seguran√ßa...';\n",
    "            break;\n",
    "        case 'cicd':\n",
    "            message = 'Configurando CI/CD...';\n",
    "            break;\n",
    "        case 'all':\n",
    "            message = 'Aplicando TODAS as corre√ß√µes...';\n",
    "            break;\n",
    "    }\n",
    "    \n",
    "    resultsContainer.innerHTML = `\n",
    "        <div class=\"alert alert-info\">\n",
    "            <div class=\"loading-spinner\"></div>\n",
    "            <strong>${message}</strong>\n",
    "        </div>\n",
    "    `;\n",
    "    \n",
    "    // Simula execu√ß√£o\n",
    "    setTimeout(() => {\n",
    "        const corrections = [\n",
    "            '‚úÖ README.md criado',\n",
    "            '‚úÖ .gitignore atualizado',\n",
    "            '‚úÖ Docker Compose configurado',\n",
    "            '‚úÖ Workflows CI/CD adicionados',\n",
    "            '‚úÖ Dependabot configurado'\n",
    "        ];\n",
    "        \n",
    "        let html = '<div class=\"alert alert-success\"><h6>Corre√ß√µes aplicadas com sucesso:</h6><ul>';\n",
    "        corrections.forEach(correction => {\n",
    "            html += `<li>${correction}</li>`;\n",
    "        });\n",
    "        html += '</ul></div>';\n",
    "        \n",
    "        resultsContainer.innerHTML = html;\n",
    "        \n",
    "        // Atualiza dados ap√≥s corre√ß√£o\n",
    "        setTimeout(refreshData, 1000);\n",
    "    }, 3000);\n",
    "}\n",
    "\n",
    "function loadSectionData(sectionId) {\n",
    "    // Carrega dados espec√≠ficos para cada se√ß√£o\n",
    "    switch(sectionId) {\n",
    "        case 'monitoring':\n",
    "            // J√° carregado com updateStats()\n",
    "            break;\n",
    "        case 'tools':\n",
    "            initializeTerminal();\n",
    "            break;\n",
    "    }\n",
    "}\n",
    "\n",
    "function initializeTerminal() {\n",
    "    // Terminal j√° inicializado no HTML\n",
    "}\n",
    "\n",
    "function handleTerminalInput(event) {\n",
    "    if (event.key === 'Enter') {\n",
    "        const input = event.target;\n",
    "        const command = input.value.trim();\n",
    "        const output = document.getElementById('terminal-output');\n",
    "        \n",
    "        // Adiciona comando ao output\n",
    "        output.textContent += `\\\\n$ ${command}`;\n",
    "        \n",
    "        // Processa comando\n",
    "        let response = '';\n",
    "        switch(command.toLowerCase()) {\n",
    "            case 'help':\n",
    "                response = `\n",
    "Comandos dispon√≠veis:\n",
    "  help          - Mostra esta ajuda\n",
    "  status        - Status do projeto\n",
    "  validate      - Executa valida√ß√£o\n",
    "  fix           - Aplica corre√ß√µes\n",
    "  clear         - Limpa terminal\n",
    "                `;\n",
    "                break;\n",
    "            case 'status':\n",
    "                response = `\\\\nStatus do projeto: ${Math.round(currentData.overall_score)}% saud√°vel`;\n",
    "                break;\n",
    "            case 'validate':\n",
    "                response = '\\\\nExecutando valida√ß√£o... (use a se√ß√£o Valida√ß√£o para detalhes)';\n",
    "                break;\n",
    "            case 'fix':\n",
    "                response = '\\\\nUse a se√ß√£o Corre√ß√µes para aplicar fixes espec√≠ficos';\n",
    "                break;\n",
    "            case 'clear':\n",
    "                output.textContent = 'Will Finance 5.0 Project Manager Terminal\\\\nDigite \"help\" para ver comandos dispon√≠veis.';\n",
    "                input.value = '';\n",
    "                return;\n",
    "            default:\n",
    "                response = `\\\\nComando n√£o reconhecido: ${command}\\\\nDigite \"help\" para ver comandos dispon√≠veis.`;\n",
    "        }\n",
    "        \n",
    "        output.textContent += response;\n",
    "        output.scrollTop = output.scrollHeight;\n",
    "        input.value = '';\n",
    "    }\n",
    "}\n",
    "\n",
    "function exportReport(format) {\n",
    "    const data = {\n",
    "        timestamp: new Date().toISOString(),\n",
    "        project: 'Will Finance 5.0',\n",
    "        overall_score: currentData.overall_score,\n",
    "        categories: currentData.categories,\n",
    "        issues: currentData.priority_issues\n",
    "    };\n",
    "    \n",
    "    switch(format) {\n",
    "        case 'json':\n",
    "            downloadJSON(data, 'will-finance-report.json');\n",
    "            break;\n",
    "        case 'csv':\n",
    "            downloadCSV(data, 'will-finance-report.csv');\n",
    "            break;\n",
    "        case 'pdf':\n",
    "            alert('Funcionalidade PDF em desenvolvimento');\n",
    "            break;\n",
    "    }\n",
    "}\n",
    "\n",
    "function downloadJSON(data, filename) {\n",
    "    const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});\n",
    "    const url = URL.createObjectURL(blob);\n",
    "    const a = document.createElement('a');\n",
    "    a.href = url;\n",
    "    a.download = filename;\n",
    "    a.click();\n",
    "    URL.revokeObjectURL(url);\n",
    "}\n",
    "\n",
    "function downloadCSV(data, filename) {\n",
    "    let csv = 'Category,Score,Status\\\\n';\n",
    "    Object.entries(data.categories).forEach(([category, info]) => {\n",
    "        csv += `${category},${info.score},${info.status}\\\\n`;\n",
    "    });\n",
    "    \n",
    "    const blob = new Blob([csv], {type: 'text/csv'});\n",
    "    const url = URL.createObjectURL(blob);\n",
    "    const a = document.createElement('a');\n",
    "    a.href = url;\n",
    "    a.download = filename;\n",
    "    a.click();\n",
    "    URL.revokeObjectURL(url);\n",
    "}\n",
    "\n",
    "function setupWebSocket() {\n",
    "    // WebSocket para updates em tempo real (implementar se necess√°rio)\n",
    "    console.log('WebSocket setup placeholder');\n",
    "}\n",
    "\n",
    "function showLoading() {\n",
    "    // Implementar loading state\n",
    "}\n",
    "\n",
    "function hideLoading() {\n",
    "    // Implementar hide loading\n",
    "}\n",
    "\n",
    "// Fun√ß√£o para atualizar dados automaticamente\n",
    "setInterval(refreshData, 30000); // Atualiza a cada 30 segundos'''\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'app.js'), 'w', encoding='utf-8') as f:\n",
    "            f.write(js_content)\n",
    "    \n",
    "    def _create_api_server(self):\n",
    "        \"\"\"Cria servidor API em Python\"\"\"\n",
    "        server_content = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Will Finance 5.0 Project Manager API Server\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from http.server import HTTPServer, BaseHTTPRequestHandler\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import threading\n",
    "import webbrowser\n",
    "\n",
    "# Adiciona o caminho do projeto principal\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "class ProjectManagerHandler(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        parsed_path = urlparse(self.path)\n",
    "        \n",
    "        # Serve arquivos est√°ticos\n",
    "        if parsed_path.path == '/' or parsed_path.path == '/index.html':\n",
    "            self.serve_file('index.html', 'text/html')\n",
    "        elif parsed_path.path == '/styles.css':\n",
    "            self.serve_file('styles.css', 'text/css')\n",
    "        elif parsed_path.path == '/app.js':\n",
    "            self.serve_file('app.js', 'application/javascript')\n",
    "        elif parsed_path.path.startswith('/api/'):\n",
    "            self.handle_api(parsed_path)\n",
    "        else:\n",
    "            self.send_error(404)\n",
    "    \n",
    "    def do_POST(self):\n",
    "        parsed_path = urlparse(self.path)\n",
    "        if parsed_path.path.startswith('/api/'):\n",
    "            content_length = int(self.headers['Content-Length'])\n",
    "            post_data = self.rfile.read(content_length)\n",
    "            self.handle_api(parsed_path, post_data)\n",
    "        else:\n",
    "            self.send_error(404)\n",
    "    \n",
    "    def serve_file(self, filename, content_type):\n",
    "        try:\n",
    "            file_path = os.path.join(os.path.dirname(__file__), filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', content_type)\n",
    "            self.send_header('Access-Control-Allow-Origin', '*')\n",
    "            self.end_headers()\n",
    "            self.wfile.write(content.encode('utf-8'))\n",
    "        except FileNotFoundError:\n",
    "            self.send_error(404)\n",
    "    \n",
    "    def handle_api(self, parsed_path, post_data=None):\n",
    "        path_parts = parsed_path.path.split('/')\n",
    "        \n",
    "        if len(path_parts) >= 3:\n",
    "            endpoint = path_parts[2]\n",
    "            \n",
    "            if endpoint == 'validate':\n",
    "                self.api_validate()\n",
    "            elif endpoint == 'correct':\n",
    "                self.api_correct(post_data)\n",
    "            elif endpoint == 'status':\n",
    "                self.api_status()\n",
    "            else:\n",
    "                self.send_json_error('Endpoint n√£o encontrado', 404)\n",
    "        else:\n",
    "            self.send_json_error('Endpoint inv√°lido', 400)\n",
    "    \n",
    "    def api_validate(self):\n",
    "        \"\"\"API para valida√ß√£o do projeto\"\"\"\n",
    "        try:\n",
    "            # Aqui voc√™ integraria com o ProjectValidator\n",
    "            from notebook_analyzer import ProjectValidator\n",
    "            \n",
    "            validator = ProjectValidator(project_root)\n",
    "            results = validator.validate_everything()\n",
    "            \n",
    "            self.send_json_response(results)\n",
    "        except Exception as e:\n",
    "            self.send_json_error(f'Erro na valida√ß√£o: {str(e)}', 500)\n",
    "    \n",
    "    def api_correct(self, post_data):\n",
    "        \"\"\"API para corre√ß√µes do projeto\"\"\"\n",
    "        try:\n",
    "            # Parse dos dados POST\n",
    "            data = json.loads(post_data.decode('utf-8')) if post_data else {}\n",
    "            correction_type = data.get('type', 'all')\n",
    "            \n",
    "            # Aqui voc√™ integraria com o ProjectAutoCorrector\n",
    "            from notebook_analyzer import ProjectAutoCorrector\n",
    "            \n",
    "            corrector = ProjectAutoCorrector(project_root)\n",
    "            \n",
    "            if correction_type == 'all':\n",
    "                results = corrector.run_all_corrections()\n",
    "            else:\n",
    "                # Implementar corre√ß√µes espec√≠ficas\n",
    "                results = ['Corre√ß√£o espec√≠fica em desenvolvimento']\n",
    "            \n",
    "            self.send_json_response({'corrections': results})\n",
    "        except Exception as e:\n",
    "            self.send_json_error(f'Erro na corre√ß√£o: {str(e)}', 500)\n",
    "    \n",
    "    def api_status(self):\n",
    "        \"\"\"API para status do projeto\"\"\"\n",
    "        try:\n",
    "            # Status b√°sico do projeto\n",
    "            status = {\n",
    "                'project_root': project_root,\n",
    "                'timestamp': time.time(),\n",
    "                'health': 'OK'\n",
    "            }\n",
    "            \n",
    "            self.send_json_response(status)\n",
    "        except Exception as e:\n",
    "            self.send_json_error(f'Erro no status: {str(e)}', 500)\n",
    "    \n",
    "    def send_json_response(self, data):\n",
    "        self.send_response(200)\n",
    "        self.send_header('Content-type', 'application/json')\n",
    "        self.send_header('Access-Control-Allow-Origin', '*')\n",
    "        self.end_headers()\n",
    "        self.wfile.write(json.dumps(data, ensure_ascii=False).encode('utf-8'))\n",
    "    \n",
    "    def send_json_error(self, message, status_code):\n",
    "        self.send_response(status_code)\n",
    "        self.send_header('Content-type', 'application/json')\n",
    "        self.send_header('Access-Control-Allow-Origin', '*')\n",
    "        self.end_headers()\n",
    "        error_data = {'error': message, 'status': status_code}\n",
    "        self.wfile.write(json.dumps(error_data).encode('utf-8'))\n",
    "\n",
    "def start_server(port=8080):\n",
    "    \"\"\"Inicia o servidor web\"\"\"\n",
    "    server_address = ('', port)\n",
    "    httpd = HTTPServer(server_address, ProjectManagerHandler)\n",
    "    \n",
    "    print(f\"üåê Will Finance 5.0 Project Manager\")\n",
    "    print(f\"üìç Servidor rodando em: http://localhost:{port}\")\n",
    "    print(f\"üîß Gerenciando projeto: {project_root}\")\n",
    "    print(\"\\\\nüöÄ Abrindo navegador...\")\n",
    "    \n",
    "    # Abre o navegador\n",
    "    threading.Timer(1.0, lambda: webbrowser.open(f'http://localhost:{port}')).start()\n",
    "    \n",
    "    try:\n",
    "        httpd.serve_forever()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\\\n‚èπÔ∏è Servidor finalizado.\")\n",
    "        httpd.shutdown()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start_server()'''\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'server.py'), 'w', encoding='utf-8') as f:\n",
    "            f.write(server_content)\n",
    "        \n",
    "        # Torna o servidor execut√°vel\n",
    "        os.chmod(os.path.join(self.web_dir, 'server.py'), 0o755)\n",
    "    \n",
    "    def _create_package_json(self):\n",
    "        \"\"\"Cria package.json para a interface web\"\"\"\n",
    "        package_content = {\n",
    "            \"name\": \"will-finance-project-manager\",\n",
    "            \"version\": \"1.0.0\",\n",
    "            \"description\": \"Interface web para gerenciar o projeto Will Finance 5.0\",\n",
    "            \"main\": \"server.py\",\n",
    "            \"scripts\": {\n",
    "                \"start\": \"python server.py\",\n",
    "                \"dev\": \"python server.py\",\n",
    "                \"install\": \"pip install -r requirements.txt\"\n",
    "            },\n",
    "            \"keywords\": [\"project-manager\", \"dashboard\", \"will-finance\"],\n",
    "            \"author\": \"Will Finance Team\",\n",
    "            \"license\": \"MIT\"\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'package.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(package_content, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        # Cria requirements.txt\n",
    "        requirements_content = '''# Will Finance 5.0 Project Manager Dependencies\n",
    "# Todas as depend√™ncias j√° est√£o no Python padr√£o\n",
    "# Este arquivo √© apenas para refer√™ncia\n",
    "\n",
    "# Se precisar de depend√™ncias adicionais:\n",
    "# requests>=2.28.0\n",
    "# flask>=2.2.0  # Alternativa ao http.server\n",
    "# jinja2>=3.1.0  # Para templates avan√ßados\n",
    "'''\n",
    "        \n",
    "        with open(os.path.join(self.web_dir, 'requirements.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(requirements_content)\n",
    "    \n",
    "    def launch_interface(self, port=8080):\n",
    "        \"\"\"Lan√ßa a interface web\"\"\"\n",
    "        server_path = os.path.join(self.web_dir, 'server.py')\n",
    "        \n",
    "        print(f\"üöÄ LAN√áANDO INTERFACE WEB...\")\n",
    "        print(f\"üìç URL: http://localhost:{port}\")\n",
    "        print(f\"üìÅ Diret√≥rio: {self.web_dir}\")\n",
    "        \n",
    "        # Executa o servidor\n",
    "        subprocess.Popen([sys.executable, server_path], cwd=self.web_dir)\n",
    "        \n",
    "        # Abre o navegador\n",
    "        threading.Timer(2.0, lambda: webbrowser.open(f'http://localhost:{port}')).start()\n",
    "        \n",
    "        return f\"http://localhost:{port}\"\n",
    "\n",
    "# Executar valida√ß√£o completa\n",
    "print(\"üîç EXECUTANDO VALIDA√á√ÉO COMPLETA DO PROJETO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "validator = ProjectValidator(PROJECT_ROOT)\n",
    "validation_results = validator.validate_everything()\n",
    "\n",
    "print(f\"\\\\nüéØ PODE AUTOCORRIGIR TUDO? {'‚úÖ SIM!' if validation_results['can_autocorrect'] else '‚ùå J√° est√° perfeito!'}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Criar interface web\n",
    "print(\"\\\\nüåê CRIANDO INTERFACE WEB DE GEST√ÉO...\")\n",
    "web_generator = WebInterfaceGenerator(PROJECT_ROOT)\n",
    "web_dir = web_generator.create_web_interface()\n",
    "\n",
    "print(f\"\\\\nüéâ SISTEMA COMPLETO CRIADO!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìÅ Interface Web: {web_dir}\")\n",
    "print(f\"üåê Para iniciar: python {os.path.join(web_dir, 'server.py')}\")\n",
    "print(f\"üìç URL: http://localhost:8080\")\n",
    "\n",
    "print(\"\\\\nüöÄ FUNCIONALIDADES DA INTERFACE WEB:\")\n",
    "print(\"-\" * 40)\n",
    "features = [\n",
    "    \"üìä Dashboard interativo com m√©tricas visuais\",\n",
    "    \"üîç Valida√ß√£o completa com 1 clique\",\n",
    "    \"üîß Autocorre√ß√£o de todo o projeto\",\n",
    "    \"üìà Monitoramento em tempo real\",\n",
    "    \"üõ†Ô∏è Terminal integrado\",\n",
    "    \"üìÑ Exporta√ß√£o de relat√≥rios\",\n",
    "    \"üéØ Interface responsiva e moderna\",\n",
    "    \"‚ö° API REST para integra√ß√£o\"\n",
    "]\n",
    "\n",
    "for feature in features:\n",
    "    print(f\"  {feature}\")\n",
    "\n",
    "print(\"\\\\nüí° COMO USAR:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"1. Execute: python project-manager-web/server.py\")\n",
    "print(\"2. Acesse: http://localhost:8080\")\n",
    "print(\"3. Use a interface para gerenciar tudo!\")\n",
    "\n",
    "print(\"\\\\n‚úÖ O notebook + interface web podem CORRIGIR TUDO automaticamente! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2d2a2",
   "metadata": {},
   "source": [
    "## üöÄ Como Iniciar o Sistema\n",
    "\n",
    "**PASSO A PASSO SIMPLES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db87f087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ WILL FINANCE 5.0 PROJECT MANAGER\n",
      "==================================================\n",
      "Este sistema vai criar uma interface web completa\n",
      "para gerenciar e corrigir todo o seu projeto!\n",
      "\n",
      "üîç VERIFICANDO REQUISITOS...\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 291\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# Verifica requisitos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mverificar_requisitos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[32m    293\u001b[39m     tutorial_rapido()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 262\u001b[39m, in \u001b[36mverificar_requisitos\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç VERIFICANDO REQUISITOS...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    259\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m    261\u001b[39m requisitos = {\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPython\u001b[39m\u001b[33m'\u001b[39m: \u001b[43msys\u001b[49m.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m),\n\u001b[32m    263\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOS Suportado\u001b[39m\u001b[33m'\u001b[39m: sys.platform \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mwin32\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlinux\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdarwin\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    264\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mDiret√≥rio do Projeto\u001b[39m\u001b[33m'\u001b[39m: os.path.exists(PROJECT_ROOT),\n\u001b[32m    265\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPermiss√µes de Escrita\u001b[39m\u001b[33m'\u001b[39m: os.access(PROJECT_ROOT, os.W_OK)\n\u001b[32m    266\u001b[39m }\n\u001b[32m    268\u001b[39m tudo_ok = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m req, status \u001b[38;5;129;01min\u001b[39;00m requisitos.items():\n",
      "\u001b[31mNameError\u001b[39m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "def iniciar_sistema_completo():\n",
    "    \"\"\"\n",
    "    INICIA TUDO COM UM CLIQUE!\n",
    "    Esta fun√ß√£o faz TUDO automaticamente:\n",
    "    1. Cria a interface web\n",
    "    2. Gera todos os arquivos necess√°rios  \n",
    "    3. Inicia o servidor\n",
    "    4. Abre o navegador\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ INICIANDO WILL FINANCE 5.0 PROJECT MANAGER\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Passo 1: Criar interface web\n",
    "    print(\"üì¶ PASSO 1: Criando interface web...\")\n",
    "    web_generator = WebInterfaceGenerator(PROJECT_ROOT)\n",
    "    web_dir = web_generator.create_web_interface()\n",
    "    \n",
    "    print(f\"‚úÖ Interface criada em: {web_dir}\")\n",
    "    print()\n",
    "    \n",
    "    # Passo 2: Iniciar servidor\n",
    "    print(\"üåê PASSO 2: Iniciando servidor web...\")\n",
    "    server_script = os.path.join(web_dir, 'server.py')\n",
    "    \n",
    "    # Cria um script de inicializa√ß√£o melhorado\n",
    "    startup_script = f'''\n",
    "import os\n",
    "import sys\n",
    "import webbrowser\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Muda para o diret√≥rio correto\n",
    "os.chdir(r\"{web_dir}\")\n",
    "sys.path.append(r\"{PROJECT_ROOT}\")\n",
    "\n",
    "print(\"üåê Will Finance 5.0 Project Manager\")\n",
    "print(\"üìç Servidor iniciando em http://localhost:8080\")\n",
    "print(\"üîß Projeto: {PROJECT_ROOT}\")\n",
    "print()\n",
    "\n",
    "# Importa e executa o servidor\n",
    "exec(open(\"server.py\").read())\n",
    "'''\n",
    "    \n",
    "    # Salva script de inicializa√ß√£o\n",
    "    startup_file = os.path.join(web_dir, 'start.py')\n",
    "    with open(startup_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(startup_script)\n",
    "    \n",
    "    print(\"‚úÖ Servidor configurado!\")\n",
    "    print()\n",
    "    \n",
    "    # Passo 3: Criar script batch para Windows\n",
    "    print(\"üíª PASSO 3: Criando atalhos para execu√ß√£o...\")\n",
    "    \n",
    "    # Script BAT para Windows\n",
    "    bat_content = f'''@echo off\n",
    "title Will Finance 5.0 Project Manager\n",
    "echo üöÄ Iniciando Will Finance 5.0 Project Manager...\n",
    "echo.\n",
    "cd /d \"{web_dir}\"\n",
    "python start.py\n",
    "pause\n",
    "'''\n",
    "    \n",
    "    bat_file = os.path.join(web_dir, 'Iniciar_Project_Manager.bat')\n",
    "    with open(bat_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(bat_content)\n",
    "    \n",
    "    # Script PowerShell\n",
    "    ps1_content = f'''# Will Finance 5.0 Project Manager\n",
    "Write-Host \"üöÄ Iniciando Will Finance 5.0 Project Manager...\" -ForegroundColor Green\n",
    "Write-Host \"\"\n",
    "Set-Location \"{web_dir}\"\n",
    "python start.py\n",
    "Read-Host \"Pressione Enter para sair\"\n",
    "'''\n",
    "    \n",
    "    ps1_file = os.path.join(web_dir, 'Iniciar_Project_Manager.ps1')\n",
    "    with open(ps1_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(ps1_content)\n",
    "    \n",
    "    print(\"‚úÖ Atalhos criados!\")\n",
    "    print()\n",
    "    \n",
    "    # Passo 4: Criar README de instru√ß√µes\n",
    "    print(\"üìö PASSO 4: Criando instru√ß√µes...\")\n",
    "    \n",
    "    readme_content = f'''# Will Finance 5.0 Project Manager\n",
    "\n",
    "## üöÄ Como Iniciar\n",
    "\n",
    "### Op√ß√£o 1: Windows (Mais F√°cil)\n",
    "- **Duplo clique** em `Iniciar_Project_Manager.bat`\n",
    "- Pronto! O navegador abrir√° automaticamente\n",
    "\n",
    "### Op√ß√£o 2: PowerShell  \n",
    "- Clique direito em `Iniciar_Project_Manager.ps1` > \"Executar com PowerShell\"\n",
    "\n",
    "### Op√ß√£o 3: Terminal Manual\n",
    "```bash\n",
    "cd \"{web_dir}\"\n",
    "python start.py\n",
    "```\n",
    "\n",
    "### Op√ß√£o 4: Python Direto\n",
    "```bash\n",
    "cd \"{web_dir}\"\n",
    "python server.py\n",
    "```\n",
    "\n",
    "## üåê URL de Acesso\n",
    "```\n",
    "http://localhost:8080\n",
    "```\n",
    "\n",
    "## üìÅ Estrutura\n",
    "```\n",
    "{os.path.basename(web_dir)}/\n",
    "‚îú‚îÄ‚îÄ index.html          # Interface principal\n",
    "‚îú‚îÄ‚îÄ styles.css          # Estilos\n",
    "‚îú‚îÄ‚îÄ app.js              # JavaScript da aplica√ß√£o\n",
    "‚îú‚îÄ‚îÄ server.py           # Servidor Python\n",
    "‚îú‚îÄ‚îÄ start.py            # Script de inicializa√ß√£o\n",
    "‚îú‚îÄ‚îÄ Iniciar_Project_Manager.bat    # Atalho Windows\n",
    "‚îî‚îÄ‚îÄ Iniciar_Project_Manager.ps1    # Atalho PowerShell\n",
    "```\n",
    "\n",
    "## üîß Funcionalidades\n",
    "\n",
    "### Dashboard\n",
    "- ‚úÖ Vis√£o geral do projeto\n",
    "- üìä M√©tricas visuais\n",
    "- ‚ö†Ô∏è Problemas identificados\n",
    "\n",
    "### Valida√ß√£o\n",
    "- üîç An√°lise completa do projeto\n",
    "- üìã Relat√≥rio detalhado de cada categoria\n",
    "- üìà Scores de qualidade\n",
    "\n",
    "### Corre√ß√µes\n",
    "- üîß Autocorre√ß√£o com 1 clique\n",
    "- üìÅ Cria√ß√£o de arquivos essenciais\n",
    "- ‚öôÔ∏è Configura√ß√µes autom√°ticas\n",
    "- üê≥ Setup completo de Docker\n",
    "- üîí Configura√ß√µes de seguran√ßa\n",
    "\n",
    "### Monitoramento  \n",
    "- üìä Estat√≠sticas do projeto\n",
    "- üìà M√©tricas em tempo real\n",
    "- üîÑ Atualiza√ß√µes autom√°ticas\n",
    "\n",
    "### Ferramentas\n",
    "- üñ•Ô∏è Terminal integrado\n",
    "- üìÑ Exporta√ß√£o de relat√≥rios\n",
    "- üõ†Ô∏è Utilit√°rios diversos\n",
    "\n",
    "## üÜò Solu√ß√£o de Problemas\n",
    "\n",
    "### Se der erro \"python n√£o encontrado\":\n",
    "1. Instale Python 3.8+ em python.org\n",
    "2. Marque \"Add to PATH\" na instala√ß√£o\n",
    "\n",
    "### Se a porta 8080 estiver ocupada:\n",
    "- Edite `server.py` e mude a porta na √∫ltima linha\n",
    "- Ou mate o processo: `taskkill /f /im python.exe`\n",
    "\n",
    "### Se o navegador n√£o abrir:\n",
    "- Acesse manualmente: http://localhost:8080\n",
    "\n",
    "## üìû Suporte\n",
    "- Projeto: Will Finance 5.0\n",
    "- Localiza√ß√£o: {PROJECT_ROOT}\n",
    "- Vers√£o: 1.0.0\n",
    "'''\n",
    "    \n",
    "    readme_file = os.path.join(web_dir, 'README.md')\n",
    "    with open(readme_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(\"‚úÖ Documenta√ß√£o criada!\")\n",
    "    print()\n",
    "    \n",
    "    # Resumo final\n",
    "    print(\"üéâ SISTEMA CRIADO COM SUCESSO!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìÅ Localiza√ß√£o: {web_dir}\")\n",
    "    print()\n",
    "    print(\"üöÄ COMO INICIAR (escolha uma op√ß√£o):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"1. üíª F√ÅCIL: Duplo clique em '{os.path.basename(bat_file)}'\")\n",
    "    print(f\"2. ‚ö° PowerShell: Execute '{os.path.basename(ps1_file)}'\") \n",
    "    print(f\"3. üêç Python: cd \\\"{web_dir}\\\" && python start.py\")\n",
    "    print(f\"4. üåê Direto: cd \\\"{web_dir}\\\" && python server.py\")\n",
    "    print()\n",
    "    print(\"üìç URL: http://localhost:8080\")\n",
    "    print()\n",
    "    \n",
    "    # Tenta iniciar automaticamente\n",
    "    print(\"üîÑ Tentando iniciar automaticamente...\")\n",
    "    try:\n",
    "        import subprocess\n",
    "        import threading\n",
    "        \n",
    "        # Inicia o servidor em background\n",
    "        def start_server():\n",
    "            os.chdir(web_dir)\n",
    "            subprocess.run([sys.executable, 'start.py'])\n",
    "        \n",
    "        thread = threading.Thread(target=start_server, daemon=True)\n",
    "        thread.start()\n",
    "        \n",
    "        # Aguarda um pouco e abre o navegador\n",
    "        time.sleep(2)\n",
    "        import webbrowser\n",
    "        webbrowser.open('http://localhost:8080')\n",
    "        \n",
    "        print(\"‚úÖ Servidor iniciado e navegador aberto!\")\n",
    "        print(\"üí° Se n√£o abriu automaticamente, use uma das op√ß√µes acima.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è N√£o foi poss√≠vel iniciar automaticamente: {e}\")\n",
    "        print(\"üí° Use uma das op√ß√µes manuais acima.\")\n",
    "    \n",
    "    return web_dir\n",
    "\n",
    "def tutorial_rapido():\n",
    "    \"\"\"Tutorial r√°pido de uso\"\"\"\n",
    "    print(\"üìö TUTORIAL R√ÅPIDO\")\n",
    "    print(\"=\" * 30)\n",
    "    print()\n",
    "    print(\"1Ô∏è‚É£ AN√ÅLISE:\")\n",
    "    print(\"   ‚Ä¢ Abra a aba 'Valida√ß√£o'\")\n",
    "    print(\"   ‚Ä¢ Clique 'Executar Valida√ß√£o'\")\n",
    "    print(\"   ‚Ä¢ Veja os problemas encontrados\")\n",
    "    print()\n",
    "    print(\"2Ô∏è‚É£ CORRE√á√ÉO:\")\n",
    "    print(\"   ‚Ä¢ Abra a aba 'Corre√ß√µes'\")  \n",
    "    print(\"   ‚Ä¢ Clique 'TODAS as Corre√ß√µes'\")\n",
    "    print(\"   ‚Ä¢ Aguarde as corre√ß√µes serem aplicadas\")\n",
    "    print()\n",
    "    print(\"3Ô∏è‚É£ MONITORAMENTO:\")\n",
    "    print(\"   ‚Ä¢ Abra a aba 'Monitoramento'\")\n",
    "    print(\"   ‚Ä¢ Veja estat√≠sticas do projeto\")\n",
    "    print(\"   ‚Ä¢ Acompanhe a evolu√ß√£o\")\n",
    "    print()\n",
    "    print(\"4Ô∏è‚É£ FERRAMENTAS:\")\n",
    "    print(\"   ‚Ä¢ Use o terminal integrado\")\n",
    "    print(\"   ‚Ä¢ Exporte relat√≥rios\")\n",
    "    print(\"   ‚Ä¢ Execute comandos personalizados\")\n",
    "    print()\n",
    "\n",
    "def verificar_requisitos():\n",
    "    \"\"\"Verifica se tem tudo necess√°rio\"\"\"\n",
    "    print(\"üîç VERIFICANDO REQUISITOS...\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    requisitos = {\n",
    "        'Python': sys.version_info >= (3, 6),\n",
    "        'OS Suportado': sys.platform in ['win32', 'linux', 'darwin'],\n",
    "        'Diret√≥rio do Projeto': os.path.exists(PROJECT_ROOT),\n",
    "        'Permiss√µes de Escrita': os.access(PROJECT_ROOT, os.W_OK)\n",
    "    }\n",
    "    \n",
    "    tudo_ok = True\n",
    "    for req, status in requisitos.items():\n",
    "        icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "        print(f\"  {icon} {req}\")\n",
    "        if not status:\n",
    "            tudo_ok = False\n",
    "    \n",
    "    if tudo_ok:\n",
    "        print(\"\\\\nüéâ Todos os requisitos atendidos!\")\n",
    "    else:\n",
    "        print(\"\\\\n‚ö†Ô∏è Alguns requisitos n√£o foram atendidos.\")\n",
    "    \n",
    "    return tudo_ok\n",
    "\n",
    "# ====== EXECU√á√ÉO PRINCIPAL ======\n",
    "\n",
    "print(\"üéØ WILL FINANCE 5.0 PROJECT MANAGER\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Este sistema vai criar uma interface web completa\")\n",
    "print(\"para gerenciar e corrigir todo o seu projeto!\")\n",
    "print()\n",
    "\n",
    "# Verifica requisitos\n",
    "if verificar_requisitos():\n",
    "    print()\n",
    "    tutorial_rapido()\n",
    "    print()\n",
    "    \n",
    "    resposta = input(\"üöÄ Quer criar e iniciar o sistema agora? (s/n): \").lower().strip()\n",
    "    \n",
    "    if resposta in ['s', 'sim', 'y', 'yes', '']:\n",
    "        print()\n",
    "        web_dir = iniciar_sistema_completo()\n",
    "        \n",
    "        print()\n",
    "        print(\"üéä PRONTO! Agora voc√™ pode:\")\n",
    "        print(\"‚Ä¢ Analisar todo o projeto visualmente\")\n",
    "        print(\"‚Ä¢ Corrigir problemas com 1 clique\") \n",
    "        print(\"‚Ä¢ Monitorar m√©tricas em tempo real\")\n",
    "        print(\"‚Ä¢ Exportar relat√≥rios profissionais\")\n",
    "        print()\n",
    "        print(\"üí° Dica: Marque nos favoritos http://localhost:8080\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\\\nüëç Ok! Para iniciar mais tarde, execute:\")\n",
    "        print(\"   iniciar_sistema_completo()\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\\\n‚ùå Resolva os requisitos primeiro.\")\n",
    "\n",
    "print(\"\\\\n‚ú® Sistema Will Finance 5.0 Project Manager pronto!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
